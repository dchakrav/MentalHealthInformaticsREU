{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suicide Watch analysis\n",
    "This notebook will walk you through building the models we\n",
    "built after collecting our data from the Suicide Watch Subreddit\n",
    "\n",
    "We first import the libraries and utility files we are going to be using,\n",
    "and parse and clean our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Import machine learning libraries\n",
    "import gensim\n",
    "import textmining\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg as LA\n",
    "import scipy.sparse as sparse\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.cluster import KMeans\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "# Import utility files\n",
    "import dataUtils\n",
    "import clusterUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the data from the csv\n",
    "df = dataUtils.read_df('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean the text in the datafram\n",
    "df =df.replace(np.nan, '', regex=True)\n",
    "df[\"rawtext\"]= df[\"title\"]+\" \"+df[\"selftext\"]\n",
    "df[\"cleantext\"]=df[\"rawtext\"].apply(dataUtils.remove_links).apply(dataUtils.cleanSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a stream of text\n",
    "posts= df[\"cleantext\"].apply(lambda str: str.split()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train a phraseDetector\n",
    "two_word_phrases = gensim.models.Phrases(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "two_word_phraser = gensim.models.phrases.Phraser(two_word_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# phrase_length =3\n",
    "#posts = list(two_word_phraser[posts])\n",
    "three_word_phrases = gensim.models.Phrases(two_word_phraser[posts])\n",
    "three_word_phraser = gensim.models.phrases.Phraser(three_word_phrases)\n",
    "posts              = list(three_word_phraser[two_word_phraser[posts]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# update clean text\n",
    "df[\"cleantext\"]=df[\"cleantext\"].apply(lambda str: \" \".join(three_word_phraser[two_word_phraser[str.split()]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data summary statistics\n",
    "\n",
    "Before building models, we first look at that data that we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the number of posts\n",
    "num_posts = len(posts)\n",
    "num_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the number of users (minus [deleted])\n",
    "userList= df[\"author\"].tolist()\n",
    "userDict = {}\n",
    "for user in userList:\n",
    "    if user in userDict.keys() and user != \"[deleted]\":\n",
    "        userDict[user] =1+userDict[user]\n",
    "    else:\n",
    "        userDict[user] =1\n",
    "len(list(userDict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build word2vec model\n",
    "At this step we will build the word2vec model that we will use in the rest of the analysis.\n",
    "Becuase this is a compuationally expensive process, we save the results of running our model\n",
    "as the value of model_name +\".model\" in the models directory. We can then load this model later, and do not need\n",
    "to re build it every time we want to analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"model3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataUtils.save_object(posts,'objects/',model_name+\"-posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts = dataUtils.load_object('objects/',model_name+\"-posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = gensim.models.Word2Vec(posts,min_count =10,\n",
    "                               sg=1, size =300,window=5,hs=1,negative=20)\n",
    "model.save('models/'+model_name+'.model')\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 0.45109570026397705),\n",
       " ('dog', 0.44111454486846924),\n",
       " ('german_shepherd', 0.4406666159629822),\n",
       " ('pet', 0.4357992708683014),\n",
       " ('baby', 0.4264637529850006),\n",
       " ('puppy', 0.4233230948448181),\n",
       " ('bunny', 0.3860231637954712),\n",
       " ('kittens', 0.3827037215232849),\n",
       " ('kitty', 0.38069093227386475),\n",
       " ('cats', 0.3786470293998718)]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "model = gensim.models.Word2Vec.load('models/'+model_name+'.model')\n",
    "# Test the model: you should see cat somewhere in this list, near the top\n",
    "model.most_similar(positive=[\"kitten\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model\n",
    "\n",
    "At this step we run some basic tests to ensure that the model has picked up on some of the semantic meanings of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"kitten\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"heartbreak\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"pills\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"knife\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"heartbreak\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"drugs\",\"hurt\"],negative =[\"help\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"drugs\",\"help\"],negative =[\"hurt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word usage summary\n",
    "\n",
    "At this step, after our model has looked at all the words, \n",
    "and filtered some out, we will look at the words used by our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the list of words used\n",
    "vocab_list = sorted(list(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#',\n",
       " '##',\n",
       " '###',\n",
       " '%',\n",
       " '%+',\n",
       " '%_certain',\n",
       " '%_certainty',\n",
       " '%_chance',\n",
       " '%_effective',\n",
       " '%_success_rate',\n",
       " '%_sure',\n",
       " \"'\",\n",
       " \"''\",\n",
       " \"''i\",\n",
       " \"''you\",\n",
       " \"'_'\",\n",
       " \"'_''\",\n",
       " \"'_lb\",\n",
       " \"'_lbs\",\n",
       " \"'_pounds\",\n",
       " \"'_tall\",\n",
       " \"'a\",\n",
       " \"'all\",\n",
       " \"'bad'\",\n",
       " \"'be\",\n",
       " \"'being\",\n",
       " \"'best_friend'\",\n",
       " \"'better'\",\n",
       " \"'cause\",\n",
       " \"'close'\",\n",
       " \"'cool'\",\n",
       " \"'d\",\n",
       " \"'depressed'\",\n",
       " \"'depression'\",\n",
       " \"'do\",\n",
       " \"'don't\",\n",
       " \"'em\",\n",
       " \"'everything\",\n",
       " \"'family'\",\n",
       " \"'fix'\",\n",
       " \"'friend'\",\n",
       " \"'friends'\",\n",
       " \"'fuck\",\n",
       " \"'get\",\n",
       " \"'get_better'\",\n",
       " \"'get_over_it'\",\n",
       " \"'go\",\n",
       " \"'god'\",\n",
       " \"'good\",\n",
       " \"'good'\",\n",
       " \"'happy'\",\n",
       " \"'have\",\n",
       " \"'help'\",\n",
       " \"'hey\",\n",
       " \"'home'\",\n",
       " \"'how\",\n",
       " \"'i\",\n",
       " \"'i'm\",\n",
       " \"'if\",\n",
       " \"'in\",\n",
       " \"'it\",\n",
       " \"'it'\",\n",
       " \"'it's\",\n",
       " \"'it_gets_better'\",\n",
       " \"'it_will\",\n",
       " \"'its\",\n",
       " \"'just\",\n",
       " \"'life\",\n",
       " \"'life'\",\n",
       " \"'living'\",\n",
       " \"'love\",\n",
       " \"'love'\",\n",
       " \"'m\",\n",
       " \"'make\",\n",
       " \"'maybe\",\n",
       " \"'me'\",\n",
       " \"'my\",\n",
       " \"'no\",\n",
       " \"'normal'\",\n",
       " \"'not\",\n",
       " \"'oh\",\n",
       " \"'okay'\",\n",
       " \"'one_more_day'\",\n",
       " \"'out\",\n",
       " \"'real\",\n",
       " \"'real'\",\n",
       " \"'right'\",\n",
       " \"'s\",\n",
       " \"'see\",\n",
       " \"'smart'\",\n",
       " \"'suicidal'\",\n",
       " \"'suicide\",\n",
       " \"'that\",\n",
       " \"'the\",\n",
       " \"'there\",\n",
       " \"'this\",\n",
       " \"'til\",\n",
       " \"'till\",\n",
       " \"'to\",\n",
       " \"'too\",\n",
       " \"'ve\",\n",
       " \"'we\",\n",
       " \"'well\",\n",
       " \"'what\",\n",
       " \"'when\",\n",
       " \"'why\",\n",
       " \"'you\",\n",
       " \"'you're\",\n",
       " '+',\n",
       " '+_hour',\n",
       " '+_hours',\n",
       " '+_miles',\n",
       " '+_miles_away',\n",
       " '+_years',\n",
       " '-',\n",
       " '--',\n",
       " '---',\n",
       " '----',\n",
       " '-----',\n",
       " '-------',\n",
       " '--------',\n",
       " '---------',\n",
       " '---_gt',\n",
       " '--_gt',\n",
       " '--and',\n",
       " '--i',\n",
       " '-_-_-talk',\n",
       " '-_calories',\n",
       " '-_hours_per',\n",
       " '-a',\n",
       " '-and',\n",
       " '-day',\n",
       " '-have',\n",
       " '-he',\n",
       " '-hour',\n",
       " '-htp',\n",
       " '-i',\n",
       " \"-i'm\",\n",
       " \"-i've\",\n",
       " '-if',\n",
       " '-im',\n",
       " '-ish',\n",
       " '-month',\n",
       " '-my',\n",
       " '-no',\n",
       " '-not',\n",
       " '-she',\n",
       " '-something',\n",
       " '-the',\n",
       " '-this',\n",
       " '-to',\n",
       " '-week',\n",
       " '-year',\n",
       " '-year-old',\n",
       " '-year-old_female',\n",
       " '-year-old_girl',\n",
       " '-year-old_male',\n",
       " '-year_old',\n",
       " '-years-old',\n",
       " '-you',\n",
       " '=',\n",
       " '=d',\n",
       " '@',\n",
       " '@gmail_com',\n",
       " '\\\\',\n",
       " '\\\\_\\\\_\\\\_\\\\',\n",
       " '`',\n",
       " 'a',\n",
       " \"a's\",\n",
       " 'a+',\n",
       " 'a-level',\n",
       " 'a-levels',\n",
       " 'a-okay',\n",
       " 'aa',\n",
       " 'aa_meetings',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abandonment_issues',\n",
       " 'abandonned',\n",
       " 'abandons',\n",
       " 'abated',\n",
       " 'abby',\n",
       " 'abd',\n",
       " 'abdomen',\n",
       " 'abdominal',\n",
       " 'abducted',\n",
       " 'abhor',\n",
       " 'abhorrent',\n",
       " 'abide_by',\n",
       " 'abilify',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abit',\n",
       " 'abject',\n",
       " 'able',\n",
       " 'abnormal',\n",
       " 'abnormality',\n",
       " 'abnormally',\n",
       " 'abomination',\n",
       " 'abort',\n",
       " 'aborted',\n",
       " 'aborting',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'above',\n",
       " 'above_average',\n",
       " 'above_average_intelligence',\n",
       " 'above_water',\n",
       " 'abrasive',\n",
       " 'abridged_version',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abs',\n",
       " 'absence',\n",
       " 'absences',\n",
       " 'absent',\n",
       " 'absent-minded',\n",
       " 'absolute',\n",
       " 'absolute_best',\n",
       " 'absolute_best_friend',\n",
       " 'absolute_bliss',\n",
       " 'absolute_certainty',\n",
       " 'absolute_hardest',\n",
       " 'absolute_hell',\n",
       " 'absolute_misery',\n",
       " 'absolute_nothingness',\n",
       " 'absolute_shit',\n",
       " 'absolute_trash',\n",
       " 'absolute_truth',\n",
       " 'absolute_worst',\n",
       " 'absolutely',\n",
       " 'absolutely_adore',\n",
       " 'absolutely_crushed',\n",
       " 'absolutely_despise',\n",
       " 'absolutely_devastated',\n",
       " 'absolutely_devastating',\n",
       " 'absolutely_disgusted',\n",
       " 'absolutely_gorgeous',\n",
       " 'absolutely_heartbroken',\n",
       " 'absolutely_loathe',\n",
       " 'absolutely_necessary',\n",
       " 'absolutely_refuse',\n",
       " 'absolutely_terrified',\n",
       " 'absolutely_zero',\n",
       " 'absolution',\n",
       " 'absolutley',\n",
       " 'absolutly',\n",
       " 'absolve',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'abstain_from',\n",
       " 'abstinence',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'abt',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly_clear',\n",
       " 'abuse',\n",
       " 'abuse_neglect',\n",
       " 'abused',\n",
       " 'abused_physically',\n",
       " 'abuser',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusing_alcohol',\n",
       " 'abusing_drugs',\n",
       " 'abusive',\n",
       " 'abusive_alcoholic',\n",
       " 'abusive_asshole',\n",
       " 'abusive_behavior',\n",
       " 'abusive_childhood',\n",
       " 'abusive_ex',\n",
       " 'abusive_ex_boyfriend',\n",
       " 'abusive_father',\n",
       " 'abusive_household',\n",
       " 'abusive_marriage',\n",
       " 'abusive_parent',\n",
       " 'abusive_relationship',\n",
       " 'abusive_relationships',\n",
       " 'abusive_towards',\n",
       " 'abut',\n",
       " 'abysmal',\n",
       " 'abyss',\n",
       " 'ac',\n",
       " 'aca',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academic_advisor',\n",
       " 'academic_career',\n",
       " 'academic_failure',\n",
       " 'academic_performance',\n",
       " 'academic_probation',\n",
       " 'academic_record',\n",
       " 'academic_success',\n",
       " 'academically',\n",
       " 'academics',\n",
       " 'academy',\n",
       " 'acc',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerating',\n",
       " 'accelerator',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'accept_defeat',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'acceptance_letter',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepting_new_patients',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accessories',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidental_death',\n",
       " 'accidentally',\n",
       " 'accidentally_sent',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'accolades',\n",
       " 'accommodate',\n",
       " 'accommodating',\n",
       " 'accommodation',\n",
       " 'accommodations',\n",
       " 'accompanied',\n",
       " 'accompanied_by',\n",
       " 'accompanies',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplish_anything',\n",
       " 'accomplished',\n",
       " 'accomplished_nothing',\n",
       " 'accomplishing',\n",
       " 'accomplishing_anything',\n",
       " 'accomplishing_something',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountant',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accrued',\n",
       " 'acct',\n",
       " 'acctually',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulating',\n",
       " 'accumulation',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accusatory',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'accustomed',\n",
       " 'accutane',\n",
       " 'ace',\n",
       " 'aced',\n",
       " 'acetaminophen',\n",
       " 'ache',\n",
       " 'ached',\n",
       " 'acheive',\n",
       " 'aches',\n",
       " 'achievable',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achieving',\n",
       " 'aching',\n",
       " 'acid',\n",
       " 'acid_reflux',\n",
       " 'acing',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acknowledgment',\n",
       " 'acl',\n",
       " 'acne',\n",
       " 'acne_scars',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquainted',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquiring',\n",
       " 'acres',\n",
       " 'across',\n",
       " 'across_town',\n",
       " 'act',\n",
       " 'act_differently',\n",
       " 'act_itself',\n",
       " 'act_score',\n",
       " 'act_upon',\n",
       " 'act_upon_them',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'acting_strange',\n",
       " 'acting_strangely',\n",
       " 'acting_upon',\n",
       " 'acting_weird',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'active',\n",
       " 'active_duty',\n",
       " 'active_social',\n",
       " 'actively',\n",
       " 'actively_avoid',\n",
       " 'actively_planning',\n",
       " 'actively_seek',\n",
       " 'actively_seeking',\n",
       " 'actively_suicidal',\n",
       " 'actively_trying',\n",
       " 'activist',\n",
       " 'activites',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actual_account',\n",
       " 'actuality',\n",
       " 'actually',\n",
       " 'actualy',\n",
       " 'acupuncture',\n",
       " 'acutally',\n",
       " 'acute',\n",
       " 'acutely',\n",
       " 'acutely_aware',\n",
       " 'acutely_suicidal',\n",
       " 'ad',\n",
       " 'ad_nauseam',\n",
       " 'adam',\n",
       " \"adam's_apple\",\n",
       " 'adamant',\n",
       " 'adamantly',\n",
       " 'adapt',\n",
       " 'adapted',\n",
       " 'adapting',\n",
       " 'add',\n",
       " 'add_insult',\n",
       " 'add_onto',\n",
       " 'added',\n",
       " 'added_stress',\n",
       " 'addendum',\n",
       " 'adderal',\n",
       " 'adderall',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addiction',\n",
       " 'addictions',\n",
       " 'addictive',\n",
       " 'addictive_personality',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adhd',\n",
       " 'adhd-pi',\n",
       " 'adhd_medication',\n",
       " 'adhd_meds',\n",
       " 'adhere',\n",
       " 'adieu',\n",
       " 'adios',\n",
       " 'adjacent',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'admin',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administration',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admins',\n",
       " 'admirable',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admiring',\n",
       " 'admission',\n",
       " 'admissions',\n",
       " 'admit',\n",
       " 'admit_defeat',\n",
       " 'admited',\n",
       " 'admits',\n",
       " 'admittance',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'admitting_defeat',\n",
       " 'adn',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adolescents',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adoptive_family',\n",
       " 'adoptive_parents',\n",
       " 'adorable',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adores',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrenaline_rush',\n",
       " 'adress',\n",
       " 'adrift',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adult_children',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advanced_classes',\n",
       " 'advancement',\n",
       " 'advancements',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adverse',\n",
       " 'adversity',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advice_regarding',\n",
       " 'advices',\n",
       " 'advil',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'adviser',\n",
       " 'advises',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisors',\n",
       " 'advocate',\n",
       " 'advocating',\n",
       " 'aerospace_engineering',\n",
       " 'aesthetic',\n",
       " 'af',\n",
       " 'afaik',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affected_by',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affection_towards',\n",
       " 'affectionate',\n",
       " 'affectionately',\n",
       " 'affections',\n",
       " 'affects',\n",
       " 'affiliated_with',\n",
       " 'affinity',\n",
       " 'affirm',\n",
       " 'affirmation',\n",
       " 'affirmations',\n",
       " 'affirmed',\n",
       " 'affirming',\n",
       " 'afflicted',\n",
       " 'affliction',\n",
       " 'afflictions',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'afford_food',\n",
       " 'afford_rent',\n",
       " 'affordable',\n",
       " 'afforded',\n",
       " 'affording',\n",
       " 'affraid',\n",
       " 'afghanistan',\n",
       " 'afk',\n",
       " 'afloat',\n",
       " 'aforementioned',\n",
       " 'afraid',\n",
       " 'afriad',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'african_american',\n",
       " 'after',\n",
       " 'after_graduating_high',\n",
       " 'after_graduation',\n",
       " 'afterall',\n",
       " 'afterlife',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'afterthought',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'afterwords',\n",
       " 'again',\n",
       " 'again-',\n",
       " 'against',\n",
       " 'age',\n",
       " 'age_difference',\n",
       " 'age_gap',\n",
       " 'age_range',\n",
       " 'aged',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'ages_-',\n",
       " 'ages_ago',\n",
       " 'aggravate',\n",
       " 'aggravated',\n",
       " 'aggravates',\n",
       " 'aggravating',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'aggressor',\n",
       " 'agh',\n",
       " 'aging',\n",
       " 'agitated',\n",
       " 'agitation',\n",
       " 'agnostic',\n",
       " 'ago',\n",
       " 'agonising',\n",
       " 'agonizing',\n",
       " 'agonizing_pain',\n",
       " 'agonizingly',\n",
       " 'agony',\n",
       " 'agoraphobia',\n",
       " 'agoraphobic',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agreed_upon',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agreements',\n",
       " 'agrees',\n",
       " 'agressive',\n",
       " 'ah',\n",
       " 'ah_well',\n",
       " 'aha',\n",
       " 'ahe',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahh',\n",
       " 'ahve',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aided',\n",
       " 'aids',\n",
       " 'ailing',\n",
       " 'ailment',\n",
       " 'ailments',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aimed_at',\n",
       " 'aiming',\n",
       " 'aimless',\n",
       " 'aimlessly',\n",
       " \"ain't\",\n",
       " 'aint',\n",
       " 'ain’t',\n",
       " 'air',\n",
       " 'air_conditioner',\n",
       " 'air_conditioning',\n",
       " 'air_force',\n",
       " 'airforce',\n",
       " 'airing',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'aisle',\n",
       " 'ait',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'akward',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alarm_clock',\n",
       " 'alarm_went',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alarms',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'albeit',\n",
       " 'alberta',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alchohol',\n",
       " 'alcohol',\n",
       " 'alcohol_abuse',\n",
       " 'alcohol_addiction',\n",
       " 'alcohol_poisoning',\n",
       " 'alcoholic',\n",
       " 'alcoholic_father',\n",
       " 'alcoholic_mother',\n",
       " 'alcoholics',\n",
       " 'alcoholism',\n",
       " 'alert',\n",
       " 'alerted',\n",
       " 'alerting',\n",
       " 'aleve',\n",
       " 'alex',\n",
       " 'alexis',\n",
       " 'alexithymia',\n",
       " 'algebra',\n",
       " 'ali',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienated',\n",
       " 'alienates',\n",
       " 'alienating',\n",
       " 'alienation',\n",
       " 'aliens',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'alignment',\n",
       " 'alike',\n",
       " 'alimony',\n",
       " 'alison',\n",
       " 'alittle',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'all-around',\n",
       " 'all-consuming',\n",
       " 'all_encompassing',\n",
       " 'all_honesty',\n",
       " 'all_intents',\n",
       " 'all_kinds',\n",
       " 'all_nighters',\n",
       " 'all_sorts',\n",
       " 'allah',\n",
       " 'allegations',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allen',\n",
       " 'allergic',\n",
       " 'allergic_reaction',\n",
       " 'allergies',\n",
       " 'allergy',\n",
       " 'alleviate',\n",
       " 'alleviated',\n",
       " 'alleviating',\n",
       " 'alley',\n",
       " 'allies',\n",
       " 'alll',\n",
       " 'allocated',\n",
       " 'allot',\n",
       " 'allotted',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allready',\n",
       " 'allright',\n",
       " 'alluded',\n",
       " 'alluding',\n",
       " 'allure',\n",
       " 'alluring',\n",
       " 'allways',\n",
       " 'ally',\n",
       " 'almighty',\n",
       " 'almost',\n",
       " 'almost_daily',\n",
       " 'almost_exclusively',\n",
       " 'almost_immediately',\n",
       " 'almost_impossible',\n",
       " 'almost_jumped',\n",
       " 'almost_jumped_off',\n",
       " 'almost_killed',\n",
       " 'almost_non-stop',\n",
       " 'almost_nonstop',\n",
       " 'almost_succeeded',\n",
       " 'almost_thirty',\n",
       " 'almost_two_decades',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'along_those_lines',\n",
       " 'alongside',\n",
       " 'aloof',\n",
       " 'alopecia',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'alpha',\n",
       " 'alpha_male',\n",
       " 'alprazolam',\n",
       " 'already',\n",
       " 'already_dead_inside',\n",
       " 'already_established',\n",
       " 'already_written',\n",
       " 'alright',\n",
       " 'als',\n",
       " 'also',\n",
       " 'alt',\n",
       " 'alt_account',\n",
       " 'alter',\n",
       " 'altercation',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternate_between',\n",
       " 'alternately',\n",
       " 'alternates_between',\n",
       " 'alternating',\n",
       " 'alternating_between',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alternatives',\n",
       " 'although',\n",
       " 'altogether',\n",
       " 'altough',\n",
       " 'altruism',\n",
       " 'altruistic',\n",
       " 'alway',\n",
       " 'always',\n",
       " 'always_dreamed',\n",
       " 'always_joked',\n",
       " 'always_wondered',\n",
       " 'always_wondered_why',\n",
       " 'alyssa',\n",
       " 'alzheimer',\n",
       " \"alzheimer's\",\n",
       " 'alzheimers',\n",
       " 'am',\n",
       " 'am-',\n",
       " 'am-_am',\n",
       " 'am-_pm',\n",
       " 'am_aurora',\n",
       " 'am_aurora_im',\n",
       " 'am_eternally_grateful',\n",
       " 'am_lunar_redemption',\n",
       " 'am_tiered',\n",
       " 'ama',\n",
       " 'amanda',\n",
       " 'amassed',\n",
       " 'amateur',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazes',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazingly_well',\n",
       " 'amazon',\n",
       " 'amber',\n",
       " 'ambien',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'ambivalence',\n",
       " 'ambivalent',\n",
       " 'ambulance',\n",
       " 'ambulance_came',\n",
       " 'ambulances',\n",
       " 'amd',\n",
       " 'amend',\n",
       " 'america',\n",
       " \"america's\",\n",
       " 'american',\n",
       " 'american_dream',\n",
       " 'american_foundation',\n",
       " 'american_society',\n",
       " 'americans',\n",
       " 'americorps',\n",
       " 'amicable',\n",
       " 'amicably',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'amirite',\n",
       " 'amiss',\n",
       " 'amitriptyline',\n",
       " 'ammo',\n",
       " 'ammonia',\n",
       " 'ammount',\n",
       " 'ammunition',\n",
       " 'amnesia',\n",
       " 'among',\n",
       " 'among_other',\n",
       " 'among_other_things',\n",
       " 'amongst',\n",
       " 'amongst_other',\n",
       " 'amongst_other_things',\n",
       " 'amoral',\n",
       " 'amount',\n",
       " 'amounted',\n",
       " 'amounting',\n",
       " 'amounts',\n",
       " 'amp',\n",
       " 'amp_amp',\n",
       " 'amp_amp_amp_amp',\n",
       " 'amp_e',\n",
       " 'amp_nbsp',\n",
       " 'amp_nbsp_amp_nbsp',\n",
       " 'amp_t',\n",
       " 'amped_up',\n",
       " 'amphetamine',\n",
       " 'amphetamines',\n",
       " 'ample',\n",
       " 'amplified',\n",
       " 'amplified_by',\n",
       " 'amplifies',\n",
       " 'amplify',\n",
       " 'amputated',\n",
       " 'amputation',\n",
       " 'amsterdam',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amusement_park',\n",
       " 'amusing',\n",
       " 'amy',\n",
       " 'an',\n",
       " 'an_a+',\n",
       " 'an_a-',\n",
       " 'an_abject_failure',\n",
       " 'an_abomination',\n",
       " 'an_abortion',\n",
       " 'an_above_average',\n",
       " 'an_absolute',\n",
       " 'an_absolute_mess',\n",
       " 'an_abstract',\n",
       " 'an_absurd_amount',\n",
       " 'an_abundance',\n",
       " 'an_abuser',\n",
       " 'an_abusive_alcoholic',\n",
       " 'an_abusive_father',\n",
       " 'an_abusive_household',\n",
       " 'an_abusive_relationship',\n",
       " 'an_abysmal',\n",
       " 'an_accident',\n",
       " 'an_accidental_death',\n",
       " 'an_accomplishment',\n",
       " 'an_accountant',\n",
       " 'an_achievement',\n",
       " 'an_acquaintance',\n",
       " 'an_actor',\n",
       " 'an_actress',\n",
       " 'an_actual',\n",
       " 'an_ad',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = len(vocab_list)\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_freq = 0\n",
    "for word in vocab_list:\n",
    "    total_freq += model.wv.vocab[word].count\n",
    "total_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_list =list(map(lambda s:re.sub(\"_\",\"_\",s),vocab_list))\n",
    "countvec = CountVectorizer(vocabulary =temp_list,analyzer=(lambda lst:list(map((lambda s:re.sub(\"_\",\"_\",s)),lst))),min_df=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf    = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PostsByWords = countvec.fit_transform(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-232-d58882cdd653>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-232-d58882cdd653>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    elif temp[i] > model.wv.vocab[vocab_list[i]].count:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Inspect a bug with creating PostsByWords\n",
    "temp = PostsByWords.sum(axis=0).tolist()[0]\n",
    "ctr =0\n",
    "for i in range(len(temp)):\n",
    "    if temp[i] < model.wv.vocab[vocab_list[i]].count:\n",
    "        print(\"<:  \"+vocab_list[i],temp[i]-model.wv.vocab[vocab_list[i]].count,temp[i],model.wv.vocab[vocab_list[i]].count)\n",
    "    elif temp[i] > model.wv.vocab[vocab_list[i]].count:\n",
    "        print(\">:  \"+vocab_list[i],temp[i]-model.wv.vocab[vocab_list[i]].count,temp[i],model.wv.vocab[vocab_list[i]].count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113499"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the magnitude of the error\n",
    "sum(temp)-sum(list(map(lambda i: model.wv.vocab[vocab_list[i]].count, range(len(vocab_list)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare PostsByWords values to correct values\n",
    "PostsByWords.sum(axis=0).tolist()[0]==list(map(lambda i: model.wv.vocab[vocab_list[i]].count, range(len(vocab_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_vocab = countvec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_arr = posts_arr.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(total_arr)-sum(list(map(lambda i: model.wv.vocab[vocab_list[i]].count, range(len(vocab_list)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "for i in range(len(posts)):\n",
    "    post = posts[i]\n",
    "    for j in range(len(post)):\n",
    "        word = post[j]\n",
    "        if word == \"amusement_park\":\n",
    "            ctr = ctr+1\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Clustering\n",
    "At this step we run and analyze the KMeans clustering algorithm \n",
    "implemented by sklearn on the word vectors we got from word2vec.\n",
    "\n",
    "The first step for this proccess is to extract the word vectors,\n",
    "and the words they correspond with from the model. We then tests \n",
    "different values of K to observe the effect of the number of centers on the fit of the model.\n",
    "After this we select a value of K to use to get the clusterings. \n",
    "We then save this result in the directory \"clustures\" with the name model_name + num_centers+\".pkl\", to save future computational time\n",
    "\n",
    "We then use the kmeans model to generate a list of dictionaries, where each dictionary corresponds to a cluster, and contains following fields:\n",
    "    'unique_words': The number of different unique words in the cluster\n",
    "    'total_freq'  : The total number of times one of the words in the cluster appeared in the corpus\n",
    "    'word_list'   : A list of words in the cluster, paired with how often they appeared in the cluster\n",
    "\n",
    "Finally we print a representation of this list to a csv, so that the clusters can be manuelly inspected.\n",
    "This representation includes the number of unique words in the cluster, the total frequency of words in the cluster, and the size_words_list most frequent words in the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract the word vectors\n",
    "vecs = []\n",
    "for word in vocab_list:\n",
    "    vecs.append(model.wv[word].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change array format into numpy array\n",
    "WordByFeatureMat = np.array(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the fit for different values of K\n",
    "test_points = [12]+ list(range(25,401,25))\n",
    "fit = []\n",
    "for point in test_points:\n",
    "    tempMeans = KMeans(n_clusters=point, random_state=42).fit(WordByFeatureMat)\n",
    "    fit.append(tempMeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the fit values for this model\n",
    "dataUtils.save_object(fit,'objects/',model_name+\"-fit\")\n",
    "dataUtils.save_object(test_points,'objects/',model_name+\"-testpoints\")\n",
    "del fit\n",
    "del test_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the fit and test point values\n",
    "fit         = dataUtils.load_object('objects/',model_name+\"-fit\")\n",
    "test_points = dataUtils.load_object('objects/',model_name+\"-testpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit1         = dataUtils.load_object('objects/',\"model1-fit\")\n",
    "test_points1 = dataUtils.load_object('objects/',\"model1-testpoints\")\n",
    "fit2         = dataUtils.load_object('objects/',\"model2-fit\")\n",
    "test_points2 = dataUtils.load_object('objects/',\"model2-testpoints\")\n",
    "fit3         = dataUtils.load_object('objects/',\"model3-fit\")\n",
    "test_points3 = dataUtils.load_object('objects/',\"model3-testpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# graph the fit for different values of K\n",
    "plt.plot(test_points1,fit1,'ro')\n",
    "plt.plot(test_points2,fit2,'bo')\n",
    "plt.plot(test_points3,fit3,'yo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the number of clusters\n",
    "num_clusters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize kmeans model\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(WordByFeatureMat)\n",
    "# Save the clusters directory\n",
    "dataUtils.save_object(kmeans,'clusters/',model_name+\"-\"+str(num_clusters))\n",
    "del kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load kmeans\n",
    "kmeans = dataUtils.load_object('clusters/',model_name+\"-\"+str(num_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = clusterUtils.makeClusteringObjects(model,kmeans,vocab_list,WordByFeatureMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# determine the total words in the clusters, and the total number of unique words in the clusters\n",
    "clusters_total_words  = 0\n",
    "clusters_unique_words = 0\n",
    "for cluster in clusters:\n",
    "    clusters_total_words  += cluster['total_freq']\n",
    "    clusters_unique_words += cluster['unique_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check that the total number of words in clusters matches the total\n",
    "clusters_total_words   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check that the number of unique words in clusters matches the total number of unique words\n",
    "clusters_unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print clusters\n",
    "\n",
    "Print clusters so we can analyze them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort all the words in the words list\n",
    "for cluster in clusters:\n",
    "    cluster[\"word_list\"].sort(key=lambda x:x[1],reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_words_list =100\n",
    "table =[]\n",
    "for i in range(len(clusters)):\n",
    "    row =[]\n",
    "    row.append(\"cluster \" + str(i+1))\n",
    "    row.append(clusters[i][\"total_freq\"])\n",
    "    row.append(clusters[i][\"unique_words\"])\n",
    "    for j in range(size_words_list):\n",
    "        try:\n",
    "            row.append(clusters[i][\"word_list\"][j])\n",
    "        except:\n",
    "            break\n",
    "    table.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('clusters-'+model_name+\"-\"+str(num_clusters)+'.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    [writer.writerow(r) for r in table]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Clusters Using MDS\n",
    "\n",
    "Produce a visualization of our clusters in a low dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the model to the clusters\n",
    "mds = MDS().fit(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_words= list(map(lambda x: x[0][0],map(lambda x: x[\"word_list\"],clusters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the embeddings\n",
    "embedding = mds.embedding_.tolist()\n",
    "x = list(map(lambda x:x[0],embedding))\n",
    "y = list(map(lambda x:x[1],embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the Graph with top words\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(x,y,'bo')\n",
    "for i in range(len(top_words)):\n",
    "    plt.annotate(top_words[i],(x[i],y[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def helper(indicies,points):\n",
    "    temp=[]\n",
    "    for i in indicies:\n",
    "        temp.append(points[i-1])\n",
    "    return temp\n",
    "\n",
    "bullying = [59,16,47]\n",
    "crime    = [31,73]\n",
    "depressive_feelings = [1,3,15,21,29,45,81,4,30]\n",
    "depressive_symptoms = [9,13,28] \n",
    "drug_abuse =[22,41,75]\n",
    "illness  = [35,87]\n",
    "failure = [68,89,90,14,19,26,52]\n",
    "prior_suicide = [27,56,79]\n",
    "psychological =[78,10,44,66,85]\n",
    "self_harm  = [5,17]\n",
    "self_image = [69,8,96]\n",
    "death_around = [76,93]\n",
    "suicidal_ideation =[36,38,57,58,97,6]\n",
    "identified =bullying+crime+depressive_feelings+depressive_symptoms\n",
    "identified = identified +drug_abuse+illness+failure+prior_suicide+psychological\n",
    "identified = identified +self_harm+self_image+death_around+suicidal_ideation\n",
    "other = [x for x in range(1,101) if x not in identified]\n",
    "all_categories = [bullying,crime,depressive_feelings,depressive_symptoms,\n",
    "                  drug_abuse,illness,failure,prior_suicide,psychological,\n",
    "                  self_harm, self_image,death_around,suicidal_ideation,other]\n",
    "colors = [\"black\" for x in all_categories]\n",
    "\n",
    "\"\"\"\n",
    "colors = [\"#ff66ff\",\"#6666ff\",\"#000099\",\n",
    "          \"#33cccc\",\"#00cc66\",\"#336600\",\n",
    "          \"#ccff33\",\"#cc6600\",\"#ff0000\",\n",
    "          \"#cc0066\",\"#ffccff\",\"#ccffff\",\"#00ff00\",\"#00ffff\"]\n",
    "\"\"\"\n",
    "#colors[0]=\"grey\"  # Bullying\n",
    "colors[2]=\"red\"   # Depressive Feelings\n",
    "#colors[4]=\"green\" # Drug Abuse\n",
    "#colors[6]=\"blue\"  # Poor performance\n",
    "colors[3]=\"magenta\" # Depressive symptoms\n",
    "colors[8]=\"cyan\" # Psychological \n",
    "\n",
    "\n",
    "# Plot the Graph with top words\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(len(all_categories)):\n",
    "    category = all_categories[i]\n",
    "    color = colors[i]\n",
    "    plt.scatter(helper(category,x),helper(category,y),color=color,s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare for regression :TODO\n",
    "\n",
    "At this step, we will initialize the matricies we need to run a linear regression algorithm.\n",
    "We will need to create a document term matrix, and a words by cluster matrix.\n",
    "We will first use sklearn's CountVectorizer function to create the document term matrix. \n",
    "We will create the words by cluster matrix by giving each word a one hot vector, with a\n",
    "one in the cluster number, and a 0 everywhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordDict ={}\n",
    "for sentence in posts:\n",
    "    for word in sentence:\n",
    "        if word in wordDict.keys() and word != \"[deleted]\":\n",
    "            wordDict[word] =1+wordDict[word]\n",
    "        else:\n",
    "            wordDict[word] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"cleantext\"]=df[\"cleantext\"].apply(lambda str : ' '.join(list(filter(lambda s: wordDict[s]>=10 ,str.split()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countvec = CountVectorizer(vocabulary =vocab_list,analyzer=(lambda lst:list(map((lambda s:re.sub(\"_\",\"_\",s)),lst))),min_df=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make Posts By Words Matrix\n",
    "PostsByWords = countvec.fit_transform(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusterWords = list(map(lambda x: list(map( lambda y: y[0] ,x[\"word_list\"])), clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make Clusters By Words Matrix\n",
    "ClustersByWords = countvec.fit_transform(clusterWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x30483 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 27668 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClustersByWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29272"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr = 0\n",
    "for cluster in clusters:\n",
    "    ctr += cluster[\"unique_words\"]\n",
    "ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27362117"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr = 0\n",
    "for cluster in clusters:\n",
    "    ctr += cluster[\"total_freq\"]\n",
    "ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WordsByCluster = ClustersByWords.transpose(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<131652x30483 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 14391138 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PostsByWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30483x100 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 27668 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordsByCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PostsByCluster = PostsByWords.dot(WordsByCluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<131652x100 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4239132 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PostsByCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131652, 100)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PostsByCluster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(PostsByCluster.sum(axis=0).tolist()[0])==sum(PostsByWords.sum(axis=0).tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run regression\n",
    "\n",
    "At this stage we run a regression on the normalized PostsByCluster matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize regression fields\n",
    "regression_fields = [\"ups\",\"downs\",\"score\",\"num_comments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean data\n",
    "for i in range(len(regression_data[1])):\n",
    "    if df[regression_fields[i]][1][i] == -np.inf:\n",
    "        print(i)\n",
    "df[regression_fields[1]].set_value()[6546]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize regression data\n",
    "regression_data=[None]*len(regression_fields)\n",
    "for i in range(len(regression_fields)):\n",
    "    regression_data[i]= (list(np.log(df[regression_fields[i]].apply(lambda x: x i ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize model\n",
    "from sklearn import linear_model\n",
    "regression_models =[None]*len(regression_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6546\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[regression_fields[1]].tolist()[6546]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131652"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PostsByCluster.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=0.1)\n",
    "model.fit(PostsByCluster,regression_data[0])\n",
    "#dataUtils.save_object(model,\"models/\",model_name+\"-\"+regression_fields[0]+\"-\"+\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-302-e1e9c0655143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregression_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPostsByCluster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdataUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"models/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mregression_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"regression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, check_input)\u001b[0m\n\u001b[1;32m    680\u001b[0m                              \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                              \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                              multi_output=True, y_numeric=True)\n\u001b[0m\u001b[1;32m    683\u001b[0m             y = check_array(y, order='F', copy=False, dtype=X.dtype.type,\n\u001b[1;32m    684\u001b[0m                             ensure_2d=False)\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n\u001b[0;32m--> 524\u001b[0;31m                         dtype=None)\n\u001b[0m\u001b[1;32m    525\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Create new regression\n",
    "for i in range(len(regression_fields)):\n",
    "    model = linear_model.Lasso(alpha=0.1)\n",
    "    model.fit(PostsByCluster,regression_data[i])\n",
    "    dataUtils.save_object(model,\"models/\",model_name+\"-\"+regression_fields[i]+\"-\"+\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataUtils.save_object(num_comments_model,\"models/\",model_name+\"-\"+\"num_comments\"+\"-\"+\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load old regression\n",
    "for i in range(len(regression_fields)):\n",
    "    model = dataUtils.load_object(\"models/\",model_name+\"-\"+regression_fields[i]+\"-\"+\"regression\")\n",
    "    regression_models[i]=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize regression coeficients\n",
    "regression_coefs = [None]*len(regression_fields)\n",
    "for i in range(len(regression_fields)):\n",
    "    regression_coefs[i]= regression_models[i].coef_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(regression_fields)):\n",
    "    field =regression_fields[i]\n",
    "    for j in range(len(clusters)):\n",
    "        clusters[j][field]  = regression_coefs[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regression_coef_locs=[None]*len(regression_fields)\n",
    "\n",
    "for i in range(len(regression_coef_locs)):\n",
    "    field =regression_fields[i]\n",
    "    regression_coef_locs[i]=[]\n",
    "    for j in range(len(clusters)):   \n",
    "        if clusters[j][field] != 0.0:\n",
    "            regression_coef_locs[i].append((clusters[j][field],j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "scores, pvalues = chi2(PostsByCluster, regression_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+000,   4.32233415e-255,   1.02799606e-231,\n",
       "         0.00000000e+000,   0.00000000e+000,   2.08522490e-230,\n",
       "         0.00000000e+000,   2.01588493e-223,   0.00000000e+000,\n",
       "         3.03133814e-281,   0.00000000e+000,   8.31016152e-145,\n",
       "         1.70690456e-134,   0.00000000e+000,   0.00000000e+000,\n",
       "         3.02952777e-148,   2.08778314e-168,   0.00000000e+000,\n",
       "         0.00000000e+000,   3.09224895e-083,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   1.19459913e-186,\n",
       "         0.00000000e+000,   6.62514770e-085,   0.00000000e+000,\n",
       "         0.00000000e+000,   2.60846191e-100,   0.00000000e+000,\n",
       "         1.03384663e-099,   2.52242558e-246,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   1.11458086e-249,\n",
       "         2.96598477e-244,   0.00000000e+000,   0.00000000e+000,\n",
       "         1.37954154e-233,   1.71129846e-253,   0.00000000e+000,\n",
       "         0.00000000e+000,   1.58880134e-186,   2.62718414e-165,\n",
       "         8.01814999e-182,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   3.92322140e-085,   3.62936353e-238,\n",
       "         9.90277711e-155,   0.00000000e+000,   0.00000000e+000,\n",
       "         7.94312605e-056,   0.00000000e+000,   3.84434099e-180,\n",
       "         0.00000000e+000,   1.09455700e-211,   2.25058738e-090,\n",
       "         4.19430707e-059,   0.00000000e+000,   0.00000000e+000,\n",
       "         1.27642100e-153,   1.27514367e-086,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         4.01968763e-121,   0.00000000e+000,   1.87277597e-212,\n",
       "         1.21421757e-255,   8.66438445e-309,   0.00000000e+000,\n",
       "         1.91875911e-308,   0.00000000e+000,   1.10002966e-300,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   3.49208913e-257,\n",
       "         0.00000000e+000,   3.37430605e-151,   3.20947051e-291,\n",
       "         5.00505513e-294,   6.10221815e-251,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   1.70240062e-281,\n",
       "         0.00000000e+000,   3.86446595e-204,   0.00000000e+000,\n",
       "         6.80101092e-049,   1.46732060e-193,   0.00000000e+000,\n",
       "         0.00000000e+000])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort all the words in the words list\n",
    "for cluster in clusters:\n",
    "    cluster[\"word_list\"].sort(key=lambda x:x[1],reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_words_list =100\n",
    "regression_tables= [None]*len(regression_fields)\n",
    "for i in range(len(regression_coef_locs)):\n",
    "    lst = sorted(regression_coef_locs[i],reverse=True)\n",
    "    regression_tables[i]=[]\n",
    "    for beta,k in lst:\n",
    "        row =[]\n",
    "        row.append(regression_fields[i]+\" \" + str(k+1))\n",
    "        row.append(beta)\n",
    "        row.append(regression_models[i].intercept_)\n",
    "        for j in range(size_words_list):\n",
    "            try:\n",
    "                row.append(clusters[k][\"word_list\"][j])\n",
    "            except:\n",
    "                break\n",
    "        regression_tables[i].append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "for i in range(len(regression_fields)):\n",
    "    with open('regression-'+regression_fields[i]+'-'+model_name+'.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        [writer.writerow(r) for r in regression_tables[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': 1000,\n",
       " 'normalize': False,\n",
       " 'positive': False,\n",
       " 'precompute': False,\n",
       " 'random_state': None,\n",
       " 'selection': 'cyclic',\n",
       " 'tol': 0.0001,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_models[0].get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0199343452998\n",
      "0.00751531271789\n",
      "0.0179348197833\n",
      "0.0113262322199\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(regression_models)):\n",
    "    model = regression_models[i]\n",
    "    y = regression_data[i]\n",
    "    print(model.score(PostsByCluster,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictArr =[{},{},{},{}]\n",
    "for i in range(len(regression_data)):\n",
    "    data = regression_data[i]\n",
    "    dictionary = dictArr[i]\n",
    "    for val in data:\n",
    "        if val in dictionary.keys():\n",
    "            dictionary[val] =1+dictionary[val]\n",
    "        else:\n",
    "            dictionary[val] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictArr[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEACAYAAABhzAtFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiKqSZGJiIhqUmQiIqKaFJmIiKjm/wMhHoLN59wuKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x166cd7c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(regression_data[0], normed=False, bins=208)\n",
    "plt.ylabel('Probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 3770,\n",
       "  1: 29507,\n",
       "  2: 22081,\n",
       "  3: 17948,\n",
       "  4: 9249,\n",
       "  5: 9247,\n",
       "  6: 7504,\n",
       "  7: 5743,\n",
       "  8: 4396,\n",
       "  9: 3461,\n",
       "  10: 2661,\n",
       "  11: 2070,\n",
       "  12: 1821,\n",
       "  13: 1455,\n",
       "  14: 1271,\n",
       "  15: 1038,\n",
       "  16: 909,\n",
       "  17: 749,\n",
       "  18: 680,\n",
       "  19: 575,\n",
       "  20: 523,\n",
       "  21: 448,\n",
       "  22: 396,\n",
       "  23: 355,\n",
       "  24: 333,\n",
       "  25: 278,\n",
       "  26: 258,\n",
       "  27: 224,\n",
       "  28: 205,\n",
       "  29: 174,\n",
       "  30: 151,\n",
       "  31: 134,\n",
       "  32: 119,\n",
       "  33: 132,\n",
       "  34: 84,\n",
       "  35: 87,\n",
       "  36: 83,\n",
       "  37: 81,\n",
       "  38: 83,\n",
       "  39: 67,\n",
       "  40: 55,\n",
       "  41: 64,\n",
       "  42: 54,\n",
       "  43: 57,\n",
       "  44: 51,\n",
       "  45: 50,\n",
       "  46: 46,\n",
       "  47: 32,\n",
       "  48: 44,\n",
       "  49: 38,\n",
       "  50: 34,\n",
       "  51: 28,\n",
       "  52: 28,\n",
       "  53: 32,\n",
       "  54: 23,\n",
       "  55: 30,\n",
       "  56: 19,\n",
       "  57: 18,\n",
       "  58: 27,\n",
       "  59: 26,\n",
       "  60: 15,\n",
       "  61: 24,\n",
       "  62: 17,\n",
       "  63: 10,\n",
       "  64: 23,\n",
       "  65: 20,\n",
       "  66: 14,\n",
       "  67: 23,\n",
       "  68: 13,\n",
       "  69: 5,\n",
       "  70: 11,\n",
       "  71: 9,\n",
       "  72: 11,\n",
       "  73: 10,\n",
       "  74: 10,\n",
       "  75: 7,\n",
       "  76: 10,\n",
       "  77: 5,\n",
       "  78: 12,\n",
       "  79: 8,\n",
       "  80: 7,\n",
       "  81: 8,\n",
       "  82: 8,\n",
       "  83: 9,\n",
       "  84: 10,\n",
       "  85: 5,\n",
       "  86: 4,\n",
       "  87: 4,\n",
       "  88: 10,\n",
       "  89: 3,\n",
       "  90: 3,\n",
       "  91: 3,\n",
       "  92: 7,\n",
       "  93: 5,\n",
       "  94: 4,\n",
       "  95: 6,\n",
       "  96: 6,\n",
       "  97: 9,\n",
       "  98: 5,\n",
       "  99: 1,\n",
       "  100: 3,\n",
       "  101: 3,\n",
       "  102: 2,\n",
       "  103: 2,\n",
       "  104: 4,\n",
       "  105: 1,\n",
       "  106: 3,\n",
       "  107: 4,\n",
       "  108: 3,\n",
       "  109: 4,\n",
       "  110: 1,\n",
       "  111: 6,\n",
       "  112: 3,\n",
       "  113: 2,\n",
       "  115: 2,\n",
       "  116: 3,\n",
       "  117: 2,\n",
       "  118: 4,\n",
       "  119: 3,\n",
       "  120: 1,\n",
       "  121: 2,\n",
       "  122: 2,\n",
       "  123: 4,\n",
       "  124: 3,\n",
       "  125: 4,\n",
       "  127: 1,\n",
       "  128: 2,\n",
       "  129: 1,\n",
       "  130: 2,\n",
       "  131: 1,\n",
       "  132: 3,\n",
       "  133: 1,\n",
       "  134: 1,\n",
       "  136: 2,\n",
       "  137: 1,\n",
       "  139: 1,\n",
       "  140: 1,\n",
       "  141: 1,\n",
       "  142: 1,\n",
       "  143: 1,\n",
       "  144: 2,\n",
       "  146: 1,\n",
       "  148: 2,\n",
       "  150: 1,\n",
       "  152: 1,\n",
       "  153: 1,\n",
       "  155: 1,\n",
       "  156: 1,\n",
       "  157: 1,\n",
       "  158: 2,\n",
       "  160: 2,\n",
       "  163: 2,\n",
       "  165: 1,\n",
       "  167: 1,\n",
       "  168: 1,\n",
       "  170: 1,\n",
       "  171: 1,\n",
       "  172: 1,\n",
       "  173: 1,\n",
       "  174: 2,\n",
       "  175: 2,\n",
       "  176: 1,\n",
       "  179: 2,\n",
       "  183: 2,\n",
       "  188: 1,\n",
       "  194: 1,\n",
       "  196: 1,\n",
       "  199: 1,\n",
       "  200: 1,\n",
       "  202: 1,\n",
       "  208: 1,\n",
       "  211: 1,\n",
       "  213: 1,\n",
       "  215: 1,\n",
       "  216: 2,\n",
       "  225: 1,\n",
       "  226: 1,\n",
       "  227: 1,\n",
       "  230: 2,\n",
       "  231: 1,\n",
       "  235: 1,\n",
       "  236: 1,\n",
       "  239: 1,\n",
       "  241: 2,\n",
       "  246: 1,\n",
       "  250: 1,\n",
       "  252: 1,\n",
       "  262: 1,\n",
       "  270: 1,\n",
       "  272: 1,\n",
       "  287: 1,\n",
       "  294: 1,\n",
       "  309: 1,\n",
       "  310: 1,\n",
       "  311: 1,\n",
       "  316: 1,\n",
       "  319: 1,\n",
       "  320: 1,\n",
       "  339: 1,\n",
       "  352: 1,\n",
       "  401: 1,\n",
       "  409: 2,\n",
       "  483: 1,\n",
       "  488: 1,\n",
       "  504: 1,\n",
       "  533: 1,\n",
       "  670: 1,\n",
       "  808: 1},\n",
       " {-1: 1,\n",
       "  0: 117959,\n",
       "  1: 5210,\n",
       "  2: 3662,\n",
       "  3: 2128,\n",
       "  4: 1084,\n",
       "  5: 575,\n",
       "  6: 329,\n",
       "  7: 206,\n",
       "  8: 119,\n",
       "  9: 76,\n",
       "  10: 61,\n",
       "  11: 39,\n",
       "  12: 41,\n",
       "  13: 22,\n",
       "  14: 16,\n",
       "  15: 18,\n",
       "  16: 16,\n",
       "  17: 9,\n",
       "  18: 8,\n",
       "  19: 16,\n",
       "  20: 2,\n",
       "  21: 7,\n",
       "  22: 5,\n",
       "  23: 6,\n",
       "  24: 2,\n",
       "  25: 2,\n",
       "  26: 4,\n",
       "  27: 4,\n",
       "  28: 3,\n",
       "  29: 3,\n",
       "  31: 1,\n",
       "  32: 1,\n",
       "  34: 1,\n",
       "  36: 1,\n",
       "  37: 2,\n",
       "  38: 1,\n",
       "  40: 2,\n",
       "  42: 1,\n",
       "  47: 1,\n",
       "  48: 1,\n",
       "  49: 1,\n",
       "  50: 1,\n",
       "  51: 2,\n",
       "  52: 1,\n",
       "  73: 1,\n",
       "  102: 1},\n",
       " {0: 4459,\n",
       "  1: 30259,\n",
       "  2: 22674,\n",
       "  3: 18375,\n",
       "  4: 8913,\n",
       "  5: 9192,\n",
       "  6: 7418,\n",
       "  7: 5551,\n",
       "  8: 4189,\n",
       "  9: 3325,\n",
       "  10: 2509,\n",
       "  11: 1921,\n",
       "  12: 1730,\n",
       "  13: 1371,\n",
       "  14: 1158,\n",
       "  15: 958,\n",
       "  16: 834,\n",
       "  17: 723,\n",
       "  18: 639,\n",
       "  19: 537,\n",
       "  20: 460,\n",
       "  21: 439,\n",
       "  22: 333,\n",
       "  23: 304,\n",
       "  24: 285,\n",
       "  25: 242,\n",
       "  26: 211,\n",
       "  27: 199,\n",
       "  28: 180,\n",
       "  29: 147,\n",
       "  30: 150,\n",
       "  31: 122,\n",
       "  32: 109,\n",
       "  33: 106,\n",
       "  34: 82,\n",
       "  35: 81,\n",
       "  36: 75,\n",
       "  37: 68,\n",
       "  38: 80,\n",
       "  39: 55,\n",
       "  40: 48,\n",
       "  41: 55,\n",
       "  42: 50,\n",
       "  43: 59,\n",
       "  44: 51,\n",
       "  45: 43,\n",
       "  46: 43,\n",
       "  47: 31,\n",
       "  48: 35,\n",
       "  49: 42,\n",
       "  50: 32,\n",
       "  51: 27,\n",
       "  52: 21,\n",
       "  53: 30,\n",
       "  54: 14,\n",
       "  55: 27,\n",
       "  56: 22,\n",
       "  57: 26,\n",
       "  58: 28,\n",
       "  59: 19,\n",
       "  60: 10,\n",
       "  61: 22,\n",
       "  62: 16,\n",
       "  63: 15,\n",
       "  64: 17,\n",
       "  65: 16,\n",
       "  66: 15,\n",
       "  67: 15,\n",
       "  68: 7,\n",
       "  69: 4,\n",
       "  70: 9,\n",
       "  71: 9,\n",
       "  72: 9,\n",
       "  73: 8,\n",
       "  74: 9,\n",
       "  75: 9,\n",
       "  76: 9,\n",
       "  77: 4,\n",
       "  78: 10,\n",
       "  79: 7,\n",
       "  80: 6,\n",
       "  81: 5,\n",
       "  82: 7,\n",
       "  83: 10,\n",
       "  84: 7,\n",
       "  85: 7,\n",
       "  86: 5,\n",
       "  87: 4,\n",
       "  88: 8,\n",
       "  89: 4,\n",
       "  90: 4,\n",
       "  91: 2,\n",
       "  92: 7,\n",
       "  93: 5,\n",
       "  94: 4,\n",
       "  95: 6,\n",
       "  96: 4,\n",
       "  97: 7,\n",
       "  98: 5,\n",
       "  100: 4,\n",
       "  101: 4,\n",
       "  102: 2,\n",
       "  103: 3,\n",
       "  104: 3,\n",
       "  105: 2,\n",
       "  106: 3,\n",
       "  107: 5,\n",
       "  108: 2,\n",
       "  109: 2,\n",
       "  111: 5,\n",
       "  112: 1,\n",
       "  113: 2,\n",
       "  114: 2,\n",
       "  115: 2,\n",
       "  116: 4,\n",
       "  118: 5,\n",
       "  119: 3,\n",
       "  120: 1,\n",
       "  121: 4,\n",
       "  122: 3,\n",
       "  123: 1,\n",
       "  124: 3,\n",
       "  125: 2,\n",
       "  128: 1,\n",
       "  129: 1,\n",
       "  130: 2,\n",
       "  131: 1,\n",
       "  132: 3,\n",
       "  134: 1,\n",
       "  139: 1,\n",
       "  140: 1,\n",
       "  142: 2,\n",
       "  143: 1,\n",
       "  144: 1,\n",
       "  146: 2,\n",
       "  147: 2,\n",
       "  148: 1,\n",
       "  150: 1,\n",
       "  151: 2,\n",
       "  152: 2,\n",
       "  153: 1,\n",
       "  154: 1,\n",
       "  155: 1,\n",
       "  158: 2,\n",
       "  159: 1,\n",
       "  160: 2,\n",
       "  161: 1,\n",
       "  163: 2,\n",
       "  165: 2,\n",
       "  170: 1,\n",
       "  171: 1,\n",
       "  173: 1,\n",
       "  174: 2,\n",
       "  175: 1,\n",
       "  176: 2,\n",
       "  179: 2,\n",
       "  182: 1,\n",
       "  188: 1,\n",
       "  189: 3,\n",
       "  196: 2,\n",
       "  199: 1,\n",
       "  210: 1,\n",
       "  211: 1,\n",
       "  215: 1,\n",
       "  225: 1,\n",
       "  227: 1,\n",
       "  230: 2,\n",
       "  232: 1,\n",
       "  235: 1,\n",
       "  236: 1,\n",
       "  239: 1,\n",
       "  241: 1,\n",
       "  246: 1,\n",
       "  252: 1,\n",
       "  260: 1,\n",
       "  262: 1,\n",
       "  266: 1,\n",
       "  270: 1,\n",
       "  272: 1,\n",
       "  287: 1,\n",
       "  294: 1,\n",
       "  303: 1,\n",
       "  309: 1,\n",
       "  316: 1,\n",
       "  319: 1,\n",
       "  320: 1,\n",
       "  364: 1,\n",
       "  409: 2,\n",
       "  483: 1,\n",
       "  488: 1,\n",
       "  504: 1,\n",
       "  533: 1,\n",
       "  568: 1,\n",
       "  808: 1},\n",
       " {-3: 1,\n",
       "  -1: 3,\n",
       "  0: 14796,\n",
       "  1: 20467,\n",
       "  2: 18720,\n",
       "  3: 15280,\n",
       "  4: 11146,\n",
       "  5: 9009,\n",
       "  6: 6784,\n",
       "  7: 5594,\n",
       "  8: 4421,\n",
       "  9: 3577,\n",
       "  10: 3017,\n",
       "  11: 2540,\n",
       "  12: 2106,\n",
       "  13: 1775,\n",
       "  14: 1454,\n",
       "  15: 1279,\n",
       "  16: 1121,\n",
       "  17: 915,\n",
       "  18: 800,\n",
       "  19: 720,\n",
       "  20: 547,\n",
       "  21: 554,\n",
       "  22: 445,\n",
       "  23: 412,\n",
       "  24: 344,\n",
       "  25: 316,\n",
       "  26: 316,\n",
       "  27: 254,\n",
       "  28: 231,\n",
       "  29: 204,\n",
       "  30: 189,\n",
       "  31: 158,\n",
       "  32: 147,\n",
       "  33: 132,\n",
       "  34: 127,\n",
       "  35: 128,\n",
       "  36: 109,\n",
       "  37: 98,\n",
       "  38: 83,\n",
       "  39: 90,\n",
       "  40: 87,\n",
       "  41: 59,\n",
       "  42: 60,\n",
       "  43: 57,\n",
       "  44: 59,\n",
       "  45: 61,\n",
       "  46: 44,\n",
       "  47: 53,\n",
       "  48: 23,\n",
       "  49: 35,\n",
       "  50: 40,\n",
       "  51: 32,\n",
       "  52: 31,\n",
       "  53: 39,\n",
       "  54: 40,\n",
       "  55: 17,\n",
       "  56: 20,\n",
       "  57: 22,\n",
       "  58: 16,\n",
       "  59: 23,\n",
       "  60: 19,\n",
       "  61: 13,\n",
       "  62: 13,\n",
       "  63: 12,\n",
       "  64: 9,\n",
       "  65: 12,\n",
       "  66: 11,\n",
       "  67: 17,\n",
       "  68: 9,\n",
       "  69: 12,\n",
       "  70: 12,\n",
       "  71: 12,\n",
       "  72: 8,\n",
       "  73: 11,\n",
       "  74: 6,\n",
       "  75: 5,\n",
       "  76: 11,\n",
       "  77: 8,\n",
       "  78: 10,\n",
       "  79: 4,\n",
       "  80: 8,\n",
       "  81: 2,\n",
       "  82: 5,\n",
       "  83: 5,\n",
       "  84: 6,\n",
       "  85: 6,\n",
       "  86: 2,\n",
       "  87: 5,\n",
       "  88: 9,\n",
       "  89: 5,\n",
       "  90: 6,\n",
       "  91: 2,\n",
       "  92: 7,\n",
       "  93: 2,\n",
       "  94: 2,\n",
       "  95: 1,\n",
       "  96: 6,\n",
       "  97: 7,\n",
       "  98: 3,\n",
       "  99: 2,\n",
       "  100: 5,\n",
       "  102: 1,\n",
       "  103: 4,\n",
       "  104: 2,\n",
       "  105: 1,\n",
       "  106: 2,\n",
       "  107: 2,\n",
       "  109: 11,\n",
       "  110: 3,\n",
       "  111: 5,\n",
       "  112: 4,\n",
       "  114: 1,\n",
       "  115: 1,\n",
       "  116: 2,\n",
       "  117: 1,\n",
       "  118: 3,\n",
       "  119: 3,\n",
       "  120: 6,\n",
       "  121: 1,\n",
       "  122: 4,\n",
       "  123: 1,\n",
       "  125: 1,\n",
       "  126: 2,\n",
       "  127: 1,\n",
       "  129: 1,\n",
       "  132: 1,\n",
       "  133: 4,\n",
       "  134: 1,\n",
       "  135: 3,\n",
       "  139: 1,\n",
       "  141: 2,\n",
       "  142: 1,\n",
       "  145: 1,\n",
       "  149: 1,\n",
       "  150: 1,\n",
       "  152: 1,\n",
       "  154: 1,\n",
       "  155: 2,\n",
       "  157: 1,\n",
       "  159: 2,\n",
       "  160: 1,\n",
       "  161: 1,\n",
       "  164: 1,\n",
       "  165: 1,\n",
       "  173: 1,\n",
       "  174: 1,\n",
       "  177: 1,\n",
       "  179: 1,\n",
       "  183: 1,\n",
       "  194: 1,\n",
       "  197: 1,\n",
       "  199: 1,\n",
       "  201: 1,\n",
       "  215: 1,\n",
       "  221: 1,\n",
       "  230: 1,\n",
       "  236: 1,\n",
       "  244: 1,\n",
       "  249: 1,\n",
       "  267: 1,\n",
       "  269: 1,\n",
       "  274: 1,\n",
       "  275: 1,\n",
       "  285: 1,\n",
       "  326: 1,\n",
       "  342: 1,\n",
       "  346: 1,\n",
       "  423: 1,\n",
       "  473: 1}]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = regression_models[0]\n",
    "predicted = model.predict(PostsByCluster)\n",
    "actual = regression_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.333462384305411,\n",
       " 5.851832354118098,\n",
       " 5.193253407198732,\n",
       " 5.224234624605756,\n",
       " 5.301955296979567,\n",
       " 5.157581488591974,\n",
       " 5.56006882518124,\n",
       " 5.21841892330674,\n",
       " 5.207998046916952,\n",
       " 5.550370227184938,\n",
       " 5.133234067583829,\n",
       " 5.931167484727342,\n",
       " 6.79775427266587,\n",
       " 5.443081707340772,\n",
       " 5.31544403141666,\n",
       " 5.198482304564619,\n",
       " 5.406037190580671,\n",
       " 6.148524125148278,\n",
       " 5.198482304564619,\n",
       " 5.198482304564619,\n",
       " 5.8520716057277635,\n",
       " 5.280359769755162,\n",
       " 5.091599151596383,\n",
       " 5.231805104988875,\n",
       " 5.905401843861306,\n",
       " 5.145650155039495,\n",
       " 5.248672079092701,\n",
       " 5.235994793773794,\n",
       " 5.286862532141318,\n",
       " 5.199148186992409,\n",
       " 5.276236676360208,\n",
       " 5.056708749920821,\n",
       " 5.169576200093123,\n",
       " 5.198243052954955,\n",
       " 5.194000333755168,\n",
       " 5.608350763865901,\n",
       " 5.31598551558105,\n",
       " 5.188846936407454,\n",
       " 6.233111350438554,\n",
       " 5.575127287633948,\n",
       " 5.212345877114593,\n",
       " 5.2128741343900495,\n",
       " 5.107052674232494,\n",
       " 5.555736925514784,\n",
       " 5.911896748413011,\n",
       " 5.198482304564619,\n",
       " 5.1871137225424695,\n",
       " 5.179211568250288,\n",
       " 5.5153021449487,\n",
       " 5.099975896107599,\n",
       " 7.013640854814961,\n",
       " 5.198482304564619,\n",
       " 6.130349973483183,\n",
       " 5.209037227630251,\n",
       " 5.24705849103255,\n",
       " 5.276858475676961,\n",
       " 5.939772949223811,\n",
       " 6.342307920087407,\n",
       " 5.159821206131125,\n",
       " 5.159765645888453,\n",
       " 5.157531531209658,\n",
       " 5.179211568250288,\n",
       " 5.258716078720491,\n",
       " 5.258716078720491,\n",
       " 5.217513789269286,\n",
       " 5.153127506452861,\n",
       " 5.169166167450755,\n",
       " 5.159940831935957,\n",
       " 5.176967240732821,\n",
       " 5.960739471626629,\n",
       " 5.271448666023594,\n",
       " 5.262842985448776,\n",
       " 5.156542307878675,\n",
       " 5.062975791121751,\n",
       " 5.143747667273892,\n",
       " 5.653516145927171,\n",
       " 5.570301266337469,\n",
       " 5.089028901689683,\n",
       " 5.8326812436086,\n",
       " 7.764530040973676,\n",
       " 5.22769541404941,\n",
       " 6.130349973483183,\n",
       " 6.630854412237585,\n",
       " 5.184364965598003,\n",
       " 5.893474975179275,\n",
       " 5.15667014708408,\n",
       " 5.209156853435084,\n",
       " 5.188846936407454,\n",
       " 7.0876055970111285,\n",
       " 6.664030256533261,\n",
       " 5.169166167450755,\n",
       " 6.5413045962779055,\n",
       " 6.604322745243127,\n",
       " 6.17852681426901,\n",
       " 5.964709686872054,\n",
       " 5.336300489166565,\n",
       " 5.216724057459463,\n",
       " 5.156009269200709,\n",
       " 5.437174401042974,\n",
       " 5.039940960954646,\n",
       " 5.914990191771794,\n",
       " 6.493678183587201,\n",
       " 5.22142188829708,\n",
       " 6.59945826241235,\n",
       " 5.5153021449487,\n",
       " 5.9132417903650865,\n",
       " 6.5756676743562785,\n",
       " 5.861962823670352,\n",
       " 5.354718759498167,\n",
       " 5.512280294327228,\n",
       " 5.249587024022851,\n",
       " 5.198482304564619,\n",
       " 5.198482304564619,\n",
       " 5.198482304564619,\n",
       " 5.198482304564619,\n",
       " 5.219492165959427,\n",
       " 6.159136452149847,\n",
       " 6.484305412027373,\n",
       " 5.188846936407454,\n",
       " 6.149909715463306,\n",
       " 5.181404462853426,\n",
       " 6.496434170204366,\n",
       " 5.934099973378063,\n",
       " 5.100249707183106,\n",
       " 5.188846936407454,\n",
       " 5.149411360539376,\n",
       " 5.207998046916952,\n",
       " 5.574917837674666,\n",
       " 5.175417630667374,\n",
       " 5.213908705125031,\n",
       " 5.221989985805318,\n",
       " 5.208193831505983,\n",
       " 5.282333907042246,\n",
       " 5.167331872575655,\n",
       " 5.264945157478491,\n",
       " 5.308497221777949,\n",
       " 5.496702835172634,\n",
       " 5.340019718723201,\n",
       " 5.308327605882247,\n",
       " 6.180792012652791,\n",
       " 5.1983626787597865,\n",
       " 5.5153021449487,\n",
       " 5.584618583097685,\n",
       " 5.6696685000081475,\n",
       " 5.188846936407454,\n",
       " 5.1983626787597865,\n",
       " 5.122757693775536,\n",
       " 5.4344930153429605,\n",
       " 5.726811819684611,\n",
       " 5.188846936407454,\n",
       " 5.245153929230587,\n",
       " 5.386355649250311,\n",
       " 5.7734500029384135,\n",
       " 5.286974300111699,\n",
       " 5.393011432005808,\n",
       " 5.482034614513225,\n",
       " 5.580280684981663,\n",
       " 6.047254047430951,\n",
       " 5.85400056815571,\n",
       " 5.5934344841021275,\n",
       " 8.588710055136605,\n",
       " 5.483648988931358,\n",
       " 5.217394163464453,\n",
       " 5.315290761457113,\n",
       " 5.175027507216935,\n",
       " 5.345436751378945,\n",
       " 5.188846936407454,\n",
       " 5.428691734914957,\n",
       " 5.136090649806089,\n",
       " 5.174751748239583,\n",
       " 5.166297301840673,\n",
       " 5.188846936407454,\n",
       " 6.353896697561116,\n",
       " 5.169721277567007,\n",
       " 5.887501992838344,\n",
       " 5.174751748239583,\n",
       " 5.735367629708696,\n",
       " 5.13977599238221,\n",
       " 5.125570834169617,\n",
       " 5.217013063125255,\n",
       " 5.29021433060454,\n",
       " 5.185448412350172,\n",
       " 5.185448412350172,\n",
       " 5.198482304564619,\n",
       " 5.114155577699803,\n",
       " 5.925649435691713,\n",
       " 5.721947347364219,\n",
       " 8.230807025020562,\n",
       " 5.242177174540996,\n",
       " 5.282731580911912,\n",
       " 5.236019426360951,\n",
       " 5.340080113563045,\n",
       " 5.070539722599941,\n",
       " 5.191820753961405,\n",
       " 5.162480088162453,\n",
       " 5.263415310729851,\n",
       " 5.307067031011569,\n",
       " 5.14048464072796,\n",
       " 5.188846936407454,\n",
       " 5.310934757481884,\n",
       " 5.47712147404933,\n",
       " 5.162334368984981,\n",
       " 5.328200417888412,\n",
       " 5.289428822371917,\n",
       " 5.207998046916952,\n",
       " 5.116626498799525,\n",
       " 5.156661933683507,\n",
       " 5.175932669997838,\n",
       " 6.019898731884086,\n",
       " 5.449195062830199,\n",
       " 5.261328285050495,\n",
       " 5.188846936407454,\n",
       " 5.175394354572068,\n",
       " 5.315619169467177,\n",
       " 5.495911782829537,\n",
       " 5.198482304564619,\n",
       " 6.827752369255792,\n",
       " 5.3175304789962645,\n",
       " 5.401660129538726,\n",
       " 5.5153021449487,\n",
       " 5.175932669997838,\n",
       " 5.87915021689429,\n",
       " 6.785246774956376,\n",
       " 5.661591834631796,\n",
       " 5.198482304564619,\n",
       " 5.416012367506386,\n",
       " 5.142944006865818,\n",
       " 5.15521991209807,\n",
       " 5.21617920576759,\n",
       " 5.303128074157528,\n",
       " 5.146351161423673,\n",
       " 6.4252483427955465,\n",
       " 5.2127414116223,\n",
       " 6.515536945875889,\n",
       " 7.23755777446196,\n",
       " 5.13977599238221,\n",
       " 5.822227745073869,\n",
       " 6.581358261833204,\n",
       " 5.096144179380832,\n",
       " 5.160855776866107,\n",
       " 5.130915101659628,\n",
       " 5.240479103646487,\n",
       " 5.505547150986702,\n",
       " 5.32716584715343,\n",
       " 5.42997016723792,\n",
       " 5.126064012896576,\n",
       " 5.312358031143881,\n",
       " 5.3175304789962645,\n",
       " 5.20854430353991,\n",
       " 5.48692429775266,\n",
       " 5.198482304564619,\n",
       " 5.149411360539376,\n",
       " 5.198482304564619,\n",
       " 5.227815039854241,\n",
       " 5.295860423322658,\n",
       " 5.150305463778792,\n",
       " 5.154422216144357,\n",
       " 5.350673528394129,\n",
       " 5.2493933874879355,\n",
       " 5.140670095621626,\n",
       " 5.169576200093123,\n",
       " 5.198482304564619,\n",
       " 5.193880707950337,\n",
       " 8.018021514540838,\n",
       " 5.123818989728959,\n",
       " 5.242057548736164,\n",
       " 5.188727310602621,\n",
       " 5.774309776389789,\n",
       " 5.629369627286962,\n",
       " 5.179927296386044,\n",
       " 5.188846936407454,\n",
       " 5.175932669997838,\n",
       " 5.198482304564619,\n",
       " 5.111665207036031,\n",
       " 5.46871074149913,\n",
       " 5.127745771061697,\n",
       " 5.194000333755168,\n",
       " 5.854560199132983,\n",
       " 5.3564095080157985,\n",
       " 5.8895840949369385,\n",
       " 5.13977599238221,\n",
       " 5.238007727516049,\n",
       " 5.198482304564619,\n",
       " 5.201936031522845,\n",
       " 5.340499761256204,\n",
       " 5.32716584715343,\n",
       " 5.203470542239771,\n",
       " 5.150077242967167,\n",
       " 5.592171071084737,\n",
       " 5.203785863903153,\n",
       " 5.48015277829653,\n",
       " 5.127755829212011,\n",
       " 6.817704077067438,\n",
       " 5.9417577409780895,\n",
       " 5.195749662935127,\n",
       " 5.205881286401505,\n",
       " 5.08302904002612,\n",
       " 5.330564371210712,\n",
       " 5.555856551319617,\n",
       " 5.159821206131125,\n",
       " 5.182305011609071,\n",
       " 5.648020506527324,\n",
       " 5.179211568250288,\n",
       " 6.007289089081073,\n",
       " 5.120505256067879,\n",
       " 5.3053356788113755,\n",
       " 5.075099553347882,\n",
       " 5.156771662813706,\n",
       " 5.319031623712804,\n",
       " 5.314658523184037,\n",
       " 5.320532914074844,\n",
       " 5.761034715382083,\n",
       " 5.58160111282454,\n",
       " 5.198482304564619,\n",
       " 6.8223611214701565,\n",
       " 5.974865457190839,\n",
       " 5.132091242015373,\n",
       " 5.99039051647374,\n",
       " 5.357713243277075,\n",
       " 5.200461021048693,\n",
       " 5.224473876215421,\n",
       " 5.39293427233796,\n",
       " 5.169576200093123,\n",
       " 5.198482304564619,\n",
       " 5.138197722591472,\n",
       " 5.981457446765843,\n",
       " 5.262800914753603,\n",
       " 5.8227554686139,\n",
       " 5.199521485277918,\n",
       " 5.556949064565533,\n",
       " 5.5232396882067585,\n",
       " 6.644902747695651,\n",
       " 5.312048755611631,\n",
       " 6.772893829074439,\n",
       " 5.046855670276467,\n",
       " 5.1990285611875775,\n",
       " 5.61693667277206,\n",
       " 5.841232222603291,\n",
       " 7.2001603010793,\n",
       " 5.516686822440745,\n",
       " 5.1839942030436434,\n",
       " 5.179739825525744,\n",
       " 5.118648718330301,\n",
       " 5.02944007052797,\n",
       " 5.318132589935114,\n",
       " 5.413820312818944,\n",
       " 5.583598429487555,\n",
       " 5.2986830901898845,\n",
       " 5.18976649131592,\n",
       " 5.207998046916952,\n",
       " 5.286742906336485,\n",
       " 5.188727310602621,\n",
       " 5.188727310602621,\n",
       " 5.242055766954148,\n",
       " 6.420842111043713,\n",
       " 5.188846936407454,\n",
       " 5.198482304564619,\n",
       " 5.190482183893055,\n",
       " 5.399443739585247,\n",
       " 5.267942815407032,\n",
       " 5.188846936407454,\n",
       " 5.530681384424645,\n",
       " 5.169609554969547,\n",
       " 5.165955193657742,\n",
       " 5.173138160179431,\n",
       " 5.210774045479966,\n",
       " 5.350381364148,\n",
       " 5.803215880861285,\n",
       " 5.409198733547245,\n",
       " 5.348468675720492,\n",
       " 5.179211568250288,\n",
       " 5.389566909152019,\n",
       " 6.495227028848259,\n",
       " 5.262113793283118,\n",
       " 5.111665207036031,\n",
       " 5.121399359307295,\n",
       " 5.9547860512393145,\n",
       " 5.579395323778237,\n",
       " 5.402356571928004,\n",
       " 6.596736327555641,\n",
       " 5.345975066804716,\n",
       " 5.198482304564619,\n",
       " 5.159940831935957,\n",
       " 6.843494164721548,\n",
       " 5.726001365597167,\n",
       " 6.159256077954679,\n",
       " 5.19586928873996,\n",
       " 5.158446869680637,\n",
       " 5.2456301619309595,\n",
       " 5.399905256248292,\n",
       " 5.942815786626762,\n",
       " 5.29483850412979,\n",
       " 5.42151088901801,\n",
       " 5.452291492584772,\n",
       " 5.194545465081567,\n",
       " 5.407589912532099,\n",
       " 5.900942023850601,\n",
       " 5.843630377273844,\n",
       " 6.026745404367352,\n",
       " 5.381799445703606,\n",
       " 6.536900265722015,\n",
       " 6.400540315611739,\n",
       " 5.150833721054248,\n",
       " 5.196553646301974,\n",
       " 5.260233472542174,\n",
       " 5.156661933683507,\n",
       " 5.4182066248177385,\n",
       " 5.867894941967625,\n",
       " 5.5153021449487,\n",
       " 5.691746767357889,\n",
       " 5.401614595670995,\n",
       " 5.340080113563045,\n",
       " 6.17377032649942,\n",
       " 5.169576200093123,\n",
       " 5.188846936407454,\n",
       " 5.119693339436862,\n",
       " 5.130020998420213,\n",
       " 5.336681589505763,\n",
       " 5.958259048112343,\n",
       " 5.904928809978801,\n",
       " 5.205638703572969,\n",
       " 5.144257189539991,\n",
       " 5.311702266367004,\n",
       " 5.140670095621626,\n",
       " 5.902789637531302,\n",
       " 5.863606924649246,\n",
       " 5.486396040477204,\n",
       " 5.176847614927988,\n",
       " 5.791455921721703,\n",
       " 5.219765974621205,\n",
       " 5.410373271001126,\n",
       " 5.13977599238221,\n",
       " 5.207998046916952,\n",
       " 5.622275145000288,\n",
       " 5.14107872709225,\n",
       " 5.198482304564619,\n",
       " 5.260522717900421,\n",
       " 5.212610580393309,\n",
       " 5.150305463778792,\n",
       " 5.150305463778792,\n",
       " 5.199440351238538,\n",
       " 5.637287326774582,\n",
       " 5.207088689302298,\n",
       " 5.304616212586649,\n",
       " 5.330508586349185,\n",
       " 7.180452776849986,\n",
       " 5.69066288069365,\n",
       " 5.090892780291507,\n",
       " 5.216487076368755,\n",
       " 5.150191425289454,\n",
       " 5.626740955380539,\n",
       " 5.81544338116887,\n",
       " 5.09280654947478,\n",
       " 5.202719249490987,\n",
       " 6.024810715629688,\n",
       " 5.30588420595329,\n",
       " 5.585729464246545,\n",
       " 5.198482304564619,\n",
       " 5.943137749339894,\n",
       " 5.280947650754566,\n",
       " 5.336935136480528,\n",
       " 5.425445400777328,\n",
       " 5.176967240732821,\n",
       " 5.522093894285398,\n",
       " 6.450055079861773,\n",
       " 5.794259396784771,\n",
       " 6.165262466566967,\n",
       " 5.194022484553914,\n",
       " 5.239401895330907,\n",
       " 5.871222716237262,\n",
       " 5.32716584715343,\n",
       " 5.418112364960728,\n",
       " 5.225586921371531,\n",
       " 5.280459336642542,\n",
       " 5.320809377248714,\n",
       " 5.280832634928051,\n",
       " 5.676982996400544,\n",
       " 5.217513789269286,\n",
       " 5.198482304564619,\n",
       " 5.169166167450755,\n",
       " 5.179739825525744,\n",
       " 5.373865065950001,\n",
       " 5.115132536544206,\n",
       " 6.077879104228915,\n",
       " 6.666187561345451,\n",
       " 5.404819758654277,\n",
       " 5.207998046916952,\n",
       " 5.018912384407882,\n",
       " 5.120659717281342,\n",
       " 5.140140437174426,\n",
       " 5.100995268143884,\n",
       " 5.21841892330674,\n",
       " 5.272717709776397,\n",
       " 6.6720757205641075,\n",
       " 5.128489929226811,\n",
       " 5.147760665541143,\n",
       " 6.392233252703926,\n",
       " 5.207998046916952,\n",
       " 5.194022484553914,\n",
       " 5.123877132247883,\n",
       " 6.278370992998735,\n",
       " 5.198482304564619,\n",
       " 5.188846936407454,\n",
       " 5.227029531621619,\n",
       " 5.45809279233324,\n",
       " 5.335896659372892,\n",
       " 5.194022484553914,\n",
       " 5.198482304564619,\n",
       " 5.158807477086877,\n",
       " 5.121279733502463,\n",
       " 5.539096650466235,\n",
       " 5.1397043906417625,\n",
       " 5.4157774685053415,\n",
       " 5.241994656782969,\n",
       " 5.991865156301906,\n",
       " 5.282731580911912,\n",
       " 5.525572177650618,\n",
       " 5.1391840931648725,\n",
       " 5.198482304564619,\n",
       " 5.5870975522465,\n",
       " 6.021890586265227,\n",
       " 5.336681589505763,\n",
       " 5.476760672320038,\n",
       " 5.227029531621619,\n",
       " 5.217513789269286,\n",
       " 5.208783555149575,\n",
       " 5.081162658127356,\n",
       " 5.150305463778792,\n",
       " 5.218792221592249,\n",
       " 7.236322324361986,\n",
       " 5.503752432168622,\n",
       " 5.175394354572068,\n",
       " 5.186607218868303,\n",
       " 5.290343767302067,\n",
       " 5.189255567878078,\n",
       " 5.3175304789962645,\n",
       " 5.169166167450755,\n",
       " 5.201290060399762,\n",
       " 6.130366571658941,\n",
       " 5.188846936407454,\n",
       " 5.203941581629068,\n",
       " 5.217513789269286,\n",
       " 5.188846936407454,\n",
       " 5.0534771183214895,\n",
       " 5.800376615079822,\n",
       " 5.179091942445456,\n",
       " 5.575127287633948,\n",
       " 6.33802822503767,\n",
       " 5.933571358830009,\n",
       " 5.48723446134629,\n",
       " 5.8635171630277965,\n",
       " 6.75503317017483,\n",
       " 6.247179322718889,\n",
       " 5.112942219943128,\n",
       " 5.188727310602621,\n",
       " 5.188727310602621,\n",
       " 5.195654761052098,\n",
       " 5.217513789269286,\n",
       " 5.679392348071239,\n",
       " 5.152273410122946,\n",
       " 5.396147854776514,\n",
       " 5.339648601846944,\n",
       " 5.153279281332743,\n",
       " 5.198752575221054,\n",
       " 5.765353292313273,\n",
       " 5.170610770828104,\n",
       " 5.207998046916952,\n",
       " 5.496031408634369,\n",
       " 5.3172912273866,\n",
       " 5.304616212586649,\n",
       " 5.2493933874879355,\n",
       " 5.389430987752656,\n",
       " 5.346197331858097,\n",
       " 5.122408044116876,\n",
       " 5.155078182445739,\n",
       " 5.23254180638383,\n",
       " 5.266940303716667,\n",
       " 5.160606714363747,\n",
       " 5.090705048356968,\n",
       " 5.203247506766444,\n",
       " 5.138328086115257,\n",
       " 5.5200455096540475,\n",
       " 6.969263137887639,\n",
       " 5.148811501523472,\n",
       " 5.188846936407454,\n",
       " 5.111578536256464,\n",
       " 5.495792157024705,\n",
       " 5.3476487225185085,\n",
       " 5.666044748574333,\n",
       " 5.835774686967384,\n",
       " 5.258307447249867,\n",
       " 5.175932669997838,\n",
       " 5.759819543685699,\n",
       " 5.600424110244995,\n",
       " 5.140670095621626,\n",
       " 5.304616212586649,\n",
       " 5.145726017963255,\n",
       " 5.227029531621619,\n",
       " 6.457602290738169,\n",
       " 5.467207284804125,\n",
       " 5.124849410907231,\n",
       " 5.555736925514784,\n",
       " 6.459845978325415,\n",
       " 5.331621784333246,\n",
       " 5.265319883455965,\n",
       " 5.050672883954687,\n",
       " 6.218017593038031,\n",
       " 5.227029531621619,\n",
       " 5.0626930471248865,\n",
       " 5.736274066813568,\n",
       " 5.777403219748572,\n",
       " 5.179739825525744,\n",
       " 5.184319431730272,\n",
       " 5.198482304564619,\n",
       " 5.184319431730272,\n",
       " 5.828630055068519,\n",
       " 5.501184805982084,\n",
       " 5.543700953633042,\n",
       " 5.194022484553914,\n",
       " 5.541636741715889,\n",
       " 5.575576617730269,\n",
       " 5.488014071388585,\n",
       " 5.239036710935536,\n",
       " 5.430183312637674,\n",
       " 5.136768238824953,\n",
       " 5.233020783082449,\n",
       " 5.223385414925284,\n",
       " 5.275011671490915,\n",
       " 5.179739825525744,\n",
       " 5.120385630263048,\n",
       " 5.248617880972213,\n",
       " 5.486276414672371,\n",
       " 5.121399359307295,\n",
       " 5.355534761495716,\n",
       " 5.972451718462982,\n",
       " 5.938544549530704,\n",
       " 5.46700567835804,\n",
       " 6.577452014674327,\n",
       " 7.288758067528591,\n",
       " 5.505666776791535,\n",
       " 5.305531157516799,\n",
       " 5.140260062979259,\n",
       " 7.188036686720716,\n",
       " 5.398602377036733,\n",
       " 5.15651537567742,\n",
       " 5.15651537567742,\n",
       " 5.15651537567742,\n",
       " 5.142327493905973,\n",
       " 5.188846936407454,\n",
       " 5.175417630667374,\n",
       " 6.481908199767126,\n",
       " 5.861706973884929,\n",
       " 5.99020230454774,\n",
       " 5.435831134196642,\n",
       " 5.185029722729234,\n",
       " 5.852698198540685,\n",
       " 5.198482304564619,\n",
       " 5.235934090345597,\n",
       " 5.175932669997838,\n",
       " 5.267942815407032,\n",
       " 5.761584399932213,\n",
       " 5.486396040477204,\n",
       " 5.140670095621626,\n",
       " 5.188846936407454,\n",
       " 5.833329126688889,\n",
       " 5.222906438226665,\n",
       " 5.857127528069392,\n",
       " 5.194022484553914,\n",
       " 5.4900357404589455,\n",
       " 5.110480625617273,\n",
       " 5.198482304564619,\n",
       " 5.316473652709382,\n",
       " 5.167321814425341,\n",
       " 5.169576200093123,\n",
       " 5.149002634985721,\n",
       " 6.167505855796817,\n",
       " 5.188846936407454,\n",
       " 5.150305463778792,\n",
       " 5.3844869856535045,\n",
       " 6.1734522930591655,\n",
       " 5.34807787511991,\n",
       " 5.3108907588269725,\n",
       " 5.126044935704288,\n",
       " 5.131034727464461,\n",
       " 5.148220705229589,\n",
       " 5.143643913175578,\n",
       " 5.486396040477204,\n",
       " 5.213445159207013,\n",
       " 5.326926595543766,\n",
       " 5.149485398494057,\n",
       " 5.153398907137575,\n",
       " 5.169166167450755,\n",
       " 5.1609973464868695,\n",
       " 6.167954657864601,\n",
       " 5.516258402356326,\n",
       " 5.02914404899201,\n",
       " 5.475824804162558,\n",
       " 5.280921026753581,\n",
       " 5.153002042776437,\n",
       " 5.188846936407454,\n",
       " 5.505666776791535,\n",
       " 5.274398440551359,\n",
       " 5.297217085640536,\n",
       " 5.100419178695903,\n",
       " 5.146787313916677,\n",
       " 5.188846936407454,\n",
       " 5.16945657428829,\n",
       " 5.310192412892432,\n",
       " 5.4883638720530215,\n",
       " 5.172635619569936,\n",
       " 5.287969281232506,\n",
       " 5.178801535607921,\n",
       " 5.121399359307295,\n",
       " 5.230505951176013,\n",
       " 5.491366920066892,\n",
       " 5.781645235818472,\n",
       " 5.79358051270412,\n",
       " 5.188846936407454,\n",
       " 5.188846936407454,\n",
       " 5.734624958669005,\n",
       " 5.165047209036995,\n",
       " 5.838691227953587,\n",
       " 5.1503488768055306,\n",
       " 5.296494963162844,\n",
       " 5.170615380806422,\n",
       " 5.2786003753575805,\n",
       " 5.270277711862419,\n",
       " 5.188846936407454,\n",
       " 5.870768552305845,\n",
       " 5.170865363515941,\n",
       " 7.552008622719925,\n",
       " 5.111933371011089,\n",
       " 5.193603398075719,\n",
       " 6.414072427521077,\n",
       " 6.007401180166189,\n",
       " 5.823779975466235,\n",
       " 5.562210750705376,\n",
       " 6.14893469155201,\n",
       " 5.258763994651366,\n",
       " 5.803894764941936,\n",
       " 5.827788757295998,\n",
       " 5.57412400823925,\n",
       " 5.446945026899313,\n",
       " 5.136636906429047,\n",
       " 6.268592111087358,\n",
       " 5.311183143684944,\n",
       " 6.241191765697426,\n",
       " 5.505666776791535,\n",
       " 5.16945657428829,\n",
       " 5.258187821445034,\n",
       " 5.127754428040268,\n",
       " 5.148855530753876,\n",
       " 5.162898777783391,\n",
       " 6.646846215092198,\n",
       " 5.505666776791535,\n",
       " 5.159740306033552,\n",
       " 5.566825210521393,\n",
       " 5.142237533610381,\n",
       " 5.193954799887438,\n",
       " 5.12966835081254,\n",
       " 5.179211568250288,\n",
       " 5.287558875477447,\n",
       " 5.087257556218767,\n",
       " 5.09035660386288,\n",
       " 5.486396040477204,\n",
       " 5.833282303752876,\n",
       " 5.139641112202139,\n",
       " 5.803031677860748,\n",
       " 5.496031408634369,\n",
       " 5.485753512158701,\n",
       " 5.368768702808201,\n",
       " 5.265060702804851,\n",
       " 5.2429465033483575,\n",
       " 5.137381139218863,\n",
       " 5.7205118356720135,\n",
       " 5.4028084971005335,\n",
       " 5.580128946290254,\n",
       " 5.179905145587298,\n",
       " 5.822931896814655,\n",
       " 5.248672079092701,\n",
       " 4.971714090193437,\n",
       " 5.316685637137597,\n",
       " 5.389229841789956,\n",
       " 5.26318641506594,\n",
       " 5.175283385745806,\n",
       " 5.149732462350444,\n",
       " 5.486396040477204,\n",
       " 5.529165717498675,\n",
       " 5.209295413585527,\n",
       " 6.8416318577844875,\n",
       " 5.779172284039185,\n",
       " 5.315033900426864,\n",
       " 5.100458124068351,\n",
       " 5.403535247703853,\n",
       " 6.438120538828626,\n",
       " 5.220975370301566,\n",
       " 5.62531706216203,\n",
       " 5.080559384282034,\n",
       " 5.169576200093123,\n",
       " 5.557651617690879,\n",
       " 5.2221008710765915,\n",
       " 6.084822227095811,\n",
       " 5.29321080617693,\n",
       " 5.29321080617693,\n",
       " 5.265583472063049,\n",
       " 5.169576200093123,\n",
       " 5.169576200093123,\n",
       " 5.411165152848602,\n",
       " 5.141335978049416,\n",
       " 6.170085585815091,\n",
       " 5.396950204189171,\n",
       " 5.174751748239583,\n",
       " 5.179739825525744,\n",
       " 5.5153021449487,\n",
       " 5.505156364045377,\n",
       " 5.842964494846054,\n",
       " 5.10217888170362,\n",
       " 4.984713491556408,\n",
       " 5.2271657323349645,\n",
       " 5.173835494201422,\n",
       " 5.173835494201422,\n",
       " 5.11176399115013,\n",
       " 6.468915430346652,\n",
       " 5.938948032687306,\n",
       " 5.191060431016344,\n",
       " 5.818705681245562,\n",
       " 5.203635701912334,\n",
       " 5.785560917373685,\n",
       " 5.230435913513352,\n",
       " 5.4115535581477126,\n",
       " 5.188846936407454,\n",
       " 5.159940831935957,\n",
       " 5.188846936407454,\n",
       " 5.2925410382065925,\n",
       " 5.188846936407454,\n",
       " 5.179211568250288,\n",
       " 5.903300560969145,\n",
       " 5.136210275610921,\n",
       " 5.169576200093123,\n",
       " 5.4146376146202595,\n",
       " 7.15668694628552,\n",
       " 5.782940157538696,\n",
       " 6.168771820307012,\n",
       " 4.8178315097561475,\n",
       " 6.570122147249371,\n",
       " 5.128949968915258,\n",
       " 5.158740295110105,\n",
       " 6.04128094838439,\n",
       " 8.642683789460776,\n",
       " 6.128611120768423,\n",
       " 5.217513789269286,\n",
       " 5.157302166883987,\n",
       " 8.062013286613514,\n",
       " 5.151213585029577,\n",
       " 9.046807801220673,\n",
       " 5.217513789269286,\n",
       " 5.79358051270412,\n",
       " 5.457076115802768,\n",
       " 6.159016826345015,\n",
       " 5.111961223686741,\n",
       " 6.506189164166363,\n",
       " 5.291450496647731,\n",
       " 12.753719632315292,\n",
       " 5.335469166043243,\n",
       " 5.110468597304337,\n",
       " 10.741777162881151,\n",
       " 4.1342655358084475,\n",
       " 5.1604888459675085,\n",
       " 5.332343424156336,\n",
       " 5.2623816558618275,\n",
       " 8.06501143974959,\n",
       " 6.387716947770663,\n",
       " 6.423359783645718,\n",
       " 5.861706973884929,\n",
       " 7.323561146537642,\n",
       " 11.23404432383575,\n",
       " 4.517619067747072,\n",
       " 5.149411360539376,\n",
       " 5.248557216388885,\n",
       " 7.728384308203047,\n",
       " 5.533187290948004,\n",
       " 8.108608480877812,\n",
       " 5.241747406824016,\n",
       " 8.369057103209613,\n",
       " 10.74916123281396,\n",
       " 6.589147921559508,\n",
       " 5.496031408634369,\n",
       " 6.244239895083494,\n",
       " 6.163079995906688,\n",
       " 5.509122386573878,\n",
       " 6.595859707950791,\n",
       " 5.471362827436417,\n",
       " 5.889992726407563,\n",
       " 5.0370328160941025,\n",
       " 6.4169795640877005,\n",
       " 5.842316611765765,\n",
       " 5.204479609713741,\n",
       " 5.721830425231174,\n",
       " 5.852480237198387,\n",
       " 5.115262987679934,\n",
       " 5.179211568250288,\n",
       " 5.235274800557596,\n",
       " 5.520906885953577,\n",
       " 8.059954723135181,\n",
       " 5.333511719646506,\n",
       " 5.267942815407032,\n",
       " 6.472162743352202,\n",
       " 5.608426170425454,\n",
       " 6.101683643764402,\n",
       " 8.521823249277375,\n",
       " 4.306925410430756,\n",
       " 6.168771820307012,\n",
       " 4.950386845955899,\n",
       " 5.420101862433766,\n",
       " 5.938608518191167,\n",
       " 5.444624915032674,\n",
       " 7.338195409246233,\n",
       " 4.761383722406142,\n",
       " 5.270213315276306,\n",
       " 5.37804044372383,\n",
       " 5.449974003799799,\n",
       " 6.0064464483622455,\n",
       " 5.276275304352638,\n",
       " 4.202395761997072,\n",
       " 6.190417327503833,\n",
       " 5.533044501584913,\n",
       " 5.159940831935957,\n",
       " 5.932540510386357,\n",
       " 6.730050173923057,\n",
       " 5.171969737142146,\n",
       " 5.757330525846315,\n",
       " 5.600746468764985,\n",
       " 5.57310248033784,\n",
       " 6.4565517803182715,\n",
       " 5.367666055403857,\n",
       " 5.34167833793755,\n",
       " 5.464045861864781,\n",
       " 5.476171709698246,\n",
       " 7.896301653157423,\n",
       " 7.865641597240553,\n",
       " 5.196122961220636,\n",
       " 4.952291134948239,\n",
       " 6.035686582586041,\n",
       " 6.780710645753933,\n",
       " 15.817249096998708,\n",
       " 5.913761882182628,\n",
       " 6.485068390086502,\n",
       " 5.3646642994218885,\n",
       " 8.39335491399614,\n",
       " 5.4077584844306275,\n",
       " 5.409348966109169,\n",
       " 5.25823880282686,\n",
       " 4.944437916389941,\n",
       " 3.6407862096645642,\n",
       " 6.5507443866799715,\n",
       " 5.534333629653367,\n",
       " 4.7017667341321925,\n",
       " 5.508037831463617,\n",
       " 7.444293677184811,\n",
       " 6.167274144586619,\n",
       " 6.506189164166363,\n",
       " 5.252851723411461,\n",
       " 5.209037227630251,\n",
       " 5.8375116968232135,\n",
       " 5.204963123851764,\n",
       " 7.55846563197187,\n",
       " 5.710168588570962,\n",
       " 5.861587348080096,\n",
       " 6.7274748999646405,\n",
       " 5.861587348080096,\n",
       " 7.403683971335506,\n",
       " 5.218672595787417,\n",
       " 5.459664407709923,\n",
       " 7.614575681804151,\n",
       " 5.473481774067588,\n",
       " 6.904635965390359,\n",
       " 9.780550637778177,\n",
       " 5.486396040477204,\n",
       " 5.558397742337328,\n",
       " 5.700881990652983,\n",
       " 5.213419777021926,\n",
       " 5.598571694900206,\n",
       " 5.474055725599767,\n",
       " 8.10576843251425,\n",
       " 5.303061039084473,\n",
       " 9.398363245882532,\n",
       " 6.197683117104727,\n",
       " 5.295868110011276,\n",
       " 9.448742355302157,\n",
       " 5.14213407921374,\n",
       " 5.235994793773794,\n",
       " 5.474978954165372,\n",
       " 8.114673104031333,\n",
       " 5.431614970959832,\n",
       " 6.088318190455425,\n",
       " 5.185328786545339,\n",
       " 6.387109804952681,\n",
       " 9.822217099608697,\n",
       " 5.542775836169157,\n",
       " 6.034209344286341,\n",
       " ...]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12,\n",
       " 2,\n",
       " 19,\n",
       " 36,\n",
       " 11,\n",
       " 20,\n",
       " 15,\n",
       " 7,\n",
       " 401,\n",
       " 13,\n",
       " 19,\n",
       " 3,\n",
       " 18,\n",
       " 9,\n",
       " 49,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 21,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 14,\n",
       " 15,\n",
       " 12,\n",
       " 20,\n",
       " 33,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 14,\n",
       " 2,\n",
       " 15,\n",
       " 16,\n",
       " 19,\n",
       " 15,\n",
       " 10,\n",
       " 167,\n",
       " 9,\n",
       " 45,\n",
       " 15,\n",
       " 15,\n",
       " 27,\n",
       " 20,\n",
       " 15,\n",
       " 19,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 14,\n",
       " 26,\n",
       " 17,\n",
       " 54,\n",
       " 5,\n",
       " 52,\n",
       " 9,\n",
       " 41,\n",
       " 1,\n",
       " 1,\n",
       " 12,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 27,\n",
       " 5,\n",
       " 68,\n",
       " 12,\n",
       " 12,\n",
       " 17,\n",
       " 1,\n",
       " 34,\n",
       " 24,\n",
       " 11,\n",
       " 12,\n",
       " 16,\n",
       " 41,\n",
       " 16,\n",
       " 10,\n",
       " 27,\n",
       " 24,\n",
       " 24,\n",
       " 30,\n",
       " 9,\n",
       " 12,\n",
       " 25,\n",
       " 15,\n",
       " 13,\n",
       " 23,\n",
       " 123,\n",
       " 18,\n",
       " 43,\n",
       " 22,\n",
       " 16,\n",
       " 14,\n",
       " 21,\n",
       " 28,\n",
       " 11,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 15,\n",
       " 61,\n",
       " 11,\n",
       " 27,\n",
       " 10,\n",
       " 25,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 14,\n",
       " 13,\n",
       " 29,\n",
       " 1,\n",
       " 1,\n",
       " 23,\n",
       " 17,\n",
       " 24,\n",
       " 11,\n",
       " 20,\n",
       " 22,\n",
       " 17,\n",
       " 8,\n",
       " 26,\n",
       " 15,\n",
       " 33,\n",
       " 7,\n",
       " 13,\n",
       " 11,\n",
       " 24,\n",
       " 21,\n",
       " 13,\n",
       " 20,\n",
       " 16,\n",
       " 1,\n",
       " 15,\n",
       " 10,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 10,\n",
       " 14,\n",
       " 24,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 17,\n",
       " 8,\n",
       " 20,\n",
       " 31,\n",
       " 15,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 39,\n",
       " 22,\n",
       " 8,\n",
       " 30,\n",
       " 13,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 11,\n",
       " 5,\n",
       " 23,\n",
       " 5,\n",
       " 12,\n",
       " 15,\n",
       " 26,\n",
       " 9,\n",
       " 12,\n",
       " 1,\n",
       " 10,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 10,\n",
       " 39,\n",
       " 9,\n",
       " 10,\n",
       " 24,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 5,\n",
       " 34,\n",
       " 21,\n",
       " 2,\n",
       " 17,\n",
       " 7,\n",
       " 7,\n",
       " 24,\n",
       " 7,\n",
       " 6,\n",
       " 21,\n",
       " 10,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 17,\n",
       " 43,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 3,\n",
       " 30,\n",
       " 1,\n",
       " 38,\n",
       " 9,\n",
       " 11,\n",
       " 3,\n",
       " 16,\n",
       " 11,\n",
       " 11,\n",
       " 33,\n",
       " 18,\n",
       " 13,\n",
       " 21,\n",
       " 10,\n",
       " 37,\n",
       " 25,\n",
       " 33,\n",
       " 10,\n",
       " 7,\n",
       " 24,\n",
       " 20,\n",
       " 24,\n",
       " 2,\n",
       " 23,\n",
       " 8,\n",
       " 12,\n",
       " 44,\n",
       " 17,\n",
       " 2,\n",
       " 11,\n",
       " 8,\n",
       " 5,\n",
       " 20,\n",
       " 6,\n",
       " 11,\n",
       " 11,\n",
       " 18,\n",
       " 4,\n",
       " 2,\n",
       " 23,\n",
       " 7,\n",
       " 1,\n",
       " 13,\n",
       " 10,\n",
       " 4,\n",
       " 14,\n",
       " 16,\n",
       " 7,\n",
       " 6,\n",
       " 31,\n",
       " 6,\n",
       " 6,\n",
       " 11,\n",
       " 33,\n",
       " 14,\n",
       " 20,\n",
       " 6,\n",
       " 9,\n",
       " 10,\n",
       " 4,\n",
       " 11,\n",
       " 14,\n",
       " 2,\n",
       " 1,\n",
       " 17,\n",
       " 11,\n",
       " 19,\n",
       " 14,\n",
       " 1,\n",
       " 25,\n",
       " 10,\n",
       " 6,\n",
       " 9,\n",
       " 28,\n",
       " 23,\n",
       " 19,\n",
       " 8,\n",
       " 12,\n",
       " 74,\n",
       " 20,\n",
       " 5,\n",
       " 13,\n",
       " 25,\n",
       " 7,\n",
       " 1,\n",
       " 30,\n",
       " 20,\n",
       " 12,\n",
       " 12,\n",
       " 24,\n",
       " 14,\n",
       " 10,\n",
       " 19,\n",
       " 7,\n",
       " 5,\n",
       " 17,\n",
       " 7,\n",
       " 6,\n",
       " 16,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 21,\n",
       " 9,\n",
       " 27,\n",
       " 17,\n",
       " 23,\n",
       " 8,\n",
       " 18,\n",
       " 1,\n",
       " 12,\n",
       " 2,\n",
       " 15,\n",
       " 15,\n",
       " 3,\n",
       " 13,\n",
       " 17,\n",
       " 9,\n",
       " 16,\n",
       " 8,\n",
       " 5,\n",
       " 14,\n",
       " 23,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 17,\n",
       " 22,\n",
       " 9,\n",
       " 13,\n",
       " 10,\n",
       " 20,\n",
       " 21,\n",
       " 10,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 20,\n",
       " 23,\n",
       " 7,\n",
       " 13,\n",
       " 27,\n",
       " 5,\n",
       " 15,\n",
       " 12,\n",
       " 1,\n",
       " 17,\n",
       " 43,\n",
       " 17,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 18,\n",
       " 13,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 18,\n",
       " 14,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 11,\n",
       " 4,\n",
       " 13,\n",
       " 20,\n",
       " 20,\n",
       " 7,\n",
       " 14,\n",
       " 78,\n",
       " 1,\n",
       " 17,\n",
       " 17,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 15,\n",
       " 18,\n",
       " 32,\n",
       " 10,\n",
       " 28,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 18,\n",
       " 7,\n",
       " 14,\n",
       " 18,\n",
       " 15,\n",
       " 1,\n",
       " 26,\n",
       " 9,\n",
       " 9,\n",
       " 50,\n",
       " 1,\n",
       " 18,\n",
       " 23,\n",
       " 5,\n",
       " 6,\n",
       " 29,\n",
       " 1,\n",
       " 7,\n",
       " 16,\n",
       " 10,\n",
       " 20,\n",
       " 1,\n",
       " 11,\n",
       " 18,\n",
       " 5,\n",
       " 23,\n",
       " 1,\n",
       " 1,\n",
       " 16,\n",
       " 20,\n",
       " 27,\n",
       " 6,\n",
       " 15,\n",
       " 22,\n",
       " 14,\n",
       " 21,\n",
       " 1,\n",
       " 14,\n",
       " 13,\n",
       " 17,\n",
       " 11,\n",
       " 16,\n",
       " 10,\n",
       " 15,\n",
       " 11,\n",
       " 16,\n",
       " 13,\n",
       " 8,\n",
       " 11,\n",
       " 7,\n",
       " 87,\n",
       " 7,\n",
       " 3,\n",
       " 11,\n",
       " 13,\n",
       " 17,\n",
       " 12,\n",
       " 7,\n",
       " 24,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 15,\n",
       " 23,\n",
       " 22,\n",
       " 14,\n",
       " 13,\n",
       " 1,\n",
       " 8,\n",
       " 11,\n",
       " 7,\n",
       " 19,\n",
       " 3,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 6,\n",
       " 19,\n",
       " 29,\n",
       " 1,\n",
       " 33,\n",
       " 13,\n",
       " 18,\n",
       " 14,\n",
       " 15,\n",
       " 8,\n",
       " 26,\n",
       " 18,\n",
       " 28,\n",
       " 18,\n",
       " 1,\n",
       " 1,\n",
       " 18,\n",
       " 1,\n",
       " 26,\n",
       " 16,\n",
       " 67,\n",
       " 1,\n",
       " 19,\n",
       " 17,\n",
       " 10,\n",
       " 14,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 19,\n",
       " 13,\n",
       " 21,\n",
       " 11,\n",
       " 13,\n",
       " 18,\n",
       " 21,\n",
       " 18,\n",
       " 41,\n",
       " 5,\n",
       " 25,\n",
       " 3,\n",
       " 14,\n",
       " 10,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 47,\n",
       " 12,\n",
       " 22,\n",
       " 20,\n",
       " 22,\n",
       " 36,\n",
       " 24,\n",
       " 7,\n",
       " 18,\n",
       " 22,\n",
       " 19,\n",
       " 22,\n",
       " 16,\n",
       " 1,\n",
       " 28,\n",
       " 20,\n",
       " 1,\n",
       " 7,\n",
       " 23,\n",
       " 30,\n",
       " 19,\n",
       " 21,\n",
       " 33,\n",
       " 9,\n",
       " 1,\n",
       " 11,\n",
       " 26,\n",
       " 23,\n",
       " 21,\n",
       " 2,\n",
       " 28,\n",
       " 24,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 11,\n",
       " 1,\n",
       " 29,\n",
       " 20,\n",
       " 16,\n",
       " 4,\n",
       " 26,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 25,\n",
       " 16,\n",
       " 20,\n",
       " 7,\n",
       " 1,\n",
       " 13,\n",
       " 19,\n",
       " 12,\n",
       " 12,\n",
       " 18,\n",
       " 3,\n",
       " 24,\n",
       " 17,\n",
       " 14,\n",
       " 4,\n",
       " 15,\n",
       " 32,\n",
       " 15,\n",
       " 17,\n",
       " 13,\n",
       " 25,\n",
       " 17,\n",
       " 4,\n",
       " 2,\n",
       " 13,\n",
       " 42,\n",
       " 19,\n",
       " 8,\n",
       " 14,\n",
       " 14,\n",
       " 19,\n",
       " 5,\n",
       " 25,\n",
       " 11,\n",
       " 2,\n",
       " 35,\n",
       " 19,\n",
       " 1,\n",
       " 12,\n",
       " 1,\n",
       " 12,\n",
       " 1,\n",
       " 19,\n",
       " 17,\n",
       " 3,\n",
       " 15,\n",
       " 29,\n",
       " 2,\n",
       " 3,\n",
       " 11,\n",
       " 9,\n",
       " 46,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 24,\n",
       " 19,\n",
       " 26,\n",
       " 5,\n",
       " 29,\n",
       " 28,\n",
       " 9,\n",
       " 22,\n",
       " 14,\n",
       " 20,\n",
       " 12,\n",
       " 15,\n",
       " 10,\n",
       " 30,\n",
       " 19,\n",
       " 16,\n",
       " 21,\n",
       " 2,\n",
       " 1,\n",
       " 21,\n",
       " 10,\n",
       " 15,\n",
       " 13,\n",
       " 9,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 55,\n",
       " 1,\n",
       " 11,\n",
       " 9,\n",
       " 11,\n",
       " 37,\n",
       " 9,\n",
       " 12,\n",
       " 20,\n",
       " 9,\n",
       " 2,\n",
       " 21,\n",
       " 1,\n",
       " 23,\n",
       " 17,\n",
       " 14,\n",
       " 6,\n",
       " 21,\n",
       " 18,\n",
       " 18,\n",
       " 12,\n",
       " 17,\n",
       " 9,\n",
       " 24,\n",
       " 2,\n",
       " 13,\n",
       " 22,\n",
       " 12,\n",
       " 10,\n",
       " 16,\n",
       " 11,\n",
       " 19,\n",
       " 17,\n",
       " 7,\n",
       " 1,\n",
       " 25,\n",
       " 2,\n",
       " 6,\n",
       " 18,\n",
       " 19,\n",
       " 26,\n",
       " 19,\n",
       " 9,\n",
       " 9,\n",
       " 12,\n",
       " 18,\n",
       " 21,\n",
       " 19,\n",
       " 1,\n",
       " 4,\n",
       " 17,\n",
       " 15,\n",
       " 19,\n",
       " 6,\n",
       " 16,\n",
       " 4,\n",
       " 12,\n",
       " 15,\n",
       " 18,\n",
       " 23,\n",
       " 7,\n",
       " 32,\n",
       " 2,\n",
       " 1,\n",
       " 14,\n",
       " 18,\n",
       " 15,\n",
       " 25,\n",
       " 9,\n",
       " 27,\n",
       " 12,\n",
       " 20,\n",
       " 1,\n",
       " 35,\n",
       " 4,\n",
       " 19,\n",
       " 6,\n",
       " 7,\n",
       " 23,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 10,\n",
       " 9,\n",
       " 1,\n",
       " 16,\n",
       " 12,\n",
       " 23,\n",
       " 17,\n",
       " 11,\n",
       " 22,\n",
       " 14,\n",
       " 14,\n",
       " 12,\n",
       " 1,\n",
       " 1,\n",
       " 16,\n",
       " 12,\n",
       " 18,\n",
       " 1,\n",
       " 13,\n",
       " 14,\n",
       " 16,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 21,\n",
       " 11,\n",
       " 2,\n",
       " 32,\n",
       " 1,\n",
       " 18,\n",
       " 9,\n",
       " 18,\n",
       " 13,\n",
       " 11,\n",
       " 10,\n",
       " 20,\n",
       " 11,\n",
       " 10,\n",
       " 18,\n",
       " 4,\n",
       " 12,\n",
       " 16,\n",
       " 4,\n",
       " 22,\n",
       " 16,\n",
       " 5,\n",
       " 10,\n",
       " 9,\n",
       " 23,\n",
       " 1,\n",
       " 9,\n",
       " 21,\n",
       " 24,\n",
       " 1,\n",
       " 18,\n",
       " 21,\n",
       " 15,\n",
       " 10,\n",
       " 1,\n",
       " 22,\n",
       " 1,\n",
       " 8,\n",
       " 11,\n",
       " 13,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 11,\n",
       " 17,\n",
       " 14,\n",
       " 29,\n",
       " 20,\n",
       " 17,\n",
       " 14,\n",
       " 15,\n",
       " 10,\n",
       " 29,\n",
       " 1,\n",
       " 37,\n",
       " 18,\n",
       " 11,\n",
       " 1,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 1,\n",
       " 14,\n",
       " 10,\n",
       " 18,\n",
       " 15,\n",
       " 18,\n",
       " 1,\n",
       " 11,\n",
       " 14,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 16,\n",
       " 16,\n",
       " 13,\n",
       " 18,\n",
       " 16,\n",
       " 16,\n",
       " 12,\n",
       " 13,\n",
       " 8,\n",
       " 8,\n",
       " 16,\n",
       " 27,\n",
       " 6,\n",
       " 9,\n",
       " 20,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 26,\n",
       " 21,\n",
       " 33,\n",
       " 1,\n",
       " 21,\n",
       " 10,\n",
       " 39,\n",
       " 16,\n",
       " 1,\n",
       " 17,\n",
       " 5,\n",
       " 7,\n",
       " 20,\n",
       " 10,\n",
       " 31,\n",
       " 16,\n",
       " 21,\n",
       " 11,\n",
       " 15,\n",
       " 16,\n",
       " 12,\n",
       " 24,\n",
       " 8,\n",
       " 16,\n",
       " 13,\n",
       " 27,\n",
       " 35,\n",
       " 16,\n",
       " 24,\n",
       " 16,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 14,\n",
       " 17,\n",
       " 15,\n",
       " 9,\n",
       " 4,\n",
       " 16,\n",
       " 14,\n",
       " 14,\n",
       " 2,\n",
       " 21,\n",
       " 11,\n",
       " 9,\n",
       " 14,\n",
       " 21,\n",
       " 12,\n",
       " 9,\n",
       " 12,\n",
       " 10,\n",
       " 16,\n",
       " 12,\n",
       " 11,\n",
       " 8,\n",
       " 11,\n",
       " 8,\n",
       " 29,\n",
       " 11,\n",
       " 13,\n",
       " 16,\n",
       " 23,\n",
       " 14,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 11,\n",
       " 12,\n",
       " 10,\n",
       " 19,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 26,\n",
       " 8,\n",
       " 12,\n",
       " 6,\n",
       " 15,\n",
       " 20,\n",
       " 10,\n",
       " 27,\n",
       " 20,\n",
       " 2,\n",
       " 36,\n",
       " 18,\n",
       " 7,\n",
       " 14,\n",
       " 9,\n",
       " 8,\n",
       " 25,\n",
       " 12,\n",
       " 45,\n",
       " 25,\n",
       " 43,\n",
       " 21,\n",
       " 8,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 15,\n",
       " 12,\n",
       " 17,\n",
       " 18,\n",
       " 22,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 13,\n",
       " 3,\n",
       " 1,\n",
       " 12,\n",
       " 20,\n",
       " 16,\n",
       " 23,\n",
       " 18,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 22,\n",
       " 1,\n",
       " 6,\n",
       " 16,\n",
       " 1,\n",
       " 2,\n",
       " 20,\n",
       " 18,\n",
       " 15,\n",
       " 27,\n",
       " 24,\n",
       " 20,\n",
       " 13,\n",
       " 15,\n",
       " 28,\n",
       " 33,\n",
       " 1,\n",
       " 19,\n",
       " ...]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x16370c438>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEPCAYAAABV6CMBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt8lPWd9//XJ4RjIoKisCCnpt2qxWOtYq01KB76s4pa\n1xVBBQ/U2qLgoXggJtzcddXbrnbtYRe3iq7W1m3roWtrhbuGbtvbVlctKmDbEBBB4hlJ8ADy+f3x\nvSZzZTKTZHK6ZsL7+XjMIzPXXIdvJnB95nv6fM3dERER6aiSpAsgIiLFRYFDRETyosAhIiJ5UeAQ\nEZG8KHCIiEheFDhERCQviQcOM9vdzP7TzFab2UtmdoSZDTezJ8zsZTP7tZntnnQ5RUQkSDxwAN8B\nfunu+wEHAWuAa4Dl7v5p4DfAtQmWT0REYizJCYBmNhR4zt0rMravAY5x9wYzGwXUuvu+iRRSRERa\nSLrGMRF408zuNrNnzWyJmQ0BRrp7A4C7bwb2TrSUIiLSLOnAUQocCnzP3Q8FmgjNVJnVIOVFEREp\nEKUJX/9VYIO7PxO9/hkhcDSY2chYU9Xr2Q42MwUUEZFOcHfr7LGJ1jii5qgNZvb30abjgJeAR4FZ\n0bbzgUfaOEfBPaqrqxMvg8qkMu2K5VKZOvboqqRrHACXAfebWX9gLTAb6Ac8aGYXAOuBsxIsn4iI\nxCQeONz9z8Dnsrw1tbfLIiIi7Uu6c7xPqqysTLoIrahMHaMydVwhlktl6h2JzuPoKjPzYi6/iEgS\nzAwv1s5xEREpPgocIiKSFwUOERHJiwKHiIjkRYFDRETyosAhIiJ5UeAQEZG8KHCIiEheFDhERCQv\nChwiIpIXBQ4REcmLAoeIiOQl8bTq3WF9fT1Lq6rYuXEjJWPGMGvxYsZPnJh0sURE+qSiz467bu1a\n7jj+eBbV1VFGWLS8uqKCucuWKXiIiGSxy2fHXVpV1Rw0AMqARXV1LK2qSrJYIiJ9VtEHjp0bNzYH\njZQyYOemTUkUR0Skzyv6wFEyZgxNGduagJLRo5MojohIn5d4H4eZrQO2ADuB7e5+uJkNB34CjAfW\nAWe5+5Ysx6qPQ0QkT13t4yiEwLEW+Ky7vxPbdjPwlrvfYmYLgOHufk2WY93d06OqNm2iZPRojaoS\nEWlDXwgc9cBh7v5WbNsa4Bh3bzCzUUCtu++b5VitOS4ikqe+MKrKgWVm9rSZXRRtG+nuDQDuvhnY\nO7HSiYhIC4UwAfAod3/NzPYCnjCzlwnBJE7VChGRApF44HD316Kfb5jZw8DhQIOZjYw1Vb2e6/ia\nmprm55WVlVRWVvZsgUVEikxtbS21tbXddr5E+zjMbAhQ4u6NZlYGPAEsAo4D3nb3mzvSOS4iIh1X\n1J3jZjYReIjQFFUK3O/uN5nZHsCDwFhgPWE47rtZjlfgEBHJU1EHjq5S4BARyV9fGFUlIiJFRIFD\nRETyosAhIiJ5UeAQEZG8KHCIiEheFDhERCQvChwiIpIXBQ4REcmLAoeIiORFgUNERPKiwCEiInlR\n4BARkbwocIiISF4UOEREJC+JrwAowfr6epZWVbFz40ZKxoxh1uLFjJ84MeliiYi0ovU4CsD6+nru\nOP54FtXVUQY0AdUVFcxdtkzBQ0S6ndbj6AOWVlU1Bw2AMmBRXR1Lq6qSLJaISFYKHAVg58aNzUEj\npQzYuWlTEsUREWmTAkcBKBkzhqaMbU1AyejRSRRHRKRNBRE4zKzEzJ41s0ej18PN7Akze9nMfm1m\nuyddxp40a/FiqisqmoNHqo9j1uLFSRZLRCSrgugcN7P5wGeBoe5+qpndDLzl7reY2QJguLtfk+W4\nPtE5DrFRVZs2UTJ6tEZViUiP6WrneOKBw8z2Ae4GvgVcEQWONcAx7t5gZqOAWnffN8uxfSZwiIj0\nlr4wquo24GogHgFGunsDgLtvBvZOomAiItJaohMAzexkoMHdnzezyjZ2zVmtOGbCBGzoUA6eMoXT\nTj+dysq2TiMisuupra2ltra2286XaFOVmd0IzAR2AIOB3YCHgMOAylhT1ZPuvl+W493RhDkRkXwU\ndVOVu1/n7uPc/RPA2cBv3P1c4BfArGi384FH2jqPJsyJiPSeQujjyOYm4Hgzexk4LnrdJk2YExHp\nHQWT5NDdVwAroudvA1PzOV4T5kREekfiw3G7wsz8BmAn0DB2LNevWKE+DhGRdhR1H0d3WARcAwy2\nTn8GIiKSh6IPHBD6N2585RV1jouI9II+ETggBI+murqkiyEi0uf1mcDRBNRt3px0MURE+rw+ETia\ngGpg7KhRSRdFRKTPK5jhuJ11HiFwfA34fUVFwqUREen7ij5w3EsIHF8vLeXiOXOSLo6ISJ/XJ5qq\nyoDv7djB8iVLki6KiEif1ycCByjliIhIb+kzgUMpR0REekefCBxao1tEpPcUf66qKVO0RreISB66\nmquq6EdVxYPG+vp6llZVsXPjRkrGjFEwERHpAUVf42gkNFOdftddPHTBBSyqqwvpR9CqgCIi2XS1\nxlH0gSO1dOx5EyZw77p1lMXebwJunTGD6vvuS6aAIiIFaJdPqw5hKG7Zu++2CBqp7RqiKyLSvfpE\n4GgCmoYNoynLdg3RFRHpXkUfOFJ9GVfccw/VFRXNwSO1feqcOSyaOZPqKVNYNHMm6+vrEyytiEjx\nS7SPw8wGAr8FBhBGeP3U3ReZ2XDgJ8B4YB1wlrtvyXK818yY0XpU1aZNlIwezdQ5c9RhLiKSoeg7\nx81siLtvM7N+wO+By4CvAG+5+y1mtgAY7u7XZDnW2yr/opkzuer++9VhLiISU/Sd4+6+LXo6kFDr\ncGAacE+0/R7gtM6ce+fGjeowFxHpZokHDjMrMbPngM3AMnd/Ghjp7g0A7r4Z2Lsz5y4ZM0Yd5iIi\n3SzxmePuvhM4xMyGAg+Z2WcItY4Wu+U6vqampvl5ZWUllZWVza9nLV5M9VNPte7jUE4rEdmF1NbW\nUltb223nS7yPI87MqoBtwEVApbs3mNko4El33y/L/m32cQCtOsyVhkREdnVF3TluZiOA7e6+xcwG\nA78GbgKOAd5295vb6xxft3at8lOJiOSh2APHAYTO75Lo8RN3/5aZ7QE8CIwF1hOG476b5Xi/sqKi\nV4bbKoGiiPQVRR04uiqV5LCnh9uur6/njuOPL6j5IApkItJZu3xa9d4Ybru0qqo5aKSusaiujlur\nqhKZD5I1kD31lCY2ikivSHw4blf1xnDbQpsPkiuQLa2qSqQ8IrJrabPGYWZXtPW+u/9z9xYnf9UZ\nfRxzy8u5cM6cbr1Gaj5IZpNYUvNBCi2Qiciupb0ax27R4zDga8CY6HEJcGjPFq1jTr/rLqaXl7MQ\nuBW4urGRhy64oNPJDNfX17dKijhr8eKsCRSTWuNcExtFJEkd6hw3s98CJ7v71uj1bsBj7v7FHi5f\ne+Xy8z7/ecb94Q/Nw7JmASOAmlNPpXy33fLqPF5fX8+3jjmGkRs2UALsBBrGjuX6FSsACmY+SCF2\n1otI8eiVUVVm9jJwoLt/GL0eCKx090939sLdwcx8BvBvkL6BAnOB6wYNYskHH+S8sWYblXT7/PnY\nI4+wOHa+KsCnTeO2hx9O4DfMTRMbRaSzeitwXA+cBTwUbToNeNDdb+zshbtDruG4N0XPF2dsTw3T\nzfWN/aV33uGnb7/d6nznjhzJzzdv7slfRUSk1/TKcNxoUt6vgKOjTbPd/bnOXrQ73UpoUko1U40H\nVgPfztgv3nmca1TS6QMHZu10Lu+ZoouIFKV85nEMAd5z97vNbC8zm+juiS+ndxUtm6kuBDaVlDBi\n584W+8U7j3ONStqrvJymDz9sVeMYecQRPVN4EZEi1KF5HGZWDSwAro029QcKYiWkFrUG4HLgvH/+\n5zZHQeUalTT6qKO4bty4FsddN24c37j99h79HUREiklH+zieBw4BnnX3Q6JtK939wB4uX3vlalX6\nr+2/Pz946aU2O4/bGpUEhTN6SkSkJ/RW5/if3P1wM3vW3Q81szLg/xVC4LiBlsNwjy8pYdjuuzOi\nf39GTp7MaVdeyfIlS1oNy9WoJBHZVfVW4LgK+BRwPPBPwAXAA+7+L529cHdI1ThSw2bfBfoBt5Pu\n97jEjOvc2Q/NdxARgV7MjmtmxwMnAAb82t2Xdfai3SXeVNUEnA38mCzZcgkd582vuzl7rohIMemV\n4bhmdrO7LwCWZdlWEMqA4eTIlpv5OoGcTkqDLiJ9RUeH4x5PGFUV96Us2xLTFHu0SkaY8frF+vrm\nXFa9cTNXGnQR6UvabKoys68BlwIVwN9ib+0G/MHdZ/Rs8doW7+O4BDgK+Au0SBlyCXAdpPs4CHM9\nbhs7lsFm3PjKKz2e72nRzJlcdf/9Pb7glIhIR/R0U9WPgF8ROsTja35vdfe3O3vR7nQe4Sb8NeBG\nYBIwDdgbGAVsAC4tLeWzO3ZQT1iL9kFg0IYN3AitZo/3xOJMSoMuIn1Jm4HD3bcAW8zsO8Dbsey4\nQ83sCHf/Y28Usi33Ek3UAwYS+jmOBBqBfwbOGDiQkfvtB88/z72kayJzgTdp2awVv5l3Z59Eoa3n\nISLSJe7e7gN4jqhZK3pdQpgM2KHj2zjvPsBvgJeAF4DLou3DgSeAl4FfA7vnON49ejSCnxx7PhN8\nGfic447zY8vK/HrwGvB1sX0Wxo5PbauZMcPXrV3rV1ZUeGNs+5UVFb5u7VrvjK6eb93atV4zY4bf\nUFnZXL5CUwxlFJEg3Pq7cO/u0E7wfJZtK7ty4egco4CDo+flUaDYF7gZ+Ga0fQFwU47j/YZYQDgn\nIwgcDX7p6NEtb9ix4HFaSYmvynIzr5kxo/mYzKDSWc031ilT8rqx5go6v1uxomBu1N0daEWkZ/VW\n4Pg5cBkhR1V/Qkqoh7ty4RzXeRiYCqwBRno6uKzJsX/zjWo++EkZN/vTovdaBYBYjWN2eblfPnly\ni5vvDZWVLY5JPW6YMqU7/3YdkiuInVJeXjA36p4ItCLSc7oaODqU5JAwOOnzwEbgVeAIoFsX9jaz\nCcDBwFNR0GgIkcE3E/q6cyojjKSKd9g0EYZ+ZeuU/hswH7gIuKOxkeEVFVTfd19zH0YhLc2aq2P9\nwMbGVh37S6uqerdwEXX+i+xaOroex+uEidk9wszKgZ8Cl7t7o5lljhHOOWa4JmOnRcB24BnCCKps\nndLDgXrg+4Rc8Ssff5zqKVOaO8FnLV5M9VNPtU6CmMAa47k61vtn7JfkjVqd/yKFrba2ltra2u47\nYVvVEdL9DHcA/5L56EpVJ3aNUuBxQtBIbVtNy6aq1TmObW4aWQU+PdY01Qh+br9+Pvvv/q7FtovB\nL8vYb1bU7xFv8ulsn0R3y9Z/MLu8vLlvphCahtTHIVJc6GJTVXsTAE9x91+Y2fk5gs49XQ1cZnYv\n8Ka7XxHbdjNh+O/NZrYAGO7u12Q51p0QZb4KfJHwTXwWYSXAJuDMUaP4+K23OHL7dkoIw3RryJ3P\nqhAn5mVm8p06Zw4PXXBB1rTwSc1EV7ZhkeLRa0kOe4KZHQX8ljAU16PHdcCfCPP0xgLrgbPc/d0s\nx/vlwBbgu7RcCXAuIXicA4wE/nf0fjWhOStTfHv1lCks+s1vuueX7EbxuSXbhg5lhxlD33tPN2oR\nyUuPzhw3s1/QRv+Cu5/a2QtHx/+ekAk9m6kdOcdw4Fu0XgnwVsKyshXAB6RTjbxICC5vAksJCRB3\nEmoi0L1t8905iTDX4lMXKN+ViPSy9pqqjomenkHoa0i130wHGtx9fs8Wr21m5ucSZo9nWkgIGHOB\nuwj54H8IXA3cRpg0Es9pdSmwO/DB2LFcv2JFl2/Gba0y2Jlz94V8V8oQLFIYerTG4e4root8290P\ni731CzN7prMX7U4VZB85tZqQcmQEoZaxjdDDX0YIEDW0rKV8H7iJ8IFC129yS6uqmoNG6hpdyYVV\nDENe2/rMlCFYpO/oaFr1MjP7hLuvBTCzibSeIpGIWaT7J+K1h1TQqCb0b9SQLvAQss/vKAFufOUV\naubNw196qUs3ufZu9PkGpkIf8tpeYOjuQCoiyelo4JgP1JrZWsIKgOMJA5kSN59QoHOinwa8AtxJ\nGGGV6iT/iHTNpITstZSSaFvDH//IDxoast7kZi1ezNKqKt7529/Y0NDAJ0eNYkhFRasbf1s3+s58\n+y6kuSXZtBcYiqHGJCId1NFxu4TkswdFj4FdGQPcXQ8y521E8znOieWjSj0uj/JUNUbvzc84NpXD\nqhF8ysCBLXJgpc5x9eTJfmVFha+KnSvXvIX43IZ1UXqTcwYN8qtOPdWvOvXUTqXoKJS5Jdm0l6ZF\naUlECgddnMfR0Rv0EEJ/853R608BX+7KhbvjQTt5qOLvLYyCSg0hMeI88K+CfyV6LxU0zi8tbZn4\nMPbeGRMmtLhGezfBdWvX+rxp03z24MEtgsw5gwa1eZMtRu0FBk0SFCkcXQ0cHc1VdTehtefI6PVG\nQtdB4s4DvgL8nnQfRxkhzW4TYRJIFaGD/DLgLEJ/yP8GPiQMDwO4uqSEfxg5kgU7drBftC01tPff\nCc1Cw3bfnVuBOsJw3/WxcuRqdnnlz39m9PvvN+9fBoz84IOsubC27bZbZz+GxM1avJjqiorm3yvV\nlDYrakobP3Eic5ctC6PApkzh1hkz1DEuUqQ6NAHQzJ5x98PM7Dl3PyTa9md3P6jHS9h2udwJN6mv\nAzOBbxM6xi8iBIZ9gAMI/Rc7CTMNxxI6zs8iDM3dndAO9yRwODAUeI/QATQE+H+DBvHVu+/msYsv\n5o4ouWDmRMMmYOG0aQwrL2+eoLfluee4bcOGVvvfTuiLiQ8HrgJ82jRue/jhHvu8eppmj4sUh16Z\nOW5mfwCOA37v7oeaWQXwgLsf3tkLd4dU4IBw8z2REBReB94HBgCH0voG/SLwGcLMxncIQ3FT718L\n/CPws4zjzh4yhB9v25Y1VclVwAWDBzNqr71arGFeRcg/Pz5j/+3AxaQnIJYQRofdVaAz1kWkb+np\nNcdTqgmJCMea2f3AUYR7XcEoAyYCexGakkYDb5C++af2WUyombxLuIH/W8b7/wR8GfivjO0HZQSN\n1Pa/ANPLyxk3eTI3Ll/e6lqpHFipbduBPw8Zwoht25q3Q2ENrRURaUu7fRwWZsStIcwenwU8ABzm\n7rU9WrI8NREm+S0GxgCDCN/0UzfuRaT7GHYDZgCvAbfE3iN6fx9az/PoH10j85ofTJjAHStXsueO\nHdmHm2bs/wegsbyc68aNy9kfICJSyNqtcbi7m9kv3f0A4LFeKFPeUn0cV5AODOcROrWvomXywwuB\nwYTcKY9mvDeX0PexjdbzPM4i9Jv8e+yYi83Ye9gwllZVsW3o0KzzNnbGnlcRRhmMeP11Lhg8mAVT\np7Lnxx9TMno0cxPuD1A6EBHpqI72cdwDfNfdn+75InWcmfmZhISFI4FPE27UKwiZE+PNTRBu3mcA\nB5I9tfpNwDrCcocP0XI2+rWElQM/S+h0X0NYGH2/6P0LBgxgUGkp34+atJqAS4cMYfdt23iXUPu5\niJb9HdPLy7lj5crEb9C58mqdftddLF+yRMFEpI/prc7xNYS5G+sI9xUjVEYO7OyFu0MqyeFWQtPU\nTYQaw9ei10uyHHM28EmyjyU+l9Av8jih6WopoU/iJUL23IdJD9FN1WRSUsFlXXk5+06aRFlFRfO6\nGYPq6rJebyHQvwCSFOZKoDi9vJwH4qPIEl7zQ0S6R1cDR0fncZwIfAI4FjiF0H98Smcv2p3uJTQ7\nDSTdEf4DQgd5tj6JjYQEiNne2wJ8HD0fTwgOawmjr/oTbvTV0bmz9We8C0xobGT1q6+yc+NGHv72\nt3l34kT+MHBg1uv1pzBSbhTDuuYiUjjaW49jEKHl5pOEKRA/dPcdvVGwfJQB3yMdycqAPWmd/PBC\nQjr1bYRayQ9i711KqLkcGJ3n74FNtGyOqgIuIPRzZOvPGEkIPD9+9VXKXn2VJuAbhIh7KS2H/ab6\nW5YMHcqimTMTbQ4qhnXNRaRwtNc5fg+htea/gS8B+xOmJhScVLCAcNNrIASN8wg3/j8CCwirQzUB\n8wgTUz5FqCkMIfSJvEkIDC8TouWQ2PlTw2svIgSR+DyPuYRRWj+l5TDe7xKa0DYCZxL6SPoTgsZt\nY8cy+LnnuCqa+7EamPvII+w3aVLWxIlx3dmZnS2B4pzSUmbvaPkdQUOGRQTaX8jphWg0FWZWCvzJ\n3Q/trcK1x8z8BkJ721mEdL2fBl4l3PC3EILJDsJkwH1puR75VMLcjwrgGkLQuIOWtZT47HBoObT3\nkvJyyhsb2ZcQTO4ke9/JN6PjzgH69e8Pe+zBHgccwBurV3PAxo30j8qS2SGfq08h1Zl9YV0dDxIi\n+8rychY89hhHffGLnfosf//b33LzySdzYGMj/aPP8+bS0uYULOrjEOk7enoC4PbUE3ffkVrkqNDs\nIHRM7x29Tn3rbyLM0N6bdIqRO0gHgk8Smq2ej/a/lfSNG9Id4ecSUgKfRbpTaATwwQcftKhh9CfU\nGh4kPSP8LMIIrDeBccCI7dvZ2tDAyoYGvkO6GWwuYXXCzD6FhfPnN6cxSdUsllZVcWFdHT+Mlbep\nsZG5J5/MPp0cpbV8yZLmjvCU7+3YwXkTJjBp4sSsQ4Y1hFdkF9VWBkRCk/170WMr4R6dev5eV7Ir\nxq7xQ0LL0srYtuHAE4QWo18Du+c4tjnT6nzwi6Kf63JkzL0yliE3lUF3Pvih0fNzs6RS9yibbiP4\n+eC/i53rGxn7/S7aJ54B9nzwZeBzs7x3ZexaqXLGz7cOWmXWvbKiwi8/4ogOZ+jtqPbSomdStlvp\nac3LCFRWFtwyAsWOLmbHbW/p2H7dFqFyu5tQEYgvHX4NsNzdbzGzBYQKxTW5TpDqfziNMGQ2M83H\nTtK1h1SuqLMJ0W8YoZ/jGrI3T8UXePoecCphHsdMQrSLdyovj/aJ1xq+F11zNenhvKn3Un0wk6Jr\nvEl6GPBOYCVw3/vvt6qFnPfxx5TTsjO7+XftZOd1ewtPZdYsunNFP9VcJJOWGi5wXYk63fUg3KPj\nNY41wMjo+ShgTY7jWnw7PiVWQ8iscaReXw/+BfDzotrHGbm+uUc/Z8dqBevAT4/OcTz47eCzy8ub\nj78+o7ZQE5XlNPBTs3ybjx/TCD49qjVlO1/8cfXkyX5K7LrdUePIVYP43YoVWbd/c/LkvGoo+V5X\n3y53bVr4q2fRxRpHR+dx9La93b0BwN03k+6+yKmJMKrpMkLG29S2uaSzMTYBzxC+3V9DaCPbj+zf\n3J8n1GBei7atB74D/AehA/whwkittWacOWYM35w8uXm+xnpCFeoqQq3iPtLzQzLLnBryWkboXB9F\nyz6TbMeUVVSw4LHHmFte3m6+q/X19SyaOZPqKVNYNHMm6+vrySbXehnLlyzJWrP42+bNWcuW76ir\nzJrLm8DgujqqJk9us7zSt2mp4cLW0ey4Scs59KuGsMLUk4Tp7KWESXvzCBNPUjfmVEf5ntH+D5Ju\nusrWRDOJ0PzVBMwhjNT6JS2bmu4EqrZuha1bebekhE994QtU/d//29wMFd/3/xDyaaWasuJNYsT2\ni0fyWbSei5JaZ3z8xInss3Ilt8bWv8jWeR2v7rc33Hf8xImtmply/QceO2oU1f36dXkN9Pj5UwF3\nEVD2+us03X+/mid2UW01nUr+amtrqa2t7b4TdqW60l0PWjdVraZlU9XqHMe1WBv8XNKd3l8F/zyh\nY/oc8EOi5qKF4FNjzUDraL1+eLYO9tOyNEHVgE+Lmrzmg395n338hNLS5iazzMcJ0XnOBZ8SlS2z\nKp655O0qwpK1nVlnPF7dj/+e62i5Bnpb52yryaA71kCPn7+G7u3wl+KlJsyeRRebqgqlxmHRI+VR\nwhfum4HzgUdyHbgo+rka2EBIk/4S8AGwmbAi4GcItZCBpOdrzCWdWmQu6U7zPxB668fHrlFGaGpa\nDS2HwJLOyjsIsFdfZSdhmG/mt6XVhDVCvkt6kuESQi3mcsLw3uvGjeN9d5piqwb+67hxjDvoINiy\nJfenl8O2WBPQ0qjcLeaqfPABTY8+ynXPP0/JIYcwdMuWVp3T2SYHxms9Xc2zFT//Nrq3w1+KV3PT\naRs1aklQV6JOdzyAHxGye3wIvALMJgzHXU4YjvsEMCzHsX4DYajrjIxaw/SoZhHfNoswZDY1dHZW\nxvszwefk+NZ7XFRjyPbewtjz+dG1L8s49/Gxb/uZNZzp4BdOnerr1q5t8S3+qlNP9YvHju30t64z\nJkxoPjY1YKCmA79D5jW6UrPoyJDK361Y4SeNGdP8GanGIdKz6GKNI/HA0aXCRzeXhTluOFPBryLd\nrLQK/KTYtgvBjyE0ZX0heu8kwoirzPkWqwjNUllHEmVcdz74PNJNWsfHjs114/7ykCGtbqr5jizJ\nvElfcNBBzUEqdd0bOvg7dMfNuiPNDal9FkafcWZQnV1e3uebJzRfQXpbVwNHoTRVdUlqnkXcm4SV\n/GpomU+qkZCocBVhfY3HaNlZfSFwPSGv1XvR/uMJKUyayN6RHu/QLiNUn8oIc0Q+JiwstQfphZ2y\nNccctG0b3503j//zSGiVW19fz5+XLeN6QhNcKm/WLLI33WQb9z63vJyTCM1w70S//5gO/A5vAs88\n/jgzRozgjcZG+pWVse/RRzPvttvyairoyFyP1D63EEa4pZoNUzPvh06a1KebJzRfQYpSV6JO0g8I\n8zA+H31bjX+DzlULWRjVKD6fq1kk+nlK7P1VUY3ktKg2Ef9G/DVad6TPBz+a0AFfEx1/HviZbZSr\nBvzckSPdPf0tPNs38Png86ZNa/UNIlftJD7fYxX41MGDfYZZi3NeRLoWNi/6nTKveRH4xWPH5vVt\nuCOz0VP71JDjc+njzVSaryBJYFevcUwipOy9HvgW6dxPL5P9m30JIb35aTneT9UIDox+rid0iI8g\nzMd4k/Q34p2EzvR5hDTsAwhZcEuBX9GyJnMNcBch8WLmErTVwEnAk++8w4wRI3jtnXcYsHMnVxDy\nbsWvWQb0FHFHAAAUN0lEQVS83tjY6nPINWx230mTuLWiormDsWbOHG6aMYNLorTvgwmrJdZE+1cR\n5qnEawmLCRl+2bCBpXnMDO/IkMrUPrPIPfS4L9N8BSlGRR84FpFefW8mIYhsAZzsTTIvEG7CAwk3\nyZLoMYsQHEoII6D+TEgHspmQVbcs9qiOzreesCTiv9IyqWIVLW+8qfkiQwjzOZYDXwEOI8wzOYmQ\nv/6xjz6i7K23mtf+eJUwETEza+4lTz7JV/bcEy8tZfyRRzLvttty3qTLKiqab/SpZpEfv/pqi+a7\neHLFbM1+ZYSRCx8BryxfTvWUKR1KDdLWiKyUqXPmMP2RRziwsZGPo9+7YdAgRp9wAnNvv73PN9do\nvoIUpa5UV5J+QHpexfVR89P+UfPVzBzNPOtIj2RalvHeqaTnfSyLnacS/MAsTSltNTtlNs+cCf6l\nWLPW5aQ7z0+MzhWfk5JqVjstxzWuit6fDj510CA/58gjffagQW12ROdsFom9rslxvVOizyXfEV5t\njcjK1nk+u7zcf7diRZvn7Es0X0GSQBebqjq05nihMjO/kpbfxmcTvqk7oelocPTzIEIT0fjo2CZC\njeJnsddHE+Zj/C9Cs1R8lvfFhA7mw6LzjIiu9WCWci2k5bocTdG2ckISrvcJsxr/nVBrWUSYW5E5\no/wu4MVYGeOmAQdA89oZdxJqMY8DawcNYvgXvsB2d95/4YXQwX/kkQxoaODmp55qs7yp1CrxRaqq\nCQkXH6L1N+Nbu7Bmera1zlcDCydMYNKECR2q1XRXgsT4eTaWlvLG6tXs3thI0/DhXHHPPZ1e5ySv\na0fNiZm/Qz6/oxJGFqZC+7t0dT2OxGsNXXkQ1QjOID0/ozGqIRxJmKdxJrkTDJ6b8Xpa7HxtdZyf\nE9USvp5jv6mxGsT8qDzTo23rSNd4fkq687yGlsOGUynfP0+oTc0j3YG9kDB3JdXhfQqhdnVG7Pwn\n9OvXqrZ10pAhOWsTuTrLa2LXaK+jO1+ZnefraF1LbOvbd3d9W4+fJ2tq/NLSXqkFZRuWm8/vqNpL\nYSrEvwtdrHEkfvPvUuHj/7ljwSO1fsZ50bZczT1nZLw+Nrohz8x1k8y42WYb9TSXEKxyNZFdGXt+\nIvjF2W6WhGCXOs86Wo/muiz63bIdu47WmXVTZTuntLTV/qnP6IYoYFyccc7Zgwb5vByfYVdG/2Q2\nndXkeY3uGpEUP0+uLw1nTJjQ6d+zI3LdXOZNm9bh31EjtApTIf5duho4ir5zHNLrXpwHHEy6g/f7\n0baraJ1g8BLga9HxqeaY7xI6utfT9lyHMkKH+fWEVf3OIyw/W0YYobSU1qOSUmuELIo9P4yQnPEJ\nWnemnxDbfivppqPUPjdG1703y7E3kU7uGP+MhgMbBw/m3K1bOSD6fVLrjiyPPqfUSLLmFCyDBnHQ\niScy55FHWo16mlteTnUXRj1ldp5vJ3vHfGqEUWZ1P55SJdv+HRUf2ZQaAJF5zrJ3383rnPnKNefl\n3K1bO/w7aoRWYeqLf5c+ETgg/CGG0DLjbOomcFT0+hTCpMB1hPXJfwDUEm6yqRvojcClhMASHy0V\nP28qqBxE+mabspAcN7+M56mU6uNy7D8+tj3XpMFcN7nVhEATl5p8yJ578pmtW/lmxrFnAd8gBM/x\n0e9VBRx04onMu+027njxRS6sq2sOKKk1zrvSTpuZj2h1fT1N69ZlHWGUbaLc9CitfFdHJMVHNuWa\n5Nk0bFj+v2Aect1cys06/DtqhFZh6pN/l65UV5J+kFH1m0LryXhnxKuGpEckXZmlOSf1uJ7QP3IG\noS/iRNITDFPNYqtyNCHF+wsy+0dSzxeSTmNydI79481rNTn2ydWscj6t2+nnEybw/W7FCr947NhW\n5b509GifPmpUc9/MQlpO+OuOTLjtaastOFt1fxUtF9Iq5j6OXM0ZV516qvo4ilwh/l3oYlNV0Y+q\nctJNT68DPyf9zfFSwloaB5NOJ3InIRvttuj9/6L1N4HTCLWXH5H+Bn85YVLgboQazM2EEViNhLQi\nYwjzRxoIzVhLYuWoIp0B9xuEVCRzgBvN2Lz//uy9Zg1LPv64RbnfIkwqXEyYAJg50unrhGaxnYRa\nQmr7tcBrJSV8dedOfk2Yh7K5pIRPTJnCdXfeyfiJE1lfX8/t8+ez/qmnKAdGHnEE37j9doA2R/f0\nhlwjjKqnTGFRlvUE5k2ezPDYBMcuj6ratImN/fqFUVVNTTQNG9bjo6pS12+VeqSigrnLlgEd/7u0\nN0JLklFof5eujqoq+sBxGvAGIa/UB8BIYC/CDbw/YQhsI+Em/DdCX8Rowg23Ltr3RtI33ouin5+I\n3t+NEJDeJtzwhxGG0+5DmBQ3njAEthT4O8KKgVtKSthrwAD22r6d19z5yIx9+vXj/UGD2PrRR4wf\nMIAP99ij+YaU+kfVVFdH3ebNjB01Chs5km2Njbzx4ouUA4MnTaK/Ge+98ALv7NjBjkGDOGDsWLaP\nHMn2pibeSw27nTyZM6+4guVLlhTMP9LukG3obleHAxeaQru5SN+1yweOGwhB4CXgL4RAcTVhNvZX\no217E27yHxI6pHcjPVt8G6FfYhKhv2Mg6fkKqdX/6giB4p7Y9rnl5QydNIn+e+/NDjOGvvee/rP3\noLa+kevzFsnPLh84zgW2Eib6bSI96a+C0MQziLAS1PLo9RuE3FOZnd4jgGMJzU7DgcElJYw79lim\nV1WxfMkS3qmrY8PmzVSMGkVZlmVXpefpG7lI99jlA8cNhNrDWYR06csJo6cAdgD/Rjrx4aXAoYTl\nBEcRgktqFvilhBnjI9A3WRHp23b5wJHqHP9m9BNCssNvE4bT/jshbcd7hE7kHxKasW4g1EwGA8M+\n+1n22mcfNTeJyC6hq4Gj6OdxVBNqHN8g5JOqIazjvS+h9vA+ofP7akJeqQuj1wcQ0qE/2Ic6V0VE\nekOfqXFUE4bNHkpIiV5KmKB3FmG281+BsYARJrcdjJqkRGTX1NUaR0n7uyTHzE4yszVm9hczW5Bt\nn2pCeowLCZ3kpYTRUw2ETLRfB/7hgQf4H3e+s3YtB8+YwRNTpnDrjBkKGiIinVCwNQ4zKyGMpj2O\nMGDqaeBsd18T26fFBMCjgHOB44FlwJeAc26/nUsuv7yXSy8iUrj6co3jcOCv7r7e3bcDPyYsQ9HC\nGcDJhA7vjYQAch5huO0XgYann+61AouI7AoKuXN8DLAh9vpVQjBp4eex518mzAq/hHQSwWLOQCki\nUogKOXB0SE308yOgHvgc6c7yC4EHizkDpYhIN6itraU2S663zirkPo7JQI27nxS9voaQ0fHm2D4t\nRlW9RBiC+0nCaKofatSUiEgrfXYCoJn1A14mdI6/BvwJmO7uq2P7+LmExIYXEDLQ7jZhApMmTtRE\nPhGRHPps4IAwHJeQUbwE+KG735TxvjcS0pZvBVYBP1q7VsFCRKQNfXrmuLs/Dny6rX1uIYygegq4\n8oEHFDRERHpYQQeOjlhE6ON4ZcAADjviiKSLIyLS5xXyPI4OKwO+/9FHLK2qSrooIiJ9Xp8IHBCC\nh+ZsiIj0vD4TOJqAEs3ZEBHpcX0icKSWEZ21eHHSRRER6fMKejhue8zMb5gyRXM2RETy0KfncbTH\nzLyYyy8ikoS+nB1XREQKkAKHiIjkRYFDRETyosAhIiJ5UeAQEZG8KHCIiEheFDhERCQvChwiIpIX\nBQ4REcmLAoeIiORFgUNERPKiwCEiInlJLHCY2Zlm9qKZfWxmh2a8d62Z/dXMVpvZCUmVUUREWkty\nzfEXgNOBf4tvNLP9gLOA/YB9gOVm9imlwRURKQyJ1Tjc/WV3/yuQmdp3GvBjd9/h7uuAvwKH93b5\nREQku0Ls4xgDbIi93hhtExGRAtCjTVVmtgwYGd8EOHC9u/+iO65RU1PT/LyyspLKysruOK2ISJ9R\nW1tLbW1tt50v8RUAzexJ4Ep3fzZ6fQ3g7n5z9PpxoNrd/5jlWHV9iIjkqa+sABj/BR4FzjazAWY2\nEfgk8KdkiiUiIpmSHI57mpltACYD/2VmvwJw91XAg8Aq4JfApapWiIgUjsSbqrpCTVUiIvnrK01V\nIiJSJBQ4REQkL0nOHO8W6+vrWVpVxc6NGykZM4ZZixczfuLEpIslItJnFX0fx5UVFSyqq6MMaAKq\nKyqYu2yZgoeISA5d7eMo+sDRCJTFtjUBt86YQfV99yVUKhGRwrbLd46XZXm9c9OmJIoiIrJLKPrA\n0ZTldcno0UkURURkl1D0gaO6oqI5eKT6OGYtXpxkkURE+rSi7+NYt3ZtGFW1aRMlo0drVJWISDt2\n+c7xYi6/iEgSdvnOcRER6V0KHCIikhcFDhERyYsCh4iI5EWBQ0RE8qLAISIieVHgEBGRvChwiIhI\nXpJcc/wWM1ttZs+b2c/MbGjsvWvN7K/R+yckVUYREWktyRrHE8Bn3P1g4K/AtQBmtj9wFrAf8CXg\n+2bW6RmOSaitrU26CK2oTB2jMnVcIZZLZeodiQUOd1/u7jujl08B+0TPTwV+7O473H0dIagcnkAR\nO60Q/6GoTB2jMnVcIZZLZeodhdLHcQHwy+j5GGBD7L2N0TYRESkAPbrmuJktA0bGNwEOXO/uv4j2\nuR7Y7u4P9GRZRESkeySaHdfMZgEXA8e6+4fRtmsAd/ebo9ePA9Xu/scsxys1rohIJxRlWnUzOwn4\nNvBFd38rtn1/4H7gCEIT1TLgU8qfLiJSGHq0qaoddwADgGXRoKmn3P1Sd19lZg8Cq4DtwKUKGiIi\nhaOoF3ISEZHeVyijqvJmZieZ2Roz+4uZLejF6/7QzBrMbGVs23Aze8LMXjazX5vZ7rH3enwyo5nt\nY2a/MbOXzOwFM7ss6XKZ2UAz+6OZPReVqTrpMsWuU2Jmz5rZowVUpnVm9ufo8/pTIZTLzHY3s/+M\nrvGSmR2R8L+pv48+n2ejn1vM7LIC+Jzmm9mLZrbSzO43swEFUKbLo/93PXM/cPeiexAC3t+A8UB/\n4Hlg31669heAg4GVsW03A9+Mni8Aboqe7w88R2gSnBCV2XqgTKOAg6Pn5cDLwL4FUK4h0c9+hLk6\nhyddpuha84H7gEcL4e8XXWstMDxjW9J/v6XA7Oh5KbB70mWKla0E2ASMTbJMwOjobzcgev0T4PyE\ny/QZYCUwMPq/9wRQ0Z1l6pE/ak8/gMnAr2KvrwEW9OL1x9MycKwBRkbPRwFrspUL+BVwRC+U72Fg\naqGUCxgCPAN8LukyESaaLgMqSQeOxD8noB7YM2NbYuUChgJ1WbYn/llF5z8B+O+ky0QIHOuB4dGN\n99Gk/+8BZwJ3xl4vBK4GVndXmYq1qSpzkuCrJDtJcG93bwBw983A3tH2Xp/MaGYTCDWipwj/SBIr\nV9Qk9BywGVjm7k8nXSbgNsJ/onjnXtJlIirPMjN72swuKoByTQTeNLO7o6ahJWY2JOEyxf0j8KPo\neWJlcvdNhNGhr0Tn3+Luy5MsE/AicHTUNDUE+P8INbNuK1OxBo5Cl8iIAzMrB34KXO7ujVnK0avl\ncved7n4I4Vv+4Wb2mSTLZGYnAw3u/jxhMmouSfz9jnL3Qwn/yb9uZkdnKUdvlqsUOBT4XlSuJsI3\n00T/TQGYWX9CaqL/zFGG3vw3NQyYRmiFGA2UmdmMJMvk7msIzVLLCBk5ngM+zrZrZ69RrIFjIzAu\n9nqfaFtSGsxsJICZjQJej7ZvJET6lB4rp5mVEoLGf7j7I4VSLgB3fw+oBU5KuExHAaea2VrgAeBY\nM/sPYHPSn5O7vxb9fIPQ1Hg4yX5WrwIb3P2Z6PXPCIGkEP5NfQn4H3d/M3qdZJmmAmvd/W13/xh4\nCPh8wmXC3e9298PcvRJ4l9Dv2W1lKtbA8TTwSTMbb2YDgLMJbYu9xWj5jfVRYFb0/Hzgkdj2s6NR\nFhOBTwJ/6qEy3QWscvfvFEK5zGxEatSGmQ0Gjie0sSZWJne/zt3HufsnCP9mfuPu5wK/SKpMAGY2\nJKotYmZlhPb7F0j2s2oANpjZ30ebjgNeSrJMMdMJgT8lyTK9Akw2s0FmZoTPaVXCZcLM9op+jgNO\nJzTrdV+ZeqrzqqcfhG+vLxOy517Ti9f9EWE0x4eEfzSzCR1jy6PyPAEMi+1/LWGUwmrghB4q01GE\nqujzhGrps9Hns0dS5QIOiMrxPGGEx/XR9sTKlFG+Y0h3jidaJkJ/Qupv90Lq33MBlOsgwpe054Gf\nE0ZVJV2mIcAbwG6xbUmXqTo6/0rgHsJIz6TL9FtCX8dzQGV3f06aACgiInkp1qYqERFJiAKHiIjk\nRYFDRETyosAhIiJ5UeAQEZG8KHCIiEheFDhE2mFmp5nZzthkuFz7nR/NyO3sdY4xs1909niR3qLA\nIdK+s4H/JsxYbsssup6wThOrpOApcIi0IUoBchRwIbHAYWYLooV7njOzG83sK8BhwH1RNtlBZlZv\nZntE+3/WzJ6Mnn/OzP5gZv9jZr8zs08l8KuJdFqSa46LFINpwOPu/jcze9PMDgFGAqcAn3P3D81s\nmLu/a2ZfB6509+cAzCxXhtTVwBfcfaeZHQf8E2ENBZGioMAh0rbpwO3R858A5xASXN7t7h8CuPu7\n0fuZyS9zpW4fBtwb1TQc/T+UIqN/sCI5mNlw4FhgUlR76Ee40f8nba/nkbKDdHPwoNj2xYTMvGeY\n2Xjgye4rtUjPUx+HSG7/ANzr7hPd/RPuPp6wxOt7wKwoXXwqwBBtHxo7vh74bPT8K7Htu5Ne72B2\nTxVepKcocIjk9o+EhXnifkZYr/lR4Bkzexa4MnrvHuBfo87xgcD/Av7FzP5EqH2k3ALcZGb/g/4P\nShFSWnUREcmLvu2IiEheFDhERCQvChwiIpIXBQ4REcmLAoeIiORFgUNERPKiwCEiInlR4BARkbz8\n/4QB+YVU6UGVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16376b2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(actual,predicted,\"ro\")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
