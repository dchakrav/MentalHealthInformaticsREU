{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Models\n",
    "This notebook will walk you through building and saving the most basic \n",
    "models we used for analysing our text data.\n",
    "\n",
    "We first import the libraries and utility files we are going to be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import useful mathematical libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import useful Machine learning libraries\n",
    "import gensim\n",
    "\n",
    "# Import utility files\n",
    "from utils import read_df,remove_links,clean_sentence,save_object,load_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup directories\n",
    "\n",
    "If this is the first time doing this analysis, \n",
    "we first will set up all the directories we need\n",
    "to save and load the models we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "directories = ['objects','models','clusters','matricies']\n",
    "for dirname in directories:\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name Model\n",
    "\n",
    "Before begining the rest of our project, we select a name for our model.\n",
    "This name will be used to save and load the files for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name= \"example_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse and Clean Data\n",
    "\n",
    "We first parse and clean our data. Our data is assumed to be in csv format, \n",
    "in a directory labeled 'data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the data from the csv\n",
    "df = read_df('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33069 entries, 0 to 3399\n",
      "Data columns (total 15 columns):\n",
      "title           33069 non-null object\n",
      "created_utc     33069 non-null int64\n",
      "ups             33069 non-null int64\n",
      "downs           33069 non-null int64\n",
      "num_comments    33069 non-null int64\n",
      "name            33069 non-null object\n",
      "id              33069 non-null object\n",
      "from            0 non-null float64\n",
      "from_id         0 non-null float64\n",
      "selftext        32652 non-null object\n",
      "subreddit       33069 non-null object\n",
      "score           33069 non-null int64\n",
      "author          33069 non-null object\n",
      "url             33069 non-null object\n",
      "permalink       33069 non-null object\n",
      "dtypes: float64(2), int64(5), object(8)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Do an inspection of our data to ensure nothing went wrong\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>from</th>\n",
       "      <th>from_id</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New year's eve is always a bad time, but we wi...</td>\n",
       "      <td>1451606721</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_3yyvad</td>\n",
       "      <td>3yyvad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>1</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>/r/SuicideWatch/comments/3yyvad/new_years_eve_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd rather end it...</td>\n",
       "      <td>1451608072</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>t3_3yyxqz</td>\n",
       "      <td>3yyxqz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I have been very depressed lately. I was a cut...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>2</td>\n",
       "      <td>deathproof69</td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>/r/SuicideWatch/comments/3yyxqz/id_rather_end_it/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Let's do this!</td>\n",
       "      <td>1451608080</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>t3_3yyxrg</td>\n",
       "      <td>3yyxrg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alright. It's about time. \\n\\nLong time lurker...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>3</td>\n",
       "      <td>gangerousdoblin</td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>/r/SuicideWatch/comments/3yyxrg/lets_do_this/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Please someone talk to me</td>\n",
       "      <td>1451608127</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_3yyxux</td>\n",
       "      <td>3yyxux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>2</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>/r/SuicideWatch/comments/3yyxux/please_someone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mostly Lifeless At The Moment</td>\n",
       "      <td>1451608748</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>t3_3yyyyb</td>\n",
       "      <td>3yyyyb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>2</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>/r/SuicideWatch/comments/3yyyyb/mostly_lifeles...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  created_utc  ups  downs  \\\n",
       "0  New year's eve is always a bad time, but we wi...   1451606721    1      0   \n",
       "1                               I'd rather end it...   1451608072    2      0   \n",
       "2                                     Let's do this!   1451608080    3      0   \n",
       "3                          Please someone talk to me   1451608127    2      0   \n",
       "4                      Mostly Lifeless At The Moment   1451608748    2      0   \n",
       "\n",
       "   num_comments       name      id  from  from_id  \\\n",
       "0             1  t3_3yyvad  3yyvad   NaN      NaN   \n",
       "1             4  t3_3yyxqz  3yyxqz   NaN      NaN   \n",
       "2             2  t3_3yyxrg  3yyxrg   NaN      NaN   \n",
       "3             1  t3_3yyxux  3yyxux   NaN      NaN   \n",
       "4             3  t3_3yyyyb  3yyyyb   NaN      NaN   \n",
       "\n",
       "                                            selftext     subreddit  score  \\\n",
       "0                                          [deleted]  SuicideWatch      1   \n",
       "1  I have been very depressed lately. I was a cut...  SuicideWatch      2   \n",
       "2  Alright. It's about time. \\n\\nLong time lurker...  SuicideWatch      3   \n",
       "3                                          [deleted]  SuicideWatch      2   \n",
       "4                                          [deleted]  SuicideWatch      2   \n",
       "\n",
       "            author                                                url  \\\n",
       "0        [deleted]  https://www.reddit.com/r/SuicideWatch/comments...   \n",
       "1     deathproof69  https://www.reddit.com/r/SuicideWatch/comments...   \n",
       "2  gangerousdoblin  https://www.reddit.com/r/SuicideWatch/comments...   \n",
       "3        [deleted]  https://www.reddit.com/r/SuicideWatch/comments...   \n",
       "4        [deleted]  https://www.reddit.com/r/SuicideWatch/comments...   \n",
       "\n",
       "                                           permalink  \n",
       "0  /r/SuicideWatch/comments/3yyvad/new_years_eve_...  \n",
       "1  /r/SuicideWatch/comments/3yyxqz/id_rather_end_it/  \n",
       "2      /r/SuicideWatch/comments/3yyxrg/lets_do_this/  \n",
       "3  /r/SuicideWatch/comments/3yyxux/please_someone...  \n",
       "4  /r/SuicideWatch/comments/3yyyyb/mostly_lifeles...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean the text in the dataframe\n",
    "df =df.replace(np.nan, '', regex=True)\n",
    "df =df.replace(\"\\[deleted\\]\", '', regex=True)\n",
    "df[\"rawtext\"]= df[\"title\"]+\" \"+df[\"selftext\"]\n",
    "df[\"cleantext\"]=df[\"rawtext\"].apply(remove_links).apply(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33069 entries, 0 to 3399\n",
      "Data columns (total 17 columns):\n",
      "title           33069 non-null object\n",
      "created_utc     33069 non-null int64\n",
      "ups             33069 non-null int64\n",
      "downs           33069 non-null int64\n",
      "num_comments    33069 non-null int64\n",
      "name            33069 non-null object\n",
      "id              33069 non-null object\n",
      "from            33069 non-null object\n",
      "from_id         33069 non-null object\n",
      "selftext        33069 non-null object\n",
      "subreddit       33069 non-null object\n",
      "score           33069 non-null int64\n",
      "author          33069 non-null object\n",
      "url             33069 non-null object\n",
      "permalink       33069 non-null object\n",
      "rawtext         33069 non-null object\n",
      "cleantext       33069 non-null object\n",
      "dtypes: int64(5), object(12)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check that the cleaning was successful\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>from</th>\n",
       "      <th>from_id</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>permalink</th>\n",
       "      <th>rawtext</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New year's eve is always a bad time, but we wi...</td>\n",
       "      <td>1451606721</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_3yyvad</td>\n",
       "      <td>3yyvad</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>/r/SuicideWatch/comments/3yyvad/new_years_eve_...</td>\n",
       "      <td>New year's eve is always a bad time, but we wi...</td>\n",
       "      <td>new years eve is always a bad time  but we wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd rather end it...</td>\n",
       "      <td>1451608072</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>t3_3yyxqz</td>\n",
       "      <td>3yyxqz</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>I have been very depressed lately. I was a cut...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>2</td>\n",
       "      <td>deathproof69</td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>/r/SuicideWatch/comments/3yyxqz/id_rather_end_it/</td>\n",
       "      <td>I'd rather end it... I have been very depresse...</td>\n",
       "      <td>id rather end it    i have been very depressed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Let's do this!</td>\n",
       "      <td>1451608080</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>t3_3yyxrg</td>\n",
       "      <td>3yyxrg</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Alright. It's about time. \\n\\nLong time lurker...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>3</td>\n",
       "      <td>gangerousdoblin</td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>/r/SuicideWatch/comments/3yyxrg/lets_do_this/</td>\n",
       "      <td>Let's do this! Alright. It's about time. \\n\\nL...</td>\n",
       "      <td>lets do this  alright  its about time    long ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Please someone talk to me</td>\n",
       "      <td>1451608127</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_3yyxux</td>\n",
       "      <td>3yyxux</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>/r/SuicideWatch/comments/3yyxux/please_someone...</td>\n",
       "      <td>Please someone talk to me</td>\n",
       "      <td>please someone talk to me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mostly Lifeless At The Moment</td>\n",
       "      <td>1451608748</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>t3_3yyyyb</td>\n",
       "      <td>3yyyyb</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>/r/SuicideWatch/comments/3yyyyb/mostly_lifeles...</td>\n",
       "      <td>Mostly Lifeless At The Moment</td>\n",
       "      <td>mostly lifeless at the moment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  created_utc  ups  downs  \\\n",
       "0  New year's eve is always a bad time, but we wi...   1451606721    1      0   \n",
       "1                               I'd rather end it...   1451608072    2      0   \n",
       "2                                     Let's do this!   1451608080    3      0   \n",
       "3                          Please someone talk to me   1451608127    2      0   \n",
       "4                      Mostly Lifeless At The Moment   1451608748    2      0   \n",
       "\n",
       "   num_comments       name      id from from_id  \\\n",
       "0             1  t3_3yyvad  3yyvad                \n",
       "1             4  t3_3yyxqz  3yyxqz                \n",
       "2             2  t3_3yyxrg  3yyxrg                \n",
       "3             1  t3_3yyxux  3yyxux                \n",
       "4             3  t3_3yyyyb  3yyyyb                \n",
       "\n",
       "                                            selftext     subreddit  score  \\\n",
       "0                                                     SuicideWatch      1   \n",
       "1  I have been very depressed lately. I was a cut...  SuicideWatch      2   \n",
       "2  Alright. It's about time. \\n\\nLong time lurker...  SuicideWatch      3   \n",
       "3                                                     SuicideWatch      2   \n",
       "4                                                     SuicideWatch      2   \n",
       "\n",
       "            author                                                url  \\\n",
       "0                   https://www.reddit.com/r/SuicideWatch/comments...   \n",
       "1     deathproof69  https://www.reddit.com/r/SuicideWatch/comments...   \n",
       "2  gangerousdoblin  https://www.reddit.com/r/SuicideWatch/comments...   \n",
       "3                   https://www.reddit.com/r/SuicideWatch/comments...   \n",
       "4                   https://www.reddit.com/r/SuicideWatch/comments...   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  /r/SuicideWatch/comments/3yyvad/new_years_eve_...   \n",
       "1  /r/SuicideWatch/comments/3yyxqz/id_rather_end_it/   \n",
       "2      /r/SuicideWatch/comments/3yyxrg/lets_do_this/   \n",
       "3  /r/SuicideWatch/comments/3yyxux/please_someone...   \n",
       "4  /r/SuicideWatch/comments/3yyyyb/mostly_lifeles...   \n",
       "\n",
       "                                             rawtext  \\\n",
       "0  New year's eve is always a bad time, but we wi...   \n",
       "1  I'd rather end it... I have been very depresse...   \n",
       "2  Let's do this! Alright. It's about time. \\n\\nL...   \n",
       "3                         Please someone talk to me    \n",
       "4                     Mostly Lifeless At The Moment    \n",
       "\n",
       "                                           cleantext  \n",
       "0  new years eve is always a bad time  but we wil...  \n",
       "1  id rather end it    i have been very depressed...  \n",
       "2  lets do this  alright  its about time    long ...  \n",
       "3                         please someone talk to me   \n",
       "4                     mostly lifeless at the moment   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase Analysis\n",
    "\n",
    "After parsing and cleaning the data we run the gensim phraser\n",
    "tool on our text data to join phrases like \"new york city\" \n",
    "together to form the word \"new_york_city\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a stream of tokens\n",
    "posts= df[\"cleantext\"].apply(lambda str: str.split()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train a phraseDetector to join two word phrases together\n",
    "two_word_phrases = gensim.models.Phrases(posts)\n",
    "two_word_phraser = gensim.models.phrases.Phraser(two_word_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a phraseDetector to join three word phrases together\n",
    "three_word_phrases = gensim.models.Phrases(two_word_phraser[posts])\n",
    "three_word_phraser = gensim.models.phrases.Phraser(three_word_phrases)\n",
    "posts              = list(three_word_phraser[two_word_phraser[posts]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update Data frame\n",
    "df[\"phrasetext\"]=df[\"cleantext\"].apply(lambda str: \" \".join(three_word_phraser[two_word_phraser[str.split()]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33069"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure posts contain same number of elements\n",
    "len(posts)==len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check that the dataframe was updated correctly\n",
    "for i in range(len(posts)):\n",
    "    if not \" \".join(posts[i])==list(df[\"phrasetext\"])[i]:\n",
    "        print(\"index :\"+str(i) +\" is incorrect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Saving\n",
    "\n",
    "After cleaning and parsing all of our data, we can now\n",
    "save it, so that we can analysis it later without having\n",
    "to go through lengthy computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_object(posts,'objects/',model_name+\"-posts\")\n",
    "save_object(df,'objects/',model_name+\"-df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Word2Vec Model\n",
    "\n",
    "After all of our data has been parsed and saved, \n",
    "we generate our Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the minimum word count to 10. This removes all words that appear less than 10 times in the data\n",
    "minimum_word_count=10\n",
    "# Set skip gram to 1. This sets gensim to use the skip gram model instead of the Continuous Bag of Words model\n",
    "skip_gram = 1\n",
    "# Set Hidden layer size to 300.\n",
    "hidden_layer_size =300\n",
    "# Set the window size to 5. \n",
    "window_size = 5\n",
    "# Set hierarchical softmax to 1. This sets gensim to use hierarchical softmax\n",
    "hierarchical_softmax =1\n",
    "# Set negative sampling to 20. This is good for relatively small data sets, but becomes harder for larger datasets\n",
    "negative_sampling =20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = gensim.models.Word2Vec(posts,min_count =minimum_word_count, sg=skip_gram, size =hidden_layer_size,\n",
    "                                window=window_size,hs=hierarchical_softmax,negative=negative_sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model test\n",
    "\n",
    "After generating our model, we run some basic tests\n",
    "to ensure that it has captured some semantic information results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('father_figure', 0.5078849196434021),\n",
       " ('puppy', 0.5020877122879028),\n",
       " ('sis', 0.4523952305316925),\n",
       " ('girlfriend_whom', 0.4390547573566437),\n",
       " ('baby', 0.4342191815376282),\n",
       " ('kidnapped', 0.4331890940666199),\n",
       " ('soul_mate', 0.43072372674942017),\n",
       " ('our_daughter', 0.4306313097476959),\n",
       " ('bunny', 0.427238404750824),\n",
       " ('ceremony', 0.426519513130188)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"kitten\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 0.5760773420333862),\n",
       " ('druggie', 0.48784691095352173),\n",
       " ('mom', 0.46765851974487305),\n",
       " ('husband', 0.46576985716819763),\n",
       " ('dad', 0.46441134810447693),\n",
       " ('step_father', 0.44937026500701904),\n",
       " ('grandmother', 0.44449758529663086),\n",
       " ('brother', 0.43873152136802673),\n",
       " ('stepfather', 0.43668779730796814),\n",
       " ('babysitter', 0.43309086561203003)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"father\",\"woman\"],negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relatives', 0.36684978008270264),\n",
       " ('parents', 0.3621269464492798),\n",
       " ('job_prospects', 0.3588736653327942),\n",
       " ('extended_family', 0.35447224974632263),\n",
       " ('incentive', 0.3542650640010834),\n",
       " ('family_members', 0.35329771041870117),\n",
       " ('moms_side', 0.338132381439209),\n",
       " ('dirt_poor', 0.3373897075653076),\n",
       " ('utilities', 0.3347025513648987),\n",
       " ('family_hates', 0.32735511660575867)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"family\",\"obligation\"],negative =[\"love\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model\n",
    "\n",
    "After generating our model, and runing some basic tests,\n",
    "we now save it so that we can analysis it later without having\n",
    "to go through lengthy computations. We also delete and then reload\n",
    "the model, as an example of how to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('models/'+model_name+'.model')\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load('models/'+model_name+'.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Matricies\n",
    "\n",
    "After generating our Word2Vec Model, we generate \n",
    "a collection of matricies that will be useful for\n",
    "analysis. This includes a Words By feature matrix,\n",
    "and a Post By Words Matrix. Note, we will use camelCase \n",
    "for matrix names, and only matrix names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the list of words used\n",
    "vocab_list = sorted(list(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the word vectors\n",
    "vecs = []\n",
    "for word in vocab_list:\n",
    "    vecs.append(model.wv[word].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change array format into numpy array\n",
    "WordByFeature = np.array(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "countvec = CountVectorizer(vocabulary =vocab_list,analyzer=(lambda lst:list(map((lambda s:s),lst))),min_df=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make Posts By Words Matrix\n",
    "PostsByWords = countvec.fit_transform(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Matrix tests\n",
    "\n",
    "After generating our matricies, we run some basic tests\n",
    "to ensure that they seem resaonable later without having\n",
    "to go through lengthy computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that PostsByWords is the number of Posts by the number of words\n",
    "PostsByWords.shape[0]==len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the number of words is consistant for all matricies\n",
    "PostsByWords.shape[1]== len(WordByFeatureMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Matricies\n",
    "\n",
    "After generating our matricies, we save them so we can \n",
    "analyze them later without having to go through lengthy\n",
    "computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_object(PostsByWords,'objects/',model_name+\"-PostsByWords\")\n",
    "save_object(WordByFeature,'objects/',model_name+\"-WordByFeatureMat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Word Clusters\n",
    "\n",
    "Now that we have generated and saved our matricies,\n",
    "we will proceed to generate word clusters using \n",
    "kmeans clustering, and save them for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# get the fit for different values of K\n",
    "test_points = [12]+ list(range(25,401,25))\n",
    "fit = []\n",
    "for point in test_points:\n",
    "    kmeans = KMeans(n_clusters=point, random_state=42).fit(WordByFeatureMat)\n",
    "    save_object(kmeans,'clusters/',model_name+\"-cluster_model-\"+str(point))\n",
    "    fit.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
