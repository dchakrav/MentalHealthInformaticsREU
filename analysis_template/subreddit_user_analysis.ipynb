{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import useful mathematical libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Import useful Machine learning libraries\n",
    "import gensim\n",
    "\n",
    "# Import utility files\n",
    "from utils import read_df, remove_links, clean_sentence, save_object, load_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the model name\n",
    "model_name = \"example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the folder for saved objects\n",
    "import os\n",
    "directories = ['objects', 'objects/subreddit_post_analysis']\n",
    "for dirname in directories:\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the data from the csv, assumed to be in a directory 'data'\n",
    "#indexed by name of the author MAKE SURE author is in column index 2 (position 3)\n",
    "# This version skips over deleted authors to speed up analysis\n",
    "dirname = 'data'\n",
    "extension = \"/*.csv\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df_list =[]\n",
    "fnames = glob.glob(dirname + extension)\n",
    "for fname in fnames:\n",
    "    df_chunks = pd.read_csv(fname, header=0, index_col = 2, iterator=True, chunksize=1000)\n",
    "    df = pd.concat([chunk[chunk.index != '[deleted]'] for chunk in df_chunks])\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the data frame of posts\n",
    "save_object(df, 'objects/', model_name + \"-subreddit_user_analysis_Posts_dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 292 entries, dediobst to zach84\n",
      "Data columns (total 14 columns):\n",
      "title           292 non-null object\n",
      "created_utc     292 non-null int64\n",
      "ups             292 non-null int64\n",
      "downs           292 non-null int64\n",
      "num_comments    292 non-null int64\n",
      "name            292 non-null object\n",
      "id              292 non-null object\n",
      "from            0 non-null float64\n",
      "from_id         0 non-null float64\n",
      "selftext        120 non-null object\n",
      "subreddit       292 non-null object\n",
      "score           292 non-null int64\n",
      "url             292 non-null object\n",
      "permalink       292 non-null object\n",
      "dtypes: float64(2), int64(5), object(7)\n",
      "memory usage: 34.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>from</th>\n",
       "      <th>from_id</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>url</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dediobst</th>\n",
       "      <td>Side effects after break from medication?</td>\n",
       "      <td>1325521921</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>t3_nzvpw</td>\n",
       "      <td>nzvpw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When I first began taking Vyvanse (40 mg), I w...</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.reddit.com/r/ADHD/comments/nzvpw/si...</td>\n",
       "      <td>/r/ADHD/comments/nzvpw/side_effects_after_brea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>choraule</th>\n",
       "      <td>Notes from ADHD in Women: A Hidden Disorder, A...</td>\n",
       "      <td>1325486071</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>t3_nzi53</td>\n",
       "      <td>nzi53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr. Quinn, and expert and speaker on ADHD, cam...</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>22</td>\n",
       "      <td>http://www.reddit.com/r/ADHD/comments/nzi53/no...</td>\n",
       "      <td>/r/ADHD/comments/nzi53/notes_from_adhd_in_wome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hajojebi</th>\n",
       "      <td>Resources?</td>\n",
       "      <td>1325479085</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_nzdy6</td>\n",
       "      <td>nzdy6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I have ADHD. I however, do not have a full tim...</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>3</td>\n",
       "      <td>http://www.reddit.com/r/ADHD/comments/nzdy6/re...</td>\n",
       "      <td>/r/ADHD/comments/nzdy6/resources/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LiliBlume</th>\n",
       "      <td>ADHD drugs do not increase risk of heart disea...</td>\n",
       "      <td>1325584742</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>t3_o0y6c</td>\n",
       "      <td>o0y6c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>12</td>\n",
       "      <td>http://www.washingtonpost.com/national/health-...</td>\n",
       "      <td>/r/ADHD/comments/o0y6c/adhd_drugs_do_not_incre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stupidestgirl</th>\n",
       "      <td>What to do when medication seems ineffective?</td>\n",
       "      <td>1325560701</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>t3_o0m51</td>\n",
       "      <td>o0m51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi, so I'm currently taking Adderall XR 30mg w...</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>3</td>\n",
       "      <td>http://www.reddit.com/r/ADHD/comments/o0m51/wh...</td>\n",
       "      <td>/r/ADHD/comments/o0m51/what_to_do_when_medicat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           title  created_utc  \\\n",
       "author                                                                          \n",
       "dediobst              Side effects after break from medication?    1325521921   \n",
       "choraule       Notes from ADHD in Women: A Hidden Disorder, A...   1325486071   \n",
       "hajojebi                                              Resources?   1325479085   \n",
       "LiliBlume      ADHD drugs do not increase risk of heart disea...   1325584742   \n",
       "stupidestgirl     What to do when medication seems ineffective?    1325560701   \n",
       "\n",
       "               ups  downs  num_comments      name     id  from  from_id  \\\n",
       "author                                                                    \n",
       "dediobst         2      0             7  t3_nzvpw  nzvpw   NaN      NaN   \n",
       "choraule        24      2            12  t3_nzi53  nzi53   NaN      NaN   \n",
       "hajojebi         3      0             1  t3_nzdy6  nzdy6   NaN      NaN   \n",
       "LiliBlume       13      1             3  t3_o0y6c  o0y6c   NaN      NaN   \n",
       "stupidestgirl    4      1             8  t3_o0m51  o0m51   NaN      NaN   \n",
       "\n",
       "                                                        selftext subreddit  \\\n",
       "author                                                                       \n",
       "dediobst       When I first began taking Vyvanse (40 mg), I w...      ADHD   \n",
       "choraule       Dr. Quinn, and expert and speaker on ADHD, cam...      ADHD   \n",
       "hajojebi       I have ADHD. I however, do not have a full tim...      ADHD   \n",
       "LiliBlume                                                    NaN      ADHD   \n",
       "stupidestgirl  Hi, so I'm currently taking Adderall XR 30mg w...      ADHD   \n",
       "\n",
       "               score                                                url  \\\n",
       "author                                                                    \n",
       "dediobst           2  http://www.reddit.com/r/ADHD/comments/nzvpw/si...   \n",
       "choraule          22  http://www.reddit.com/r/ADHD/comments/nzi53/no...   \n",
       "hajojebi           3  http://www.reddit.com/r/ADHD/comments/nzdy6/re...   \n",
       "LiliBlume         12  http://www.washingtonpost.com/national/health-...   \n",
       "stupidestgirl      3  http://www.reddit.com/r/ADHD/comments/o0m51/wh...   \n",
       "\n",
       "                                                       permalink  \n",
       "author                                                            \n",
       "dediobst       /r/ADHD/comments/nzvpw/side_effects_after_brea...  \n",
       "choraule       /r/ADHD/comments/nzi53/notes_from_adhd_in_wome...  \n",
       "hajojebi                       /r/ADHD/comments/nzdy6/resources/  \n",
       "LiliBlume      /r/ADHD/comments/o0y6c/adhd_drugs_do_not_incre...  \n",
       "stupidestgirl  /r/ADHD/comments/o0m51/what_to_do_when_medicat...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a list of all authors\n",
    "authors = []\n",
    "author_frequency = []\n",
    "for author in df.index:\n",
    "    if not (author in authors):\n",
    "        authors.append(author)\n",
    "        author_frequency.append(1)\n",
    "    else:\n",
    "        author_frequency[authors.index(author)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[deleted]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the most frequent author\n",
    "authors[author_frequency.index(max(author_frequency))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# move deleted authors into separate variables for faster run DONE with loading DFs\n",
    "#authors_deleted = authors.index('[deleted]')\n",
    "#authors_frequency_deleted = author_frequency[authors.index('[deleted]')]\n",
    "#del author_frequency[authors.index('[deleted]')]\n",
    "#del authors[authors.index('[deleted]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Deletion: 551900\n",
      "After Deletion: 292\n"
     ]
    }
   ],
   "source": [
    "# number of posts before deletion\n",
    "print('Before Deletion: ' + str(len(df)))\n",
    "# number of posts after deletion\n",
    "print('After Deletion: ' + str(len(df)-len(df.loc[['[deleted]']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in range(len(df.loc[[authors[2]]])):\n",
    "#    print(df.loc[[authors[2]]].iloc[[i][0]].subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a list of author subreddit counts\n",
    "author_subreddit_counts = []\n",
    "total_subreddit_count = []\n",
    "# iterate through the authors\n",
    "for author in authors:\n",
    "    subreddits = []\n",
    "    subreddit_count = []\n",
    "    sub = []\n",
    "    # find posts from that author in dataframe\n",
    "    for i in range(len(df.loc[[author]])):\n",
    "        # if this is the author's first post in the subreddit, add the subreddit name to subreddits list, and add one to the occcurces\n",
    "        if not (df.loc[[author]].iloc[[i][0]].subreddit in subreddits):\n",
    "            subreddits.append(df.loc[[author]].iloc[[i][0]].subreddit)\n",
    "            subreddit_count.append(1)\n",
    "        # else, add one to the subreddit's occurences at the subreddits index within subreddit count\n",
    "        else:\n",
    "            subreddit_count[subreddits.index(df.loc[[author]].iloc[[i][0]].subreddit)] += 1\n",
    "    # after going through all the data, create a list of lists, which contain a subreddit and its occurence\n",
    "    for i in range(len(subreddits)):\n",
    "        sub.append([subreddits[i],subreddit_count[i]])\n",
    "    # append this list to the author_subreddits list\n",
    "    author_subreddit_counts.append(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save array of author counts\n",
    "save_object(author_subreddit_counts, 'objects/', model_name + \"-subreddit_analysis_author_subreddit_counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create lists for subreddits, subreddit totals\n",
    "subreddits = []\n",
    "subreddit_post_totals = []\n",
    "# iterate through the list of lists of lists to find all the occurences of a subreddit\n",
    "for i in range(len(author_subreddit_counts)):\n",
    "    # if a new subreddit is found, append it to all_subreddits, and add its occurences to the correct position in total_posts\n",
    "    # if it has already been found, add its occurences from that user tothe correct position in total_posts\n",
    "    for j in range(len(author_subreddit_counts[i])):\n",
    "        if not(author_subreddit_counts[i][j][0] in subreddits):\n",
    "            subreddits.append(author_subreddit_counts[i][j][0])\n",
    "            subreddit_post_totals.append(author_subreddit_counts[i][j][1])\n",
    "        else:\n",
    "            subreddit_post_totals[subreddits.index(author_subreddit_counts[i][j][0])] += author_subreddit_counts[i][j][1]\n",
    "            \n",
    "#sort the subreddits and their post totals\n",
    "subreddit_post_totals, subreddits = (list(t) for t in zip(*sorted(zip(subreddit_post_totals, subreddits))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADHD: 34.93150684931507\n",
      "Agronomy: 0.3424657534246575\n",
      "Anthropology: 0.684931506849315\n",
      "Archaeology: 1.7123287671232876\n",
      "AskReddit: 2.0547945205479454\n",
      "Atlanta: 0.3424657534246575\n",
      "Bayes: 1.0273972602739727\n",
      "BipolarReddit: 0.3424657534246575\n",
      "BodyAcceptance: 3.767123287671233\n",
      "Christianity: 0.3424657534246575\n",
      "Coffee: 0.3424657534246575\n",
      "Communications: 1.0273972602739727\n",
      "CrappyDesign: 0.3424657534246575\n",
      "DesktopDetective: 0.3424657534246575\n",
      "DoesAnybodyElse: 0.3424657534246575\n",
      "Drugs: 0.684931506849315\n",
      "EarthPorn: 0.3424657534246575\n",
      "Fitness: 0.3424657534246575\n",
      "Games: 0.3424657534246575\n",
      "GradSchool: 1.7123287671232876\n",
      "IDAP: 0.3424657534246575\n",
      "LadiesofScience: 0.684931506849315\n",
      "LadyBoners: 0.3424657534246575\n",
      "LongDistance: 0.3424657534246575\n",
      "Medicaid: 0.3424657534246575\n",
      "Military: 0.3424657534246575\n",
      "Minecraft: 1.0273972602739727\n",
      "Music: 0.3424657534246575\n",
      "Names: 1.36986301369863\n",
      "Naruto: 0.3424657534246575\n",
      "Ohio: 0.3424657534246575\n",
      "Paleontology: 0.3424657534246575\n",
      "RedditDayOf: 0.3424657534246575\n",
      "SFGiants: 0.3424657534246575\n",
      "Scotch: 0.684931506849315\n",
      "Scrubs: 0.3424657534246575\n",
      "Sikh: 0.3424657534246575\n",
      "SocialEngineering: 0.3424657534246575\n",
      "TrueReddit: 0.3424657534246575\n",
      "WTF: 1.0273972602739727\n",
      "akron: 0.3424657534246575\n",
      "askscience: 1.0273972602739727\n",
      "atheism: 1.0273972602739727\n",
      "banana: 0.3424657534246575\n",
      "beer: 0.3424657534246575\n",
      "bestof: 0.3424657534246575\n",
      "books: 0.3424657534246575\n",
      "canada: 5.136986301369863\n",
      "choralmusic: 0.3424657534246575\n",
      "discworld: 0.3424657534246575\n",
      "education: 0.3424657534246575\n",
      "explainlikeimfive: 0.3424657534246575\n",
      "fences: 0.3424657534246575\n",
      "firstworldproblems: 0.3424657534246575\n",
      "fitnessplus: 0.3424657534246575\n",
      "funny: 1.7123287671232876\n",
      "gamedev: 1.0273972602739727\n",
      "gamemaker: 0.3424657534246575\n",
      "gaming: 0.3424657534246575\n",
      "gamingpc: 0.684931506849315\n",
      "gifs: 0.3424657534246575\n",
      "healthcare: 0.684931506849315\n",
      "healthcarereform: 0.3424657534246575\n",
      "history: 0.684931506849315\n",
      "hospitals: 0.3424657534246575\n",
      "languagelearning: 0.3424657534246575\n",
      "lanparty: 0.3424657534246575\n",
      "malefashionadvice: 0.3424657534246575\n",
      "marketing: 0.684931506849315\n",
      "math: 0.3424657534246575\n",
      "mentalhealth: 0.3424657534246575\n",
      "musicdetective: 0.3424657534246575\n",
      "mylittlepony: 0.3424657534246575\n",
      "news: 0.3424657534246575\n",
      "nursing: 0.684931506849315\n",
      "occupywallstreet: 0.684931506849315\n",
      "ottawa: 0.684931506849315\n",
      "pakistan: 0.3424657534246575\n",
      "pharmaceuticals: 0.3424657534246575\n",
      "pharmacy: 1.36986301369863\n",
      "philadelphia: 0.3424657534246575\n",
      "prescriptiondrugabuse: 0.3424657534246575\n",
      "relationship_tips: 0.3424657534246575\n",
      "reportthespammers: 1.7123287671232876\n",
      "sanfrancisco: 0.3424657534246575\n",
      "science: 1.0273972602739727\n",
      "secretsanta: 0.3424657534246575\n",
      "shittyaskscience: 0.3424657534246575\n",
      "skeptic: 1.0273972602739727\n",
      "southasian: 0.3424657534246575\n",
      "space: 0.3424657534246575\n",
      "tf2: 0.3424657534246575\n",
      "tf2trade: 0.3424657534246575\n",
      "todayilearned: 0.3424657534246575\n",
      "todayiresearched: 0.3424657534246575\n",
      "toronto: 0.3424657534246575\n",
      "travel: 0.3424657534246575\n",
      "truegaming: 0.3424657534246575\n",
      "uchicago: 1.0273972602739727\n",
      "ukpolitics: 0.3424657534246575\n",
      "unitedkingdom: 0.3424657534246575\n",
      "vegan: 0.684931506849315\n",
      "videos: 0.684931506849315\n",
      "worldnews: 0.684931506849315\n",
      "worldpolitics: 0.3424657534246575\n",
      "writing: 0.3424657534246575\n"
     ]
    }
   ],
   "source": [
    "# print the percentages of posts in each subreddit present\n",
    "sum_posts = 0\n",
    "for posts in subreddit_post_totals:\n",
    "    sum_posts += posts\n",
    "    \n",
    "for subreddit in subreddits:\n",
    "    print(str(subreddit), end=\": \")\n",
    "    print(subreddit_post_totals[subreddits.index(subreddit)]*100/sum_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find percentage of authors who post in each subreddit\n",
    "# create list that holds the number of authors that post in each subreddit, ordered by subreddit\n",
    "num_authors_in_subreddits = []\n",
    "for subreddit in subreddits:\n",
    "    num_authors_in_subreddits.append(0)\n",
    "# update the list with occurences\n",
    "for i in range(len(author_subreddit_counts)):\n",
    "    for j in range(len(author_subreddit_counts[i])):\n",
    "        num_authors_in_subreddits[subreddits.index(author_subreddit_counts[i][j][0])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADHD: 1.0\n",
      "Agronomy: 0.011904761904761904\n",
      "Anthropology: 0.011904761904761904\n",
      "Archaeology: 0.011904761904761904\n",
      "AskReddit: 0.05952380952380952\n",
      "Atlanta: 0.011904761904761904\n",
      "Bayes: 0.011904761904761904\n",
      "BipolarReddit: 0.011904761904761904\n",
      "BodyAcceptance: 0.011904761904761904\n",
      "Christianity: 0.011904761904761904\n",
      "Coffee: 0.011904761904761904\n",
      "Communications: 0.011904761904761904\n",
      "CrappyDesign: 0.011904761904761904\n",
      "DesktopDetective: 0.011904761904761904\n",
      "DoesAnybodyElse: 0.011904761904761904\n",
      "Drugs: 0.011904761904761904\n",
      "EarthPorn: 0.011904761904761904\n",
      "Fitness: 0.011904761904761904\n",
      "Games: 0.011904761904761904\n",
      "GradSchool: 0.011904761904761904\n",
      "IDAP: 0.011904761904761904\n",
      "LadiesofScience: 0.011904761904761904\n",
      "LadyBoners: 0.011904761904761904\n",
      "LongDistance: 0.011904761904761904\n",
      "Medicaid: 0.011904761904761904\n",
      "Military: 0.011904761904761904\n",
      "Minecraft: 0.011904761904761904\n",
      "Music: 0.011904761904761904\n",
      "Names: 0.011904761904761904\n",
      "Naruto: 0.011904761904761904\n",
      "Ohio: 0.011904761904761904\n",
      "Paleontology: 0.011904761904761904\n",
      "RedditDayOf: 0.011904761904761904\n",
      "SFGiants: 0.011904761904761904\n",
      "Scotch: 0.011904761904761904\n",
      "Scrubs: 0.011904761904761904\n",
      "Sikh: 0.011904761904761904\n",
      "SocialEngineering: 0.011904761904761904\n",
      "TrueReddit: 0.011904761904761904\n",
      "WTF: 0.023809523809523808\n",
      "akron: 0.011904761904761904\n",
      "askscience: 0.03571428571428571\n",
      "atheism: 0.03571428571428571\n",
      "banana: 0.011904761904761904\n",
      "beer: 0.011904761904761904\n",
      "bestof: 0.011904761904761904\n",
      "books: 0.011904761904761904\n",
      "canada: 0.03571428571428571\n",
      "choralmusic: 0.011904761904761904\n",
      "discworld: 0.011904761904761904\n",
      "education: 0.011904761904761904\n",
      "explainlikeimfive: 0.011904761904761904\n",
      "fences: 0.011904761904761904\n",
      "firstworldproblems: 0.011904761904761904\n",
      "fitnessplus: 0.011904761904761904\n",
      "funny: 0.03571428571428571\n",
      "gamedev: 0.011904761904761904\n",
      "gamemaker: 0.011904761904761904\n",
      "gaming: 0.011904761904761904\n",
      "gamingpc: 0.011904761904761904\n",
      "gifs: 0.011904761904761904\n",
      "healthcare: 0.011904761904761904\n",
      "healthcarereform: 0.011904761904761904\n",
      "history: 0.023809523809523808\n",
      "hospitals: 0.011904761904761904\n",
      "languagelearning: 0.011904761904761904\n",
      "lanparty: 0.011904761904761904\n",
      "malefashionadvice: 0.011904761904761904\n",
      "marketing: 0.011904761904761904\n",
      "math: 0.011904761904761904\n",
      "mentalhealth: 0.011904761904761904\n",
      "musicdetective: 0.011904761904761904\n",
      "mylittlepony: 0.011904761904761904\n",
      "news: 0.011904761904761904\n",
      "nursing: 0.011904761904761904\n",
      "occupywallstreet: 0.023809523809523808\n",
      "ottawa: 0.011904761904761904\n",
      "pakistan: 0.011904761904761904\n",
      "pharmaceuticals: 0.011904761904761904\n",
      "pharmacy: 0.011904761904761904\n",
      "philadelphia: 0.011904761904761904\n",
      "prescriptiondrugabuse: 0.011904761904761904\n",
      "relationship_tips: 0.011904761904761904\n",
      "reportthespammers: 0.023809523809523808\n",
      "sanfrancisco: 0.011904761904761904\n",
      "science: 0.011904761904761904\n",
      "secretsanta: 0.011904761904761904\n",
      "shittyaskscience: 0.011904761904761904\n",
      "skeptic: 0.023809523809523808\n",
      "southasian: 0.011904761904761904\n",
      "space: 0.011904761904761904\n",
      "tf2: 0.011904761904761904\n",
      "tf2trade: 0.011904761904761904\n",
      "todayilearned: 0.011904761904761904\n",
      "todayiresearched: 0.011904761904761904\n",
      "toronto: 0.011904761904761904\n",
      "travel: 0.011904761904761904\n",
      "truegaming: 0.011904761904761904\n",
      "uchicago: 0.011904761904761904\n",
      "ukpolitics: 0.011904761904761904\n",
      "unitedkingdom: 0.011904761904761904\n",
      "vegan: 0.023809523809523808\n",
      "videos: 0.023809523809523808\n",
      "worldnews: 0.023809523809523808\n",
      "worldpolitics: 0.011904761904761904\n",
      "writing: 0.011904761904761904\n"
     ]
    }
   ],
   "source": [
    "# print percentages of users in each subreddit present\n",
    "for subreddit in subreddits:\n",
    "    print(str(subreddit), end=\": \")\n",
    "    print(num_authors_in_subreddits[subreddits.index(subreddit)]/len(authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
