{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import useful mathematical libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Import useful Machine learning libraries\n",
    "import gensim\n",
    "\n",
    "# Import utility files\n",
    "from utils import read_df, save_object, load_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the model name\n",
    "model_name = \"example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the folder for saved objects\n",
    "import os\n",
    "directories = ['objects', 'objects/subreddit_post_analysis']\n",
    "for dirname in directories:\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the data from the csv files, assumed to be in a directory 'data'\n",
    "# indexed by name of the author MAKE SURE author is in column index 2 (position 3)\n",
    "# This version skips over deleted authors to speed up analysis\n",
    "dirname = 'data'\n",
    "extension = \"/*.csv\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df_list =[]\n",
    "fnames = glob.glob(dirname + extension)\n",
    "for fname in fnames:\n",
    "    df_chunks = pd.read_csv(fname, header=0, index_col = 2, iterator=True, chunksize=1000)\n",
    "    df = pd.concat([chunk[chunk.index != '[deleted]'] for chunk in df_chunks])\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the data frame of posts\n",
    "save_object(df, 'objects/', model_name + \"-subreddit_user_analysis_Posts_dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a list of all authors\n",
    "authors = []\n",
    "author_frequency = []\n",
    "for author in df.index:\n",
    "    if not (author in authors):\n",
    "        authors.append(author)\n",
    "        author_frequency.append(1)\n",
    "    else:\n",
    "        author_frequency[authors.index(author)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the most frequent author\n",
    "authors[author_frequency.index(max(author_frequency))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# move deleted authors into separate variables for faster run DONE with loading DFs\n",
    "#authors_deleted = authors.index('[deleted]')\n",
    "#authors_frequency_deleted = author_frequency[authors.index('[deleted]')]\n",
    "#del author_frequency[authors.index('[deleted]')]\n",
    "#del authors[authors.index('[deleted]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of posts before deletion\n",
    "print('Before Deletion: ' + str(len(df)))\n",
    "# number of posts after deletion\n",
    "print('After Deletion: ' + str(len(df)-len(df.loc[['[deleted]']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in range(len(df.loc[[authors[2]]])):\n",
    "#    print(df.loc[[authors[2]]].iloc[[i][0]].subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a list of author subreddit counts\n",
    "author_subreddit_counts = []\n",
    "total_subreddit_count = []\n",
    "# iterate through the authors\n",
    "for author in authors:\n",
    "    subreddits = []\n",
    "    subreddit_count = []\n",
    "    sub = []\n",
    "    # find posts from that author in dataframe\n",
    "    for i in range(len(df.loc[[author]])):\n",
    "        # if this is the author's first post in the subreddit, add the subreddit name to subreddits list, and add one to the occcurces\n",
    "        if not (df.loc[[author]].iloc[[i][0]].subreddit in subreddits):\n",
    "            subreddits.append(df.loc[[author]].iloc[[i][0]].subreddit)\n",
    "            subreddit_count.append(1)\n",
    "        # else, add one to the subreddit's occurences at the subreddits index within subreddit count\n",
    "        else:\n",
    "            subreddit_count[subreddits.index(df.loc[[author]].iloc[[i][0]].subreddit)] += 1\n",
    "    # after going through all the data, create a list of lists, which contain a subreddit and its occurence\n",
    "    for i in range(len(subreddits)):\n",
    "        sub.append([subreddits[i],subreddit_count[i]])\n",
    "    # append this list to the author_subreddits list\n",
    "    author_subreddit_counts.append(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save array of author counts\n",
    "save_object(author_subreddit_counts, 'objects/', model_name + \"-subreddit_analysis_author_subreddit_counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create lists for subreddits, subreddit totals\n",
    "subreddits = []\n",
    "subreddit_post_totals = []\n",
    "# iterate through the list of lists of lists to find all the occurences of a subreddit\n",
    "for i in range(len(author_subreddit_counts)):\n",
    "    # if a new subreddit is found, append it to all_subreddits, and add its occurences to the correct position in total_posts\n",
    "    # if it has already been found, add its occurences from that user tothe correct position in total_posts\n",
    "    for j in range(len(author_subreddit_counts[i])):\n",
    "        if not(author_subreddit_counts[i][j][0] in subreddits):\n",
    "            subreddits.append(author_subreddit_counts[i][j][0])\n",
    "            subreddit_post_totals.append(author_subreddit_counts[i][j][1])\n",
    "        else:\n",
    "            subreddit_post_totals[subreddits.index(author_subreddit_counts[i][j][0])] += author_subreddit_counts[i][j][1]\n",
    "            \n",
    "#sort the subreddits and their post totals\n",
    "subreddit_post_totals, subreddits = (list(t) for t in zip(*sorted(zip(subreddit_post_totals, subreddits))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the percentages of posts in each subreddit present\n",
    "sum_posts = 0\n",
    "for posts in subreddit_post_totals:\n",
    "    sum_posts += posts\n",
    "    \n",
    "for subreddit in subreddits:\n",
    "    print(str(subreddit), end=\": \")\n",
    "    print(subreddit_post_totals[subreddits.index(subreddit)]*100/sum_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find percentage of authors who post in each subreddit\n",
    "# create list that holds the number of authors that post in each subreddit, ordered by subreddit\n",
    "num_authors_in_subreddits = []\n",
    "for subreddit in subreddits:\n",
    "    num_authors_in_subreddits.append(0)\n",
    "# update the list with occurences\n",
    "for i in range(len(author_subreddit_counts)):\n",
    "    for j in range(len(author_subreddit_counts[i])):\n",
    "        num_authors_in_subreddits[subreddits.index(author_subreddit_counts[i][j][0])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print percentages of users in each subreddit present\n",
    "for subreddit in subreddits:\n",
    "    print(str(subreddit), end=\": \")\n",
    "    print(num_authors_in_subreddits[subreddits.index(subreddit)]/len(authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
